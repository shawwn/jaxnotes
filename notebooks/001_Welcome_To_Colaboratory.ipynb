{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shawwn/jaxnotes/blob/master/notebooks/001_Welcome_To_Colaboratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fCEDCU_qrC0"
      },
      "source": [
        "<p><img alt=\"Colaboratory logo\" height=\"45px\" src=\"/img/colab_favicon.ico\" align=\"left\" hspace=\"10px\" vspace=\"0px\"></p>\n",
        "\n",
        "<h1>What is Colaboratory?</h1>\n",
        "\n",
        "Colaboratory, or \"Colab\" for short, allows you to write and execute Python in your browser, with \n",
        "- Zero configuration required\n",
        "- Free access to GPUs\n",
        "- Easy sharing\n",
        "\n",
        "Whether you're a **student**, a **data scientist** or an **AI researcher**, Colab can make your work easier. Watch [Introduction to Colab](https://www.youtube.com/watch?v=inN8seMm7UI) to learn more, or just get started below!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJBs_flRovLc"
      },
      "source": [
        "## **Getting started**\n",
        "\n",
        "The document you are reading is not a static web page, but an interactive environment called a **Colab notebook** that lets you write and execute code.\n",
        "\n",
        "For example, here is a **code cell** with a short Python script that computes a value, stores it in a variable, and prints the result:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJr_9dXGpJ05",
        "outputId": "0b185252-f92b-4691-eee1-5438c16d0ab0"
      },
      "source": [
        "seconds_in_a_day = 24 * 60 * 60\n",
        "seconds_in_a_day"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86400"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fhs6GZ4qFMx"
      },
      "source": [
        "To execute the code in the above cell, select it with a click and then either press the play button to the left of the code, or use the keyboard shortcut \"Command/Ctrl+Enter\". To edit the code, just click the cell and start editing.\n",
        "\n",
        "Variables that you define in one cell can later be used in other cells:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "-gE-Ez1qtyIA",
        "outputId": "94cb2224-0edf-457b-90b5-0ac3488d8a97"
      },
      "source": [
        "seconds_in_a_week = 7 * seconds_in_a_day\n",
        "seconds_in_a_week"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "604800"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSrWNr3MuFUS"
      },
      "source": [
        "Colab notebooks allow you to combine **executable code** and **rich text** in a single document, along with **images**, **HTML**, **LaTeX** and more. When you create your own Colab notebooks, they are stored in your Google Drive account. You can easily share your Colab notebooks with co-workers or friends, allowing them to comment on your notebooks or even edit them. To learn more, see [Overview of Colab](/notebooks/basic_features_overview.ipynb). To create a new Colab notebook you can use the File menu above, or use the following link: [create a new Colab notebook](http://colab.research.google.com#create=true).\n",
        "\n",
        "Colab notebooks are Jupyter notebooks that are hosted by Colab. To learn more about the Jupyter project, see [jupyter.org](https://www.jupyter.org)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdRyKR44dcNI"
      },
      "source": [
        "## Data science\n",
        "\n",
        "With Colab you can harness the full power of popular Python libraries to analyze and visualize data. The code cell below uses **numpy** to generate some random data, and uses **matplotlib** to visualize it. To edit the code, just click the cell and start editing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "C4HZx7Gndbrh",
        "outputId": "46abc637-6abd-41b2-9bba-80a7ae992e06"
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "ys = 200 + np.random.randn(100)\n",
        "x = [x for x in range(len(ys))]\n",
        "\n",
        "plt.plot(x, ys, '-')\n",
        "plt.fill_between(x, ys, 195, where=(ys > 195), facecolor='g', alpha=0.6)\n",
        "\n",
        "plt.title(\"Sample Visualization\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wEY0siNlckV2gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_kCnsPUqS6o"
      },
      "source": [
        "You can import your own data into Colab notebooks from your Google Drive account, including from spreadsheets, as well as from Github and many other sources. To learn more about importing data, and how Colab can be used for data science, see the links below under [Working with Data](#working-with-data)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwuxHmxllTwN"
      },
      "source": [
        "## Machine learning\n",
        "\n",
        "With Colab you can import an image dataset, train an image classifier on it, and evaluate the model, all in just [a few lines of code](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb). Colab notebooks execute code on Google's cloud servers, meaning you can leverage the power of Google hardware, including [GPUs and TPUs](#using-accelerated-hardware), regardless of the power of your machine. All you need is a browser."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufxBm1yRnruN"
      },
      "source": [
        "Colab is used extensively in the machine learning community with applications including:\n",
        "- Getting started with TensorFlow\n",
        "- Developing and training neural networks\n",
        "- Experimenting with TPUs\n",
        "- Disseminating AI research\n",
        "- Creating tutorials\n",
        "\n",
        "To see sample Colab notebooks that demonstrate machine learning applications, see the [machine learning examples](#machine-learning-examples) below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Rh3-Vt9Nev9"
      },
      "source": [
        "## More Resources\n",
        "\n",
        "### Working with Notebooks in Colab\n",
        "- [Overview of Colaboratory](/notebooks/basic_features_overview.ipynb)\n",
        "- [Guide to Markdown](/notebooks/markdown_guide.ipynb)\n",
        "- [Importing libraries and installing dependencies](/notebooks/snippets/importing_libraries.ipynb)\n",
        "- [Saving and loading notebooks in GitHub](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb)\n",
        "- [Interactive forms](/notebooks/forms.ipynb)\n",
        "- [Interactive widgets](/notebooks/widgets.ipynb)\n",
        "- <img src=\"/img/new.png\" height=\"20px\" align=\"left\" hspace=\"4px\" alt=\"New\"></img>\n",
        " [TensorFlow 2 in Colab](/notebooks/tensorflow_version.ipynb)\n",
        "\n",
        "<a name=\"working-with-data\"></a>\n",
        "### Working with Data\n",
        "- [Loading data: Drive, Sheets, and Google Cloud Storage](/notebooks/io.ipynb) \n",
        "- [Charts: visualizing data](/notebooks/charts.ipynb)\n",
        "- [Getting started with BigQuery](/notebooks/bigquery.ipynb)\n",
        "\n",
        "### Machine Learning Crash Course\n",
        "These are a few of the notebooks from Google's online Machine Learning course. See the [full course website](https://developers.google.com/machine-learning/crash-course/) for more.\n",
        "- [Intro to Pandas](/notebooks/mlcc/intro_to_pandas.ipynb)\n",
        "- [Tensorflow concepts](/notebooks/mlcc/tensorflow_programming_concepts.ipynb)\n",
        "- [First steps with TensorFlow](/notebooks/mlcc/first_steps_with_tensor_flow.ipynb)\n",
        "- [Intro to neural nets](/notebooks/mlcc/intro_to_neural_nets.ipynb)\n",
        "- [Intro to sparse data and embeddings](/notebooks/mlcc/intro_to_sparse_data_and_embeddings.ipynb)\n",
        "\n",
        "<a name=\"using-accelerated-hardware\"></a>\n",
        "### Using Accelerated Hardware\n",
        "- [TensorFlow with GPUs](/notebooks/gpu.ipynb)\n",
        "- [TensorFlow with TPUs](/notebooks/tpu.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-H6Lw1vyNNd"
      },
      "source": [
        "<a name=\"machine-learning-examples\"></a>\n",
        "\n",
        "## Machine Learning Examples\n",
        "\n",
        "To see end-to-end examples of the interactive machine learning analyses that Colaboratory makes possible, check out these  tutorials using models from [TensorFlow Hub](https://tfhub.dev).\n",
        "\n",
        "A few featured examples:\n",
        "\n",
        "- [Retraining an Image Classifier](https://tensorflow.org/hub/tutorials/tf2_image_retraining): Build a Keras model on top of a pre-trained image classifier to distinguish flowers.\n",
        "- [Text Classification](https://tensorflow.org/hub/tutorials/tf2_text_classification): Classify IMDB movie reviews as either *positive* or *negative*.\n",
        "- [Style Transfer](https://tensorflow.org/hub/tutorials/tf2_arbitrary_image_stylization): Use deep learning to transfer style between images.\n",
        "- [Multilingual Universal Sentence Encoder Q&A](https://tensorflow.org/hub/tutorials/retrieval_with_tf_hub_universal_encoder_qa): Use a machine learning model to answer questions from the SQuAD dataset.\n",
        "- [Video Interpolation](https://tensorflow.org/hub/tutorials/tweening_conv3d): Predict what happened in a video between the first and the last frame.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JP2yrpbgxXSw"
      },
      "source": [
        "# Jax examples\n",
        "\n",
        "These are some random Jax code snippets that I've come across, mostly for learning purposes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjkQV4bqxjSu"
      },
      "source": [
        "## [jax/multi_device_test.py](https://github.com/google/jax/blob/main/tests/multi_device_test.py)\n",
        "\n",
        "\n",
        "This was mentioned in the [JAX FAQ \"Controlling data and computation placement on devices\"](https://jax.readthedocs.io/en/latest/faq.html#controlling-data-and-computation-placement-on-devices)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXhUGmNGx4FS",
        "outputId": "01b91283-b515-4a93-8c9e-f48ae2d05f65"
      },
      "source": [
        "%%time\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import lax\n",
        "from jax import test_util as jtu\n",
        "from jax.lib import xla_bridge\n",
        "from jax.interpreters import xla\n",
        "\n",
        "class MultiDeviceTest(jtu.JaxTestCase):\n",
        "\n",
        "  def get_devices(self):\n",
        "    if len(jax.devices()) < 2:\n",
        "      raise SkipTest(\"test requires multiple devices\")\n",
        "    return jax.devices()\n",
        "\n",
        "  def assert_committed_to_device(self, data, device):\n",
        "    \"\"\"Asserts that the data is committed to the device.\"\"\"\n",
        "    self.assertIsNotNone(data._device)\n",
        "    self.assertEqual(data.device_buffer.device(), device)\n",
        "\n",
        "  def assert_uncommitted_to_device(self, data, device):\n",
        "    \"\"\"Asserts that the data is on the device but not committed to it.\"\"\"\n",
        "    self.assertIsNone(data._device)\n",
        "    self.assertEqual(data.device_buffer.device(), device)\n",
        "\n",
        "  def test_computation_follows_data(self):\n",
        "    devices = self.get_devices()\n",
        "\n",
        "    # By default, computation is placed (uncommitted) on device 0\n",
        "    x = jnp.ones(2)\n",
        "    self.assert_uncommitted_to_device(x, devices[0])\n",
        "\n",
        "    # Computing only with uncommitted data, will perform the computation\n",
        "    # on the same device 0, and the result is uncommitted\n",
        "    y = jnp.sin(x + x * 1) + 2\n",
        "    self.assert_uncommitted_to_device(y, devices[0])\n",
        "\n",
        "    # We can use device_put to both place the data on the requested device,\n",
        "    # and to commit it there.\n",
        "    z = jax.device_put(1, devices[1])\n",
        "    self.assert_committed_to_device(z, devices[1])\n",
        "\n",
        "\n",
        "    # A computation with some committed inputs will happen on the committed\n",
        "    # device. Uncommitted data may be moved to the committed device.\n",
        "    u = z + x  # z is committed, and x is uncommitted\n",
        "    self.assert_committed_to_device(u, devices[1])\n",
        "\n",
        "    # A computation with inputs committed to multiple devices will result\n",
        "    # in an error\n",
        "    with self.assertRaisesRegex(ValueError,\n",
        "                                \"primitive arguments must be colocated on the same device\"):\n",
        "      jax.device_put(x, devices[2]) + jax.device_put(x, devices[3])\n",
        "\n",
        "    # A jitted-computation without a device specification behave like any\n",
        "    # other primitive\n",
        "    jit_add = jax.jit(lambda a, b: a + b)\n",
        "    self.assert_uncommitted_to_device(jit_add(1, 2), devices[0])\n",
        "    self.assert_committed_to_device(jit_add(1, jax.device_put(2, devices[2])),\n",
        "                                    devices[2])\n",
        "    with self.assertRaisesRegex(ValueError,\n",
        "                                \"primitive arguments must be colocated on the same device\"):\n",
        "      jit_add(jax.device_put(x, devices[2]), jax.device_put(x, devices[3]))\n",
        "\n",
        "    # Even jit of trivial computations leaves the result uncommitted\n",
        "    x_uncommitted = jnp.array([1, 2, 3])\n",
        "    y = jax.jit(lambda x: x)(x_uncommitted)\n",
        "    self.assert_uncommitted_to_device(y, devices[0])\n",
        "\n",
        "    z1, z2 = jax.jit(lambda x: (x, x))(x_uncommitted)\n",
        "    self.assert_uncommitted_to_device(z1, devices[0])\n",
        "    self.assert_uncommitted_to_device(z2, devices[0])\n",
        "    self.assertIs(z1, z2)\n",
        "\n",
        "    x2_uncommitted = jnp.array([2, 3])\n",
        "    z1, z2, z3 = jax.jit(lambda x, y: (y, 1, x))(x_uncommitted, x2_uncommitted)\n",
        "    self.assert_uncommitted_to_device(z1, devices[0])\n",
        "    self.assert_uncommitted_to_device(z2, devices[0])\n",
        "    self.assert_uncommitted_to_device(z3, devices[0])\n",
        "\n",
        "\n",
        "    # A jitted computation with an device specification behaves as if the\n",
        "    # arguments are first device_put to the specified device. The result\n",
        "    # will be committed on the specified.\n",
        "    # The `device` parameter is experimental, and subject to change.\n",
        "    jit_add_on4 = jax.jit(lambda a, b: a + b, device=devices[4])\n",
        "    self.assert_committed_to_device(jit_add_on4(1, 2), devices[4])\n",
        "    self.assert_committed_to_device(jit_add_on4(1, jax.device_put(2, devices[2])),\n",
        "                                    devices[4])\n",
        "    self.assert_committed_to_device(jit_add_on4(jax.device_put(x_uncommitted, devices[2]),\n",
        "                                                jax.device_put(x_uncommitted, devices[3])),\n",
        "                                    devices[4])\n",
        "\n",
        "  def test_primitive_compilation_cache(self):\n",
        "    devices = self.get_devices()\n",
        "\n",
        "    x = jax.device_put(jnp.int32(1), devices[1])\n",
        "\n",
        "    with jtu.count_primitive_compiles() as count:\n",
        "      y = lax.add(x, x)\n",
        "      z = lax.add(y, y)\n",
        "\n",
        "    self.assertEqual(count[0], 1)\n",
        "    self.assert_committed_to_device(y, devices[1])\n",
        "    self.assert_committed_to_device(z, devices[1])\n",
        "\n",
        "  def test_device_put(self):\n",
        "    devices = self.get_devices()\n",
        "\n",
        "    # test device_put on regular values\n",
        "    x = jax.device_put(1, device=devices[0])\n",
        "    self.assert_committed_to_device(x, devices[0])\n",
        "\n",
        "    # test device_put on its own output\n",
        "    y = jax.device_put(x, device=devices[1])\n",
        "    self.assert_committed_to_device(y, devices[1])\n",
        "\n",
        "    x = jax.device_put(jnp.zeros(2), device=devices[0])\n",
        "    self.assert_committed_to_device(x, devices[0])\n",
        "\n",
        "    y = jax.device_put(x, device=devices[1])\n",
        "    self.assert_committed_to_device(y, devices[1])\n",
        "\n",
        "    x = jax.device_put(jnp.zeros(2), device=devices[1])\n",
        "    self.assert_committed_to_device(x, devices[1])\n",
        "\n",
        "    # device_put with device=None does not change placement\n",
        "    x = jax.device_put(jnp.zeros(2))\n",
        "    self.assert_uncommitted_to_device(x, devices[0])\n",
        "\n",
        "    x = jax.device_put(jax.device_put(2, device=devices[1]))\n",
        "    self.assert_committed_to_device(x, devices[1])\n",
        "\n",
        "\n",
        "  def test_closed_over_values_device_placement(self):\n",
        "    # see https://github.com/google/jax/issues/1431\n",
        "    devices = self.get_devices()\n",
        "\n",
        "    def f(): return lax.add(3., 4.)\n",
        "    self.assertIsInstance(f(), xla.DeviceArray)\n",
        "    self.assert_uncommitted_to_device(f(), devices[0])\n",
        "    self.assert_uncommitted_to_device(jax.jit(f)(), devices[0])\n",
        "    self.assert_committed_to_device(jax.jit(f, device=devices[1])(),\n",
        "                                    devices[1])\n",
        "\n",
        "  def test_reshape(self):\n",
        "    devices = self.get_devices()\n",
        "    # computation follows data explicitly placed on device 1\n",
        "    x = jax.device_put(1, devices[1])\n",
        "    y = x.reshape((1, 1))\n",
        "    self.assert_committed_to_device(y, devices[1])\n",
        "    z = y.reshape((1, 1))\n",
        "    self.assert_committed_to_device(z, devices[1])\n",
        "\n",
        "  def test_broadcast(self):\n",
        "    devices = self.get_devices()\n",
        "\n",
        "    z = 1 + jnp.ones((2, 3))\n",
        "    self.assert_uncommitted_to_device(z, devices[0])\n",
        "    y = jax.device_put(1, devices[2]) + jnp.ones((2, 3))\n",
        "    self.assert_committed_to_device(y, devices[2])\n",
        "\n",
        "  def test_transpose(self):\n",
        "    devices = self.get_devices()\n",
        "\n",
        "    x = jnp.ones((2, 3))\n",
        "    self.assert_uncommitted_to_device(x, devices[0])\n",
        "\n",
        "    y = lax.transpose(x, (1, 0))\n",
        "    self.assert_uncommitted_to_device(y, devices[0])\n",
        "    z = lax.transpose(jax.device_put(x, devices[2]), (1, 0))\n",
        "    self.assert_committed_to_device(z, devices[2])\n",
        "\n",
        "\n",
        "self = MultiDeviceTest()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 179 s, sys: 0 ns, total: 179 s\n",
            "Wall time: 249 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaiiahhQy8Gw",
        "outputId": "d5ae85d6-2582-437a-e067-e6e70df3e0c5"
      },
      "source": [
        "%time self.test_computation_follows_data()\n",
        "%time self.test_primitive_compilation_cache()\n",
        "%time self.test_device_put()\n",
        "%time self.test_closed_over_values_device_placement()\n",
        "%time self.test_reshape()\n",
        "%time self.test_broadcast()\n",
        "%time self.test_transpose()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 111 ms, sys: 18.2 ms, total: 129 ms\n",
            "Wall time: 103 ms\n",
            "CPU times: user 10.3 ms, sys: 0 ns, total: 10.3 ms\n",
            "Wall time: 8.06 ms\n",
            "CPU times: user 23.8 ms, sys: 1.14 ms, total: 24.9 ms\n",
            "Wall time: 18.8 ms\n",
            "CPU times: user 28.5 ms, sys: 928 s, total: 29.4 ms\n",
            "Wall time: 25.6 ms\n",
            "CPU times: user 7.35 ms, sys: 0 ns, total: 7.35 ms\n",
            "Wall time: 6.26 ms\n",
            "CPU times: user 37.6 ms, sys: 6.93 ms, total: 44.5 ms\n",
            "Wall time: 36.4 ms\n",
            "CPU times: user 21.6 ms, sys: 0 ns, total: 21.6 ms\n",
            "Wall time: 18 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msR5D_FM9n1U"
      },
      "source": [
        "## haiku + optax example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RK-YQd-S9qlA",
        "outputId": "87866cb7-0833-49ce-f7b4-c982c64d999e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip3 install -U dm-haiku optax tqdm"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: dm-haiku in /home/shawn/.local/lib/python3.8/site-packages (0.0.5.dev0)\n",
            "Requirement already satisfied: optax in /home/shawn/.local/lib/python3.8/site-packages (0.0.8)\n",
            "Requirement already satisfied: tqdm in /home/shawn/.local/lib/python3.8/site-packages (4.61.1)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /home/shawn/.local/lib/python3.8/site-packages (from dm-haiku) (0.8.9)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.8/dist-packages (from dm-haiku) (0.12.0)\n",
            "Requirement already satisfied: jmp>=0.0.2 in /home/shawn/.local/lib/python3.8/site-packages (from dm-haiku) (0.0.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.8/dist-packages (from dm-haiku) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from absl-py>=0.7.1->dm-haiku) (1.16.0)\n",
            "Requirement already satisfied: jax>=0.1.55 in /home/shawn/.local/lib/python3.8/site-packages (from optax) (0.2.14)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.8/dist-packages (from optax) (0.1.67)\n",
            "Requirement already satisfied: chex>=0.0.4 in /home/shawn/.local/lib/python3.8/site-packages (from optax) (0.0.7)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /home/shawn/.local/lib/python3.8/site-packages (from chex>=0.0.4->optax) (0.1.6)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /home/shawn/.local/lib/python3.8/site-packages (from chex>=0.0.4->optax) (0.11.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.8/dist-packages (from jax>=0.1.55->optax) (3.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from jaxlib>=0.1.37->optax) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.8/dist-packages (from jaxlib>=0.1.37->optax) (1.12)\n",
            "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 21.1.3 is available.\n",
            "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jezyW_A-KRG"
      },
      "source": [
        "import haiku as hk\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import optax\n",
        "import tqdm"
      ],
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOUO1jq390A7"
      },
      "source": [
        "learning_rate = 1e-2\n",
        "batch_size = 64\n",
        "input_size = 8\n",
        "n_training_steps = 100"
      ],
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg5LdX3G95tS"
      },
      "source": [
        "# Random number generator sequence.\n",
        "key_seq = hk.PRNGSequence(1729)"
      ],
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBkUld2e95-l"
      },
      "source": [
        "# A simple Linear function.\n",
        "def forward_pass(x):\n",
        "  return hk.Linear(10)(x)"
      ],
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sY2d233o96Jx"
      },
      "source": [
        "network = hk.without_apply_rng(hk.transform(forward_pass))"
      ],
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97LpaASu96S6"
      },
      "source": [
        "# Some arbitrary loss.\n",
        "def mean_square_loss(params, x):\n",
        "  output = network.apply(params, x)\n",
        "  loss = jnp.sum(output**2)\n",
        "  return loss"
      ],
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIQybsbT96bk"
      },
      "source": [
        "# Construct a simple Adam optimiser using the transforms in optax.\n",
        "# You could also just use the `optax.adam` alias, but we show here how\n",
        "# to do so manually so that you may construct your own `custom` optimiser.\n",
        "opt_init, opt_update = optax.chain(\n",
        "    # Set the parameters of Adam. Note the learning_rate is not here.\n",
        "    optax.scale_by_adam(b1=0.9, b2=0.999, eps=1e-8),\n",
        "    # Put a minus sign to *minimise* the loss.\n",
        "    optax.scale(-learning_rate)\n",
        ")"
      ],
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKPyAgsx96mD"
      },
      "source": [
        "# Initialise the model's parameters and the optimiser's state.\n",
        "# The `state` of an optimiser contains all statistics used by the\n",
        "# stateful transformations in the `chain` (in this case just `scale_by_adam`).\n",
        "params = network.init(next(key_seq), jnp.zeros([1, input_size]))\n",
        "opt_state = opt_init(params)"
      ],
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnF0ilrp96t0",
        "outputId": "e776c53c-d513-4f7c-dee9-3aacb8b5bd4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Minimise the loss.\n",
        "for step in tqdm.trange(n_training_steps):\n",
        "  # Get input. Learn to minimize the input to 0.\n",
        "  data = jax.random.normal(next(key_seq), [batch_size, input_size])\n",
        "  # Compute gradient and loss.\n",
        "  loss, grad = jax.value_and_grad(mean_square_loss)(params, data)\n",
        "  print(f'Loss[{step}] = {loss}')\n",
        "  # Transform the gradients using the optimiser.\n",
        "  updates, opt_state = opt_update(grad, opt_state, params)\n",
        "  # Update parameters.\n",
        "  params = optax.apply_updates(params, updates)"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  4%|         | 4/100 [00:00<00:04, 19.21it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss[0] = 360.4685363769531\n",
            "Loss[1] = 383.222900390625\n",
            "Loss[2] = 387.949951171875\n",
            "Loss[3] = 353.0426330566406\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  8%|         | 8/100 [00:00<00:04, 19.45it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss[4] = 351.621826171875\n",
            "Loss[5] = 306.15032958984375\n",
            "Loss[6] = 286.50439453125\n",
            "Loss[7] = 260.3722229003906\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 12%|        | 12/100 [00:00<00:04, 19.48it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss[8] = 247.23802185058594\n",
            "Loss[9] = 252.73973083496094\n",
            "Loss[10] = 211.09149169921875\n",
            "Loss[11] = 191.31239318847656\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 14%|        | 14/100 [00:00<00:04, 19.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss[12] = 195.86322021484375\n",
            "Loss[13] = 165.38400268554688\n",
            "Loss[14] = 203.56411743164062\n",
            "Loss[15] = 153.7543182373047\n",
            "Loss[16] = 155.00555419921875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 19%|        | 19/100 [00:00<00:04, 19.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss[17] = 152.5860595703125\n",
            "Loss[18] = 126.02527618408203\n",
            "Loss[19] = 145.9685821533203\n",
            "Loss[20] = 124.48328399658203\n",
            "Loss[21] = 113.47123718261719\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 25%|       | 25/100 [00:01<00:03, 20.27it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss[22] = 121.27320861816406\n",
            "Loss[23] = 99.3895492553711\n",
            "Loss[24] = 97.33267974853516\n",
            "Loss[25] = 94.80059814453125\n",
            "Loss[26] = 93.54313659667969\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 31%|       | 31/100 [00:01<00:03, 20.05it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss[27] = 86.94953155517578\n",
            "Loss[28] = 71.41590881347656\n",
            "Loss[29] = 81.15572357177734\n",
            "Loss[30] = 50.53354263305664\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 34%|      | 34/100 [00:01<00:03, 20.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss[31] = 60.777435302734375\n",
            "Loss[32] = 56.270145416259766\n",
            "Loss[33] = 56.12770462036133\n",
            "Loss[34] = 46.2148551940918\n",
            "Loss[35] = 46.85677719116211\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|      | 40/100 [00:02<00:02, 20.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss[36] = 42.114933013916016\n",
            "Loss[37] = 44.25080490112305\n",
            "Loss[38] = 32.378509521484375\n",
            "Loss[39] = 36.31406021118164\n",
            "Loss[40] = 34.094600677490234\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 43%|     | 43/100 [00:02<00:02, 20.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss[41] = 28.004365921020508\n",
            "Loss[42] = 29.078697204589844\n",
            "Loss[43] = 24.826072692871094\n",
            "Loss[44] = 24.6033992767334\n",
            "Loss[45] = 23.0926513671875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 48%|     | 48/100 [00:02<00:02, 19.85it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss[46] = 20.05662727355957\n",
            "Loss[47] = 19.317113876342773\n",
            "Loss[48] = 19.516845703125\n",
            "Loss[49] = 17.92032241821289\n",
            "Loss[50] = 14.532524108886719\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 53%|    | 53/100 [00:02<00:02, 19.98it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss[51] = 14.189445495605469\n",
            "Loss[52] = 12.643304824829102\n",
            "Loss[53] = 11.310023307800293\n",
            "Loss[54] = 11.214791297912598\n",
            "Loss[55] = 10.769514083862305\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 59%|    | 59/100 [00:02<00:02, 20.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss[56] = 9.315577507019043\n",
            "Loss[57] = 9.702679634094238\n",
            "Loss[58] = 9.152926445007324\n",
            "Loss[59] = 7.6360764503479\n",
            "Loss[60] = 6.652319431304932\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 65%|   | 65/100 [00:03<00:01, 20.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss[61] = 6.621987819671631\n",
            "Loss[62] = 5.874000072479248\n",
            "Loss[63] = 5.920876502990723\n",
            "Loss[64] = 5.1665191650390625\n",
            "Loss[65] = 5.140484809875488\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 68%|   | 68/100 [00:03<00:01, 20.22it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss[66] = 4.875308513641357\n",
            "Loss[67] = 3.6651241779327393\n",
            "Loss[68] = 3.8316946029663086\n",
            "Loss[69] = 2.970449924468994\n",
            "Loss[70] = 2.8759851455688477\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 74%|  | 74/100 [00:03<00:01, 20.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss[71] = 3.3813316822052\n",
            "Loss[72] = 2.716059446334839\n",
            "Loss[73] = 2.4723241329193115\n",
            "Loss[74] = 2.4627063274383545\n",
            "Loss[75] = 1.8654676675796509\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|  | 80/100 [00:03<00:00, 20.34it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss[76] = 1.844037413597107\n",
            "Loss[77] = 1.7082849740982056\n",
            "Loss[78] = 1.3265392780303955\n",
            "Loss[79] = 1.3780871629714966\n",
            "Loss[80] = 1.1984424591064453\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 83%| | 83/100 [00:04<00:00, 20.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss[81] = 1.0033552646636963\n",
            "Loss[82] = 0.862655520439148\n",
            "Loss[83] = 0.7771552801132202\n",
            "Loss[84] = 0.9016150236129761\n",
            "Loss[85] = 0.7677745223045349\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 89%| | 89/100 [00:04<00:00, 20.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss[86] = 0.6724677681922913\n",
            "Loss[87] = 0.5727012157440186\n",
            "Loss[88] = 0.6650385856628418\n",
            "Loss[89] = 0.4620400667190552\n",
            "Loss[90] = 0.4926437437534332\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 95%|| 95/100 [00:04<00:00, 20.58it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss[91] = 0.47753676772117615\n",
            "Loss[92] = 0.42201071977615356\n",
            "Loss[93] = 0.34924575686454773\n",
            "Loss[94] = 0.3175011873245239\n",
            "Loss[95] = 0.3437548577785492\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 100/100 [00:04<00:00, 20.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss[96] = 0.26395124197006226\n",
            "Loss[97] = 0.26085519790649414\n",
            "Loss[98] = 0.20528018474578857\n",
            "Loss[99] = 0.18269899487495422\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfqYAb_LqSsr"
      },
      "source": [
        "# Jax tutorials"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVqmiSQtr2kP"
      },
      "source": [
        "## Tutorial 1: [Thinking in Jax](https://jax.readthedocs.io/en/latest/notebooks/thinking_in_jax.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btSjqRa4qWqJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d66d9cee-419d-4aaa-d61e-615274c9d95e"
      },
      "source": [
        "import jax\n",
        "from pprint import pprint as pp\n",
        "pp(jax.devices())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0),\n",
            " TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1),\n",
            " TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0),\n",
            " TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1),\n",
            " TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0),\n",
            " TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1),\n",
            " TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0),\n",
            " TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "rnzGDWrUsBKQ",
        "outputId": "1fc47cf9-6a88-4622-c58d-b2eccfc00cc6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "x_np = np.linspace(0, 10, 1000)\n",
        "y_np = 2 * np.sin(x_np) * np.cos(x_np)\n",
        "plt.plot(x_np, y_np);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABCSUlEQVR4nO2deXxk1XXnv6eqtJd2lZaW1K3W0ns33SC6MWBwMKvtALEdBzye4MQOySTO5iQTnHw+dmInGTyZzziTGScTYjvBE2LsYCcQG4MxAbwATTfQq7pbWy/aVdqrtKvqzh9VT10tJLWk2t5yv5+PPqp69eq9o6f37u+ce889V5RSaDQajca5uNJtgEaj0WjSixYCjUajcThaCDQajcbhaCHQaDQah6OFQKPRaByOJ90GbISysjJVV1eXbjM0Go3GUrz55ptDSinf0u2WFIK6ujqOHj2abjM0Go3GUojIxeW2664hjUajcThaCDQajcbhaCHQaDQah6OFQKPRaByOFgKNRqNxOAkRAhH5mogMisipFT4XEflrEWkXkRMicm3MZw+JSFv056FE2KPRaDSatZOoiOAfgbtX+fweoCn68zDwtwAiUgJ8DjgEHAQ+JyLFCbJJo9FoNGsgIfMIlFI/EpG6VXa5D/i6itS8fl1EikSkCngP8IJSagRARF4gIijfSIRdqeTi8CQ/OD2A2yW8b28VlYXZ6TbJMYTCip+0D3Gia4ytvjzu2l1Jhlv3eqaK0ck5njvdz9jUPO9uKmNPdWG6TdKsk1RNKKsGumLed0e3rbT9HYjIw0SiCTZv3pwcKzeAUoq/faWD//H8OcLRpR2++NxZvnD/Hj7SXJte4xzAUHCW33jiLQ6fH1nc1lTu5Wsfv57aktw0WuYMXjo7yO988xjj0/MAfPE5+MV3beFzP7sbt0vSbJ1mrVjGbVJKPaaUalZKNft875ghnTb+/sed/PfnzvG+vVW89pnbePn338P1dSX816dO8G9v96TbPFszNbfAL//jEY53j/HfPriX0396F3/3n69jMDDLR/7uNYaCs+k20da83jnMr/6/N6kuyuG7v3kzxz57Bx+/sY6vv3aRzz697HChxqSkSgh6gFj3uCa6baXtluBY1xiPfv8s799bxV8/cICqwhzqyvL42sev5+DWEj7znZOcH5pMt5m25dHvn+Vkzzhf/ui1PHhwM3lZHu7aXckTnzzE8OQcn/7WcfQKfMlhfGqe337ybWpKcvjnXznEnupCinIz+ZN7d/Ort9TzxOFLfPdEb7rN1KyRVAnBM8AvRrOHbgDGlVJ9wPPAnSJSHB0kvjO6zfSEwopHvn2CioJsHv3QXlwxYXCmx8X/fvAAbpfwp/9+WjdGSeDtS6N8/bWL/NKNW3nvzoorPttTXcgf3bODH7X6+f6p/jRZaG/+8gdnGQrO8b9+4QBFuZlXfPYHd21nX00hn//3FoKzC2myULMeEpU++g3gNWC7iHSLyCdE5NdE5NeiuzwLdALtwN8Dvw4QHST+AnAk+vN5Y+DY7Hz3RC9n+wP80ft2kp+d8Y7PKwqy+Z3bm3j5nJ/XOofTYKG9+Z8vtFKal8nv3blt2c8/dsMWdlTm8+j3z7IQCqfYOnvTNTLFk2908eDBWvbWvHNg2ON28af37mYwMMvf/6gzDRZq1ktChEAp9aBSqkoplaGUqlFKfVUp9X+VUv83+rlSSv2GUqpBKbVXKXU05rtfU0o1Rn/+IRH2JJtQWPHXL7axvSKf9++tWnG/j92whTJvFn/7ckcKrbM/Ry6M8OO2IX7t1gbyspbPd/C4XfzuHdu4NDLF9072pdhCe/PXL7bhdgm/eVvTivsc2FzM7TvLefy1C0zN6ajA7FhmsNhMvHxukA7/JJ+6rfGKLqGlZGe4+eS7t/LjtiFOdo+n0EJ789Ufn6c4N4OP3bBl1f3u2FlBgy+Pv325Q3fPJYjh4CxPH+vlF66vpaJg9RTpX7u1gbGpeZ58o2vV/TTpRwvBBnji8CV8+Vncvafyqvv+p0Obyclw889vLFsGXLNO+sdneOHMAB9priUn073qvi6X8Ml313O2P8Bbl8ZSY6DN+dbRbuZCYX7xXauLMEBzXQnXbi7in16/qIU4AYTCilA4OddRC8E66Rmb5qVzgzxwfe2aJi3lZ2fw/n1V/PvxPh0iJ4BvHukiFFZ89NDa5pL87DWbyMlw8y9HtVcaL+Gw4onDF7mhvoTG8vw1feeB6zfTOTTJW5dGk2yd/flp+xCH/uJFzvRNJPzYWgjWyb+93YNSrGuy2EeaawnOLvC9E7qvOh6UUvzr293c2FDKltK8NX3Hm+WJCnGvFuI4eevSKN2j0/zC9Wu/99+3ryoqxN1JtMwZfPdELzPzIbaWre3eXw9aCNbJ9070ce3monXNWr2+rpgtpbk8c1znVcdDS98EF4an+NlrNq3rez9/XQ2TcyF+eGYwSZY5g++e6CPT4+KOXVfvEjXwZnm4Z28l3zvRx+xCKInW2Zu5hTDPnx7gjl0VZGes3iW6EbQQrIPzQ5O09E3wvlUyhZZDRLhnTxWvdQwzNjWXJOvsz/dO9OF2CXftXntDBJG+6jJvFs+d0hHZRgmFFc+e7ONntvvwrpCptRIf2FdFYHaBV9t1GvVG+Wn7EOPT83xg3/ranrWihWAdPBtNQ1yvEES+U8lCWPFCy0CizXIESim+d7KPGxtKKcnLvPoXYoiIRwUvnfUzPae90o1w5MIIg4FZPrBvfdEYwE2NZeRneXhOT+7bMP9+opeCbA/vbkpOeR0tBOvg2ZORbqFNRTnr/u7e6kKqi3L0w7BBWvomuDg8teq8jdW4Z08V0/MhXmn1J9gyZ/DcqX6yPC5u21G+7u9medzctrOcH7T068l9G2AhFOaHLQPcubuSTE9ymmwtBGtkYGKG070T6+ofjUVEuGNXBa92DDMzr73S9fLyuUgDftvO9TdEADfUl5Cf7eGls3qcYCO8fG6QGxtKV5zAdzXu2l3J6NQ8x7rGEmuYA3i7a4yJmYUNifBa0UKwRn4U9SRv3bbx0OzWbT6m50McvaBT6dbLK61+dm8qoDx/Y+s8eNwubm4s45VWv85pXycXhia5MDzFe7ZvvCG6qbEMt0sWnyPN2nn53CBul3BTY1nSzqGFYI280urHl5/Fzqq15U8vx6H6EjI9Ll5p1V7pepiYmefNi6NxiTBEhLh/Yoa2wWCCLHMGryTACSrMyWB/bRGvtA0lyizH8PI5P9dtLqYw5501zRKFFoI1EAorftw2xK3bfIhsfLGN3EwPh7aW6H7qdfJq+xChsIrLIwW4JdqQvXJOX//18PK5QepKc6mLM3/9liYfJ7rHGJnUmXNrZTAQ6ZK+dXty12DRQrAGjnePMT49H7dHCpGHoXUgSO/YdAIscwavtPrJz/JwYHNRXMfZVJRDY7mXH7VpIVgrswshXuscjluEAW7ZVoZS8JN2HRWslR+3Rq5VItqe1dBCsAZejd64Nyegj87wSvXDsHZe7RjmhobShKxDfEuTj8PnR/SA/Ro53jXOzHyYGxtK4z7WvpoiinIz+LGOiNfM653DFOVmsKuqIKnn0UKwBg6fH2FHZT7F68xfX46mci/FuRm8cd4Syy6knf7xGS4OT3Foa0lCjveuhlLmFsIc19kra+Jw5zAicDAB19/tEg5tLblifWnN6hw+P8LBupJVqxwnAi0EV2EhFObNi6MJeRAgUhHz4NYSDp/XsyzXwhsXIo3Goa3xe6QQKfchghbiNfLGhRG2V+S/YxWyjXJwaymXRqboG9ddo1ejb3yaSyNTHKpPzL2/GolaoexuETknIu0i8sgyn39JRI5Ff1pFZCzms1DMZ88kwp5Ecrp3gqm5UMKEACKNWtfItB4nWAOHO4fxZnniytaKpSg3k+0V+dorXQPzUScoUdEYsHgsLcRXx7hGibz+KxG3EIiIG/gycA+wC3hQRHbF7qOU+l2l1H6l1H7gfwPfifl42vhMKXVvvPYkGuOfcbAucf+Mg/phWDNvnB/hui3FeBIwPmBwaGsJb14cZV7Pcl2VUz3jTM2FEuqR7qwqwJvl0ff+Gni9c4T8bA87kzw+AImJCA4C7UqpTqXUHPAkcN8q+z8IfCMB500Jh8+PsLUsj/KrrMa0HnZWFZCf7dHdQ1dhODhL22CQQ/WJ9YgO1ZcyPR/iVI9eNW41jMb6+gQ6QW6X0FxXrIVgDRw+P8z1dSW4kzw+AIkRgmogdtWP7ui2dyAiW4CtwH/EbM4WkaMi8rqI3L/SSUTk4eh+R/3+1GQdhMOKIxdGEhoNQORhuL5OD5pdjSPRGdiJDo2Nhk03Rqtz+PwI9b48fPlZCT3uwa0ltA0GGQ7OJvS4dsIfmKXTP5mSbiFI/WDxA8BTSqnY3L0tSqlm4KPAX4lIw3JfVEo9ppRqVko1+3zJzak1aBsMMj49z/VJ+Gdcu7mITv8k41PzCT+2XThyYYQsj4u91UUJPa4vP4stpbm8rZevXBGlVCRJIsFOEEDzlsgx9fVfmTcvRpyg5iRc/+VIhBD0ALFLFtVEty3HAyzpFlJK9UR/dwIvAwcSYFNCONYV+Wdct6U44cfeXxs55vHusYQf2y4c6xpjb3VhUiou7q8t4u0uXfNpJS4MTzE+PR/3JL7l2FtdiNslugDdKhzvHiPDLezelPzxAUiMEBwBmkRkq4hkEmns35H9IyI7gGLgtZhtxSKSFX1dBtwEtCTApoRwrGucgmwPdaVrX41sreyrLUREe0UrMR8Kc6pnnGtqi5Jy/AO1RQxMzOo0xhUwnKBkXP+cTDfbK/K1EKzC8a4xdlYVJGU1suWIWwiUUgvAp4DngTPAt5RSp0Xk8yISmwX0APCkurL0407gqIgcB14CHlVKmUYIjneNcU1tUVz1hVaiIDuDRp938YHTXMm5/gCzC+GkCcH+zZGI7JgW4mU53jVObqabpjUuUr9e9m8u4njXGOGwrgS7lFBYcaJ7nGtqilJ2zo0VF1+CUupZ4Nkl2z675P2fLPO9V4G9ibAh0UzPhTg3EODXdy47ZJEQDmwu4oWWAZRSSREbK2N0me1P0sOwsyqfTLeLt7vGuGeDi93YGaNbLlkZK/tri/jnw5foHArSmCSxsSqd/iDB2YWkOUHLoWcWr8Dp3nFCYZVUVd5fW8zo1DwXh6eSdg6rcrxrjOLcDGpL1r8a3FrI8rjZXV2gI4JlmFsI09I7wf4kNkQHosd+S1//d/B2tMssmdd/KVoIVsDov9xXW5i0cxj/aD1o+U6Od40nrVvOYH9tESd7xvXyiUs40zfBXCh53XIADT4v+VkePU6wDMe7xsjP8lAfZ9nv9aCFYAWOd49TXZSz4RWx1sK2Ci+5mW7tlS4hOLtA62Ag6X2k+2uLmJ6PdAFqLrPYLZdEIXC5hH21hfreX4ZjXWPsqy1MeqG5WLQQrEBkoDh50QBElk/cs6mQk3qG6xWc7B5HqciAYjIxGroT3fr6x3KsawxffhZVhclzgiBy/c8NBHRJ8Bhm5kOc7Q+ktFsItBAsy8jkHJdGplIyar+7uoAzfQFCOntiEcMjTfb131ySS362h9O9WghiOdY1xjU1ye2WA9izqZBQWHG2X0dkBqkYm1wOLQTLsNgQpUCVd28qZHo+xPkhvY6uwYnuMWpLcihJwPoPqyEi7Koq4FTPRFLPYyUCM/N0+ie5pia50TDAnurIObQQX8aITvdpIUg/Lb2RhiEVs/r2VEfOoRujy5zunWBvdfIbIog0Rmf7J/SAcZQzfRHvfE8Krn9NcQ4F2R5O9+p73+B07wRl3kwqChJb3+lqaCFYhpbeCbaU5pKfnZH0czX4vGR6XNorihKYiaTTJntpPoPdmwqYmQ/TOTSZkvOZnZbofZgKJ0hE2LWpgNN6jGyRlt4JdlYVpHxekRaCZWjpm0hZQ5ThdrGzMl9HBFEMj3RXimqs7N6kuydiMTzSRFccXYndmwo52x/QERmR+Rttg4HFezKVaCFYQnB2gQvDkylZDMJgd3Uhp3vHubL6hjO57JGm5mFo8OWR5XFpIY7S0pdaj3RPdQGzC2E6/DoiaxsMMB9SKXOCYtFCsIRz/RMoRcoiAoiE4RMzC3SP6gJoLX0TlOZlUp4ij9TjdrGjqkBHBEQ90oFgSj1SHZFdJpVjk0vRQrAE45+RSlXeox+GRU73TrBrU2r7SPdsKuB074TjI7L2wSBzoXBK7/36skhEpgeMI/d+ToabutLUzSg20EKwhJa+AEW5GUmfTBPL9sp83C5xfPeE4ZGmOjTevamQwMwCXSPOjsha+qJOUAqjYSMi08uGGt1y+SlZmnIpWgiWYAwUp9Ijzc5w01TudXxE0OGPeqQpbIjgciju9Ot/unecnAw3W1NY4wYiEVlLn7MjsnBYcSYaDacDLQQxLITCnI0OlqWaXVUFixkzTiVdfaRGRGZ4xE6lpXeCHWnwSHVEBt2j0wRmF9KSMQRaCK7gwvAkswup90gBtlXm0z8x4+g1jE/3TpCd4WJrmTel583OcFNXmuvoUgdKqZSmTceyvTKyHoGTi/8Z0Wg6rj8kSAhE5G4ROSci7SLyyDKff1xE/CJyLPrzyZjPHhKRtujPQ4mwZ6OcTsNAsYHxMJztd65X2tI3zo7KgrT0ke6oLOCcg4Wge3SawMxCWu/9cw6+98/0TeCSy9ci1cQtBCLiBr4M3APsAh4UkV3L7PpNpdT+6M9Xot8tAT4HHAIOAp8TkcSvFL9GWvomyHS7aPCl1iMF2OFwr0gpxbn+ADur0vMgbK/M59LIFJOzC2k5f7oxRHBHZeqFwJvloaY4x9ER2bmBAFvL8lK2RvFSEhERHATalVKdSqk54EngvjV+9y7gBaXUiFJqFHgBuDsBNm2Ilt4JmioiJR9STWVBNgXZHsc+DP7gLKNT82yrSJ8QALQNOrP4n+GAbKtIvRMEEUfIyRFZ60AwbdEAJEYIqoGumPfd0W1L+ZCInBCRp0Skdp3fRUQeFpGjInLU7/cnwOx30joQSNs/Q0Qc3T3R2h9pgLenSQh2OLx7onUgQHVRTkrqay3H9sp8OocmmV1w3toEM/MhLgxPps0JgtQNFv87UKeU2kfE6398vQdQSj2mlGpWSjX7fL6EGzg+Nc/AxGzaGiKIPAyt/QFHptEteqRpEuLa4lxyMtyOjcjO9QfSFg0AbK8sIBRWdAw6r9RE+2AQpdLnBEFihKAHqI15XxPdtohSalgpNRt9+xXgurV+N1W0DhqhcXqFIDC7QM+Y89LoWvsDlOZlUuZNbfldA5dL2FbhdWRENh8K0+mfTJsIw+VGsNWBY2TGPZfO658IITgCNInIVhHJBB4AnondQUSqYt7eC5yJvn4euFNEiqODxHdGt6UcM/wzLndPOPBhGAikVYQhIsROvPYXhyeZC4XT6pHW+/LIcIsjI7LWgQCZHhdbSnLTZkPcQqCUWgA+RaQBPwN8Syl1WkQ+LyL3Rnf7LRE5LSLHgd8CPh797gjwBSJicgT4fHRbymkbCODN8rAphaUllrJtMYXUWQ+DUoq2NI7PGGyvLGB4cg5/YPbqO9uIc9HxmXQKcUY0W8+JYzTnBgI0+rx43Omb1uVJxEGUUs8Czy7Z9tmY158BPrPCd78GfC0RdsTDuYEATRXelC8IEUtBdgbVRTmO80p7xqaZnAulPSIwIrLWgUDK6vGbgXMDAVwCjeXpGyOASER25Hxa/MC00tof4FB9aVpt0DOLo7QNBNlWnt6GCJzZPWH0C2+vTH9DBM6LyFr7A9SVpi+H3WB7ZT694zOMTztndv3EzDy94zNpd4K0EABDwVmGJ+fSOj5gsK0iP1J8bcE5KzYZXRONaRbiMm8WZd5Mx3VPtJpgfAYuDxi3OWjAuM0kTpAWAi57pOlMnzPYUZnPQljROeSciU2tAwGqCrMpzElPDnssTovIFnPYTeAEOTEiM8P4DGghACKhMaQ3j9dg26JX5BwhiOSwp//aQ+T6tw4ECYedMZejfTBIOM057AbVRTnkZ3kcJcStAwHyMt1UF+Wk1Q4tBEDrYJDCnAxTDBDW+/JwSeQBdQILoTDt/vROr4+lqTyf6fkQvePOmMthlvEZiMyubyj3Oubeh6gTVJmf1iQV0EIARCKC7RXp/2dApCRybUmuYx6GiyNTzC2ETRMRGJkzTrn+5wYCZLpdbEnD8ojL0VTupd3vjGsP0bI2Jrj3HS8ESilao6mjZqHJQV6RmbrlIHLtwTlC0NofiE7mMkdT0FjuxR+YdcS6HItJKia4983x308jAxOzTMwsmKZrAqCh3EvnUJCFkP0zh1oHgogJctgNivMyKc3LdI4QDARN0RAZGA5Zu9/+4wSGE2SG6+94ITD6SJtMMIfAoKk8n/mQ4uLIVLpNSTptgwFqinPIyUxvDnssjeVeR5SjnpqL1LVqMokIAzT6nJMs0eE30qbTf/21EJgoddTASf3UHf5JGtOwENBqNEa75uxeBbbTH6n0aYaGyKC6OIfsDJdj7v28TDcVBelPUnG8ELQPBinJy6Q0TVUvl8MpQhAOKzr9wbSsCLcaTeVexqfn8QftXXPI8EgbTCQEbpdQX+aMiKzDH6ShPL1lbQwcLwQd/qDpPFKj+J3dhaBnbJrZhbCpGiK4PMPZ7te/YzCIS2BLafqqXi5HU4UzkiU6Bs3jBGkh8E+ariGCiJfWNmjvATMz9ZHGsjhgafPGqMM/yeaSXLI85hmfAWj0eSOFCG28fvTk7AK94zOmufcdLQQjk3OMTM7R4DNHDnUsTeX5dAxO2nqGa0e0j9osXpFBeX4W+VkeBwiBeTzSWAwhNsYw7Ejn4r1vjrbH0UJgxj5Sg8ZyL9PzIVuvVtY+GKQ4N4OSvMx0m3IFIkJjhdfWmSuhsKJzyJzRsOEl2zkiXmx7TCLECRECEblbRM6JSLuIPLLM558WkZbo4vUvisiWmM9CInIs+vPM0u8mk46ox2e2MQJwRveEWT1SiNwTdp7h2jM6zdxC2DQeaSxbSvPwuMT2977bJWw2yfhM3EIgIm7gy8A9wC7gQRHZtWS3t4Hm6OL1TwH/PeazaaXU/ujPvaSQDn+QLI+LTWku+LQchjjZ+WEwY8aQQVOFvWe4ms0jjSXD7aKuLM/WmUMd/qCpxmcSEREcBNqVUp1KqTngSeC+2B2UUi8ppYzZUa8TWaQ+7XT4J9lalofblf70raUU52VS5s20bXg8NjXHUHCOhnLzeaQQk8Jr0xmuhoNhRiGASApvh52FYHDSVNFYIoSgGuiKed8d3bYSnwC+H/M+W0SOisjrInL/Sl8SkYej+x31+/1xGWzQ4Q+aZtR+ORptXHPIrAPFBsZMc7uOE3T4g5TmZVJssvEZg8ZyLxeGJ5ldCKXblIQTCivOm2x8JqWDxSLyMaAZ+MuYzVuUUs3AR4G/EpGG5b6rlHpMKdWslGr2+Xxx2zIzH6JrZMq0DRFcLnVgxxmuZu6agEhtfDvPcDXz+AxE7v2wggtD9iuz0j06xVwobKrrnwgh6AFqY97XRLddgYjcDvwxcK9SanHKplKqJ/q7E3gZOJAAm67KheFJwsqcGUMGTeX5BGYW8AfsN8O1wx8k0+2itsQcg2VLcbmEBp99Z7hG5s+Yp2tiKXbOHDJjt1wihOAI0CQiW0UkE3gAuCL7R0QOAH9HRAQGY7YXi0hW9HUZcBPQkgCbrkrHoLnyeJfj8sNgv8aoY9C84zMGdu2auzx/xjwN0VIafF7Epgs0XY6GzdP2xC0ESqkF4FPA88AZ4FtKqdMi8nkRMbKA/hLwAv+yJE10J3BURI4DLwGPKqVSIwTRf0Z9mXkfBjvXHIrUWTHPg7AcxgzXqTl7zXDtNHm3HEQXaCrOta0TVObNpCjXPOMznkQcRCn1LPDskm2fjXl9+wrfexXYmwgb1kuHP0h1kbnKHy/FmOHaYbN89tmFEJdGpvjAvqp0m7IqhhB3+ifZU12YZmsSh9nHZwwabZo51OEPUm+ya+/YmcVmzxgC+67heml4ilBYmb4harBpRNY+GCTT46K62HzzZ2Jp8OXROTRJyGZlVszY9jhSCMJhFc3jNdc/YzkafPYTAqt4pHWlkTEMu0VkHf5J6k0+PgORiGBuIUzPqH3KrIxMzjE6NW+6e9+RQtA3McP0fMj0fdQQeRgGA7NMzNhnhqsxh6DeRINly5HpcbGlJNeWQmzmbDkDO07qu5wxZK5735FC0GHC9K2VMB4GO/WVdgwGqSrMJi8rIUNUSaXe57VVRGCF+TMGho1Ghp8dMGs07EwhMOk/YzkMz8FOXqkZ+0hXorHcy/mhSRZC4XSbkhAuDk9F5s+YzCNdjqLcSJkVW937g5H6ZtUmq2/mWCEoyPZQ5jVP+tZKbC7JJdPtsk0lTKVUZDKTBUQYIg3mfEhxacQeM1yt5ARBJCKzy70PlzOGXCYbn3GmEAxO0miStUKvhsftoq4s1zbh8WBgluDsgiU8UojpmrPJIilGF6PZx2cMjEl9dimz0uGfNGU07EwhMHmdlaU0ltunn9qM0+tXw24ppMb8mdxM84/PQGRS3/j0PMOTc+k2JW5m5kN0jU6Z0glynBBMzMwzGJi1RNaEQYPPy0WbVGI086pwy1GQnUF5fpZthKDdH7RMNACX7xM7JEucH5pEKXM6QY4TAitlDBkYlRgvDlu/n7pjMIg3y0N5fla6TVkzdonIjPkzZuyaWInLKaTWv/5mHp9xnhCYbNHotWDcOHbwSiMDxXmWGJ8xaPBFSh1YvZ+635g/Y8KGaCWqCrLJyXDb494fnEQEtpaZr+1xoBAEyXALm01a/ng56m2UQmq18RmIeKWBWeuXAzezR7oSLpfQUJ5ni8F6M9c3c54QDAapK83D47bOn56b6aG6KMfy3RPB2QX6xmcsMz5gYJcqsIvdohaYUR9Lo88exefMPH/GOq1hgrCiRwr2qI1/3uTLU67EYtecxYW4wz9JfrYHn9c64zMQuf49Y9NMzlq3HHg4rOg08fwZRwnBfCjMxeEpy3lEEO2n9gcJW7gSoxHRNFrs+lcUZOHN8ljeKzWcICuNz8DliOz8kHW7h/pMPj7jKCG4ODzFggXKHy9HY7mXmfkwvePWrcTYPhjE7RI2l1hLCESEBl+e5SOC9kHrRsNg7a45sxabM0iIEIjI3SJyTkTaReSRZT7PEpFvRj8/LCJ1MZ99Jrr9nIjclQh7VsKKg2UGdngYOvxBtpTkkumxnv/RUO619Ozuy/NnzNkQrcYWG5QDvzw+Y862J+4nUkTcwJeBe4BdwIMismvJbp8ARpVSjcCXgC9Gv7uLyBrHu4G7gb+JHi8pLC5PaVJVXg07FJ8z48pMa6Wx3Ev/xAwBi5YD77To+AzYoxx4hz9IYU4GpXnmrG+WCNfsINCulOpUSs0BTwL3LdnnPuDx6OungPdKpKPyPuBJpdSsUuo80B49XlLoGJyksiCb/OyMZJ0iaZR6syjOzbBsGt1CKMyFIWuOz0BMSWSLXn/DIzVr1srVqLf4Ak1GxpBZx2cSIQTVQFfM++7otmX3iS52Pw6UrvG7AIjIwyJyVESO+v3+DRmak+niurriDX3XDFh5Ddfu0WnmQmFLeqRg/XUhOvxBPC5rzZ+JpbHcy4Vh65YDNyZSmhVrVJ4ClFKPAY8BNDc3byh15s/u35tQm1JNY7mX508PpNuMDXE5Y8iaQrC5JBePSyw7YNzhD7KlNJcMC82fiaWx3LtYDtxq3Yvj0/P4A7OmdoIScVf0ALUx72ui25bdR0Q8QCEwvMbvaqI0+LyMTM4xYsFKjIsD9WXmfRhWI8Ptoq4sz8IRgXlz2NeC4U1bsWvOCkkqiRCCI0CTiGwVkUwig7/PLNnnGeCh6OsPA/+hIoVbngEeiGYVbQWagDcSYJMtWazEaEGvtGNwkjJvFoW51hufMWi06CIp86EwF4YmTZuxshasXA7c7BlDkAAhiPb5fwp4HjgDfEspdVpEPi8i90Z3+ypQKiLtwKeBR6LfPQ18C2gBngN+Qyll/VrLSaLRwsXn2v1BU/eRroWG8jwuDk8xt2CtfupLI9adP2NQkJ1BRYE1y4F3+CfJdLuoLTbX8pSxJGSMQCn1LPDskm2fjXk9A/z8Ct/9c+DPE2GH3akuyiE7w2W5h0EpRftgkPfvq0q3KXHRWO4lFFZcGpmksTw/3easmQ6TT2ZaK8bseqvR4Q9SV5Zr6vpm5rVM8w5cLqG+zHoPw8jkHOPT85b2SMG65cAXS6+buGtiLRhZc1YrB26F+mZaCCyGFYvPWXENiOWwrhAEKc/PosCC82diafBZrxz4fCjMpeEpLQSaxGJUYpyes85QihWyJtZCXpaHTYXZlstcsYJHuhasWGZlsb6ZySdSaiGwGI3lXpSCziHrPAwdg0GyM1xUF5l3sGytNFgsIjPGZ6xYVmUpVly28nKxOXMLsRYCi2FFr6jdH6S+zIvLZc7p9evBGLC0Sj+1PzhLYGbBshP5YinPt145cKtEw1oILEZdWS4usVapgw5/0PIDlQYN5V6m5kL0jc+k25Q1YVRMtYMQiEgkIrNQRNAxGKSqMJu8LHMXcdBCYDGyPG42l+Rapp96Zj5E9+j04hwIq2O1uRztFvFI10qDL88y1x6sMz6jhcCCWClzqNM/iVLWWyd3JRotNru7YzBIbqabqsLsdJuSEBrLvQxMzFqiHLhSig7/pCWiMS0EFqTB5+X8kDUqMbZbvNjcUsq8mRRkeywjxFZdnnIlGi1UDnxgYpbg7IIl0qa1EFiQhnIvc6Ew3aPmX7ayYzCIS6Cu1PwPw1oQkcjEJgtFBFZoiNZKg4XKgS8OFFvACdJCYEGslDnU7g9SW5JLdkbSFp5LOQ0+L+0WWLZycnaB3vEZ20RjAFtKcslwW6McuPF8WmF8TAuBBVmc4WqBh6HDogumr0ZjuZeh4CzjU+bup7by8pQr4XG7qCu1xoBxhz9IfpYHX35Wuk25KloILEhhTga+/CzTh8ehsKJzyNwrM20Eq0xssvpiQCthleJz7YORtGkrjM9oIbAoVqiN3zM6zdxC2JYNEZi/n7p9MIjbJWwutebylCvRWO61RDlwq6SOghYCy2KkkJp5hmu7PwDYq2sCoLYkl0y3y/ReaYc/yOaSXLI89hmfgUgqslEO3KxMzMwzMDFrGSdIC4FFafDlEZhZwB80byVGY1ar3YTA7RK2lpm/n9pKHul6aPRF1oIw8/XvtFjF3biEQERKROQFEWmL/i5eZp/9IvKaiJwWkRMi8gsxn/2jiJwXkWPRn/3x2OMkjIVRzPwwdPiDlOZlUpyXmW5TEk6jyUsdLITCnB+atM1EvliMAnqmvvctsDxlLPFGBI8ALyqlmoAXo++XMgX8olJqN3A38FciUhTz+R8opfZHf47FaY9jaLRAPrUxWGZHGsq9dI1MMTNvznLgXaPTzIeUJVIX14sVyoG3+4NkuIXNJdYYn4lXCO4DHo++fhy4f+kOSqlWpVRb9HUvMAj44jyv46koiFZiNPHDYNeuCYiE/GEFF4bNef3bLeaRrhezlwPvGAyypTSPDBMvTxlLvFZWKKX6oq/7gYrVdhaRg0Am0BGz+c+jXUZfEpEVE25F5GEROSoiR/1+f5xmWx8RMXUBruHgLKNT85YZLFsvZp/UZ5XyxxvFmN1t1mSJdn/QUtHYVYVARH4oIqeW+bkvdj8V+Y+s+F8RkSrg/wG/pJQy8r4+A+wArgdKgD9c6ftKqceUUs1KqWafTwcUYG6vyC7LU65EfZkXkcsD4majYzCILz+LwhxrL0+5Eg0+85YDX1ye0kLjM1ctkq2Uun2lz0RkQESqlFJ90YZ+cIX9CoDvAX+slHo95thGNDErIv8A/P66rHc4DT4v33mrh8DMPPkmW492cXq9TSOCnEw31UU5ph0wtppHul5iI7JNJlv5bnF5Sgtd/3i7hp4BHoq+fgh4eukOIpIJ/CvwdaXUU0s+q4r+FiLjC6fitMdRGA9DpwnHCTr8keUpNxWa6yFNJI3lXlMO1iulIqU9LOSRrpfFSX0mFGIrOkHxCsGjwB0i0gbcHn2PiDSLyFei+3wEuAX4+DJpok+IyEngJFAG/Fmc9jgKM/dTtw/aZ3nKlWjweekcChIOm6uf2h+cZWJmwVIe6Xop82ZSmJNhynvfEKd6C13/uNZPU0oNA+9dZvtR4JPR1/8E/NMK378tnvM7nc0luXhc5qzE2OEPcu3md0wrsRWN5V5m5sP0jE1Ta6I0QTstT7kSZi4HbixP6TX58pSxWCO3SbMsGW4XdWV5puuemJ4L0TM2bWuPFMxbBdZuy1OuRCRrzpzdola79loILI4Zi891DgVttTzlSph1Up/dlqdcCTOWA1dK0T4YtFw0poXA4pixEmPbQKRh3FaRn2ZLkktJXiYleZmm655oHQjQVJFvifLH8WDGiKxnbJrJuRBNFVoINCnEjJUYzw0E8LjENstTroYZJ/W1DgTZZjGPdCOYMSKzqhOkhcDimLESY9tAgHpfHpke+99ejSab1DcyOcdQcNZyDdFGqCnOJdPjMlVEcG4gUnp9W7m1rr/9n1SbY8ZKjK0DQZoc0BBBpHtidGqekcm5dJsCRLqFALZV2v/6u11CvcmSJVoHAlQUZFGYa64JnldDC4HFMVslxqm5BS6NTFnOI9ooDSaby9FmCIHF+qg3SoPJyoG3DQQtGY1pIbABZqo5ZNixvdIZDVGjyWa4tg5EFkyvLLB3xpBBo8885cDDYUXbYIAmCzpBWghsgDGxxgwzXFujg2VO6RqqLsohO8NlGiE+NxBgW6X9M4YMGsq9pikH3jU6xcx82JLRmBYCG2BUYuyfSH8lxtaBAJluF1tMNNM2mbhcQn2ZOSIypRRtAwFLNkQbxYjIzHD9rewEaSGwAWaqOdQ6EKCh3IvHIgtyJIIGk5Q6GArOMTo1b8muiY1S78szTTnwVguPzzjnabUxZhKCyGCZ9R6EeGj0eekZm2Z6Lr391EZDtN0BGUMG2RluaorNUQ68dSDApsJs05WEXwtaCGxAaV6kEmO6vdLAzDw9Y9OWzJqIh8ZyL0qlf8DYEAKrzWqNl0afOcqBWzltWguBDTAqMaY7ImgbtOasyngxaiqlXwiCFOVm4POuuOKrLTFDOfBQWNHht240rIXAJjT60t9P7bQcdoO60jxckv5SB60DAbY5oMbQUmLLgaeLi8OTzC2ELesExSUEIlIiIi+ISFv097IF6EUkFLMozTMx27eKyGERaReRb0ZXM9NsgEglxjnGptI3w/Vcf2RVstpiZ2QMGWRnuNlSmrdYXiAdKKWiQuAsEYbLY2Rtg+m7/pcHih0oBMAjwItKqSbgxej75ZhWSu2P/twbs/2LwJeUUo3AKPCJOO1xLEb3RDq7h4zJNHZelWwldlTmc7Y/fQ3RwMQsgZkFyzZE8WAMjp/pS6cQWG95yljiFYL7gMejrx8nsu7wmoiuU3wbYKxjvK7va65kR2UBAGfS2BhFyh9b80GIl51VBVwcniI4u5CW8xvRiJNSRw3yszOoLcnhTN9E2mw4NxCgpjiHPAutShZLvEJQoZTqi77uBypW2C9bRI6KyOsicn90WykwppQynpxuoHqlE4nIw9FjHPX7/XGabT+qCrMpzMmgpTc9D8PI5BwDE7PscFDqYiw7qyJCfC5NQmw0gjurnHn9d1QWpFUIzvRNLN4DVuSqQiAiPxSRU8v83Be7n1JKASsN229RSjUDHwX+SkQa1muoUuoxpVSzUqrZ5/Ot9+u2R0TYWZWftofBOO+uqsK0nD/dGA1wOq//psJsinKdOcy2s6qA80OTaak5NDW3wPmhSUsLwVXjGKXU7St9JiIDIlKllOoTkSpgcIVj9ER/d4rIy8AB4NtAkYh4olFBDdCzgb9BE2VnVQFPvtFFKKxwp7if3ukeaXVRDvnZnrQKgZUbonjZVZVPWEUismtqi1J67nP9AZSCXRa+/vF2DT0DPBR9/RDw9NIdRKRYRLKir8uAm4CWaATxEvDh1b6vWTu7qgqYng+lpQBXS+8EFQVZlDosh91ARNhZWZCWAeOZ+RAdfmt7pPFi/O3pEGJjkNrJQvAocIeItAG3R98jIs0i8pXoPjuBoyJynEjD/6hSqiX62R8CnxaRdiJjBl+N0x5Hk86HocXhHilEoqGzfRMpn9jUNhAkFFbs2uTc619bnEtepjtNQjCBN8tDTXFOys+dKOIa4lZKDQPvXWb7UeCT0devAntX+H4ncDAeGzSXaarw4nEJZ/om+MC+TSk77+xCiPbBID+zozxl5zQjO6sKmJwL0TU6xZYUrtd8uVvOuULgcgk7qgrSkkJ6pm+CHZXWTpvWM4ttRJbHTYPPm/LMofbBIAthZenQOBHsSFNE1tI3QW6m2zGlv1diZ1U+Z/oniPQ6p4ZwWHG2P2D5aEwLgc3YtSn1XpFxPid7pADbK/JxSeonNrX0TbDd4h5pIthRWUBgZiGlpSa6R6cJzi5Y/t7XQmAzdlbl0z8xw2gKF1Nv6Z0gO8PF1rLUdYeYkZxMN3VleSmNCJRSnOmbcHw0BrFjZKkT4pa+8SvObVW0ENiMdAwYn+mbYHtlQcpTVs3IzqoCzvSn7tr3jE0TmLG+R5oIdlTmI5Lae7+lL4BLItGgldFCYDOMBqElRQ+DUoqWvgl2OXT+wFJ2VRXQNTLNxMx8Ss6nu+Uuk5flYUtJbkrHyM70TbC1LI+cTHfKzpkMtBDYjDJvFuX5WSl7GHrHZxifntddE1H2VEdmVp/qGU/J+U73juMSHFvaYym7qws5maJrD3C6Z5xdm6w/m14LgQ3Zk8KH4WT3GAB7a4pScj6zszcqBCe7U3P9T3SP01jutWyxs0RzTU0hPWPTDAdnk34uf2CW3vEZrqnRQqAxIftqCmn3B1NSCfN49zgel2iPNEpJXia1JTmcSIEQKKU40T3O3uqipJ/LKhjXIhWOkBH1GeJvZbQQ2JBraopQKjXdEye7x9lRlU92hrX7SBPJvuoiTvSMJf08/RMzDAVn2WcDjzRR7KmOdFGmQohPdI8jEumOsjpaCGyI0TCciHbbJIuIRzqmPdIl7K0ppGtkOukpvEZjt1cLwSL52RnU+/JSIgQne8Zo8Hnx2qBbTguBDSn1ZlFdlMPxJD8MF4enmJhZ0B7pEvYZ4wRJjshORrvl9ED9lVxTU8TJFERkJ7rHF//XVkcLgU25prYw6RHBiWhDp4XgSvakKCI70TPOtgrdLbeUvdWFDEzMMjAxk7RzDEzMMBiwT7ecFgKbsq+miK6RaUaS2D1xsnuMTI/LkevkrkZBdgb1ZcntnjC65ezSECWSy12jybv+l7vlipJ2jlSihcCmpGKc4Hj3OLuqCshw69toKXtrkpvC2z06zdjUvB4fWIbdmwpxSXLv/RPdY7ht1C2nn2Cbsre6EJHkeUULoTCnesZtkUOdDPZWF9I3PsNgIDndE293jQGR/nDNleRkutlWkZ/UiODtS2Nsq8i3/IxiAy0ENiU/2j1xPNpgJJqz/QGm5kJcu6U4Kce3Ogc2FwHw1sWxpBz/zQsj5Ga69fyNFbimpohjXWNJWSRoIRTm7UujNNvo3o9LCESkREReEJG26O93XBkR+RkRORbzMyMi90c/+0cROR/z2f547NFcyYHNxbzdNZaU+uxHL4wA0FxXkvBj24E91YVkely8eXEkKcc/enGU/bVFeHS33LJcV1fM+PQ8Hf5gwo99biDA5FyI5jotBAaPAC8qpZqAF6Pvr0Ap9ZJSar9Saj9wGzAF/CBmlz8wPldKHYvTHk0M19cVMzI5R4c/8WsYH704SlVhNtVF1l2eL5lkedxcU1PIkQujCT92cHaBM30TtvJIE831UQclGdf/zYuRY1672T7XP14huA94PPr6ceD+q+z/YeD7SqmpOM+rWQOGt25474nkzYujXKcbolW5bksJp3vHmZ4LJfS4x7vGCCu4TkdjK1JXmkuZNzNp935FQZal1yheSrxCUKGU6ou+7gcqrrL/A8A3lmz7cxE5ISJfEpGslb4oIg+LyFEROer3++Mw2TnUl+VRmpfJGwl+GHrGpukbn9Ee6VW4vq6Y+ZDieIKzV45eGEXk8jiE5p2ICM1bSjh6MfERwdELozRvKUHEPutvXFUIROSHInJqmZ/7YvdTkY7oFTujRaSKyCL2z8ds/gywA7geKAH+cKXvK6UeU0o1K6WafT7f1czWEH0Y6oo5muDw2AiNr9uiPdLVMCKmNxPcGB29OML2inwKsjMSely70VxXzKWRKQYTOLGsf3yGnrFp2yVJXFUIlFK3K6X2LPPzNDAQbeCNhn5wlUN9BPhXpdTiih1KqT4VYRb4B+BgfH+OZinX15VwaWQqobMsjYyVnXoxmlUpys2kqdzLkQRGZKGw4tilMd0ttwYWu0YTKMSGqNstGo63a+gZ4KHo64eAp1fZ90GWdAvFiIgQGV84Fac9miUc3Bp5GN44n7jG6PD5EQ5s1hkra6G5rpg3L44SSlAaY0vvBIHZhcXBUM3K7N5UQHaGK6H3/mudQ+Rlutm1yR4TyQzifZIfBe4QkTbg9uh7RKRZRL5i7CQidUAt8MqS7z8hIieBk0AZ8Gdx2qNZwq6qAnIz3QnzSoeCs5ztD3BjQ1lCjmd3bqgvJTCzwOnexExu+mnHEAA3NpQm5Hh2JsPt4rotxbzeOZywY77aPszBrSW2m00fV/1UpdQw8N5lth8FPhnz/gJQvcx+t8Vzfs3V8bhdXF9Xwk/bhxJyvFc7Ig/VTY1aCNaCIZg/aR9iXwJmAf+0fYhtFV7KC7LjPpYTuLnRxxefO8tgYIby/PiuWd/4NJ1Dk3z00OYEWWce7CVrmmV5d1MZHf5Jesam4z7WT9uGyM/22GJVplTgy89iR2U+P2mLX4hnF0IcuTCio7F1cHPUYXm1Pf6owDiGHa+/FgIHcMu2SJbVT9riS7tVSvGT9iFubCjF7bJP6lyyubmxjKMXRuOeT/DWxTFm5sM6GlsHuzcVUJybwU8SEBH/tGOIkrxMW5b10ELgAJrKvVQUZPGjOL3SSyNT9IxN64ZondzUVMZcKMzROMtNvNoxhNslHKrXA8VrxeUSbmws4ydtQ3GVWlFK8Wr7MO9qKMVlQydIC4EDEBHe3eTjp+1DcWWvvHQ2kh387iY9j2M9HNpaQqbbxSvn4ovIXjwzyIHaIj1/YJ3c3FhG/8QM7YMbrzt0uneC/okZbt1mz3tfC4FDuGWbj7GpeY51bTyn+oUzAzT48thalpdAy+xPbqaHdzWU8sKZgQ17pT1j07T0TXDHrqtN3tcs5We2lwPwg5aBDR/jh2cGEIH37ihPlFmmQguBQ3jPdh8ZbuG5U/0b+v749DyHO0e4Y1dlgi1zBnfuruDi8BRtG/RKfxhtxLQQrJ/KwmyuqS2KWwiu21xMqXfFKjiWRguBQyjIzuCmxjKeO92/Ia/05XODLISVbog2yB07I9ftB6c3JsQvtESisXqfN5FmOYY7d1VwvGuM/vH1z7DvG5/mVM8Et9v43tdC4CDu2VNJ18g0p3sn1v3dH7QMUObN4kBtUeINcwDlBdkc2Lwxr3R8ep7XO4dt3RAlm7t2RyLZF1rWL8QvRP9nt++07/XXQuAgbt9ZgUtYd/dQcHaB/zgzyJ27K2yZMZEq7tpdyYnucS4Nr68K+/dP9rEQVrxvT1WSLLM/jeVe6n15fO9k39V3XsK/vd3DtgovDT77jo1pIXAQpd4sbmwo49+O9axrCb/nTvUzPR/iQ9e+Y3K4Zh3ct38TIvDtt7rX9b3vvN1DvS+PfXp96Lj4uf3VvN45QtfI2oX4wtAkb10a4+cO1Niq7PRStBA4jJ9vrqF7dJrX1lF/5TtvdbOlNNdWKzKlg6rCHG5uLOPbb3WvWYi7RqZ44/wIH7rW3g1RKvjgdTXrFuJ/fbsHEbj/wKYkWpZ+tBA4jLt2V1KYk8E3j3Staf9Of5DXOof5oM09olTx4esiQmzUbLoa33jjEi6B+w/oaCxeqotyuKmhjKfe7F7TfJr5UJhvHuni5sYyqgrtsxrZcmghcBjZGW4+eG013z/VR9/41WsP/cNPL5Dhctmy0FY6uGt3JWXeLP7+x51X3Xd6LsQ/v3GJO3dV6rWhE8THbthM9+g0z68he+vZk330T8zwSzfVJd+wNKOFwIF84uatKAV//6Pzq+43OjnHv7zZxf0HNuHLt2f+dKrJznDz8Ru38Eqrn3P9gVX3feqtbsam5vnEu7emyDr7c8euSupKc/m7VzpWTaNWSvHVn5ynviyP92yz5ySyWLQQOJCa4lzu21/NP79xcdVl/L78UjuzC2E++e76FFpnfz52wxbyMt385fPnVtxnei7E//mPNq7dXGS71bDSidsl/Mot9RzvHueHZ1ZeUPH50wOc6B7n4VvqHZEpp4XAofzWexsJK/jzZ88s+3n7YICvv3aRn7+uhm0V9qu2mE6KcjP51G1N/PDMAK+0Ll9/6G9ebmdgYpbPvG+nHptJMB9prqWp3Mvnv3uamfl3VoSdmlvgv33/DA2+PD58XU0aLEw9cQmBiPy8iJwWkbCINK+y390ick5E2kXkkZjtW0XkcHT7N0UkMx57NGtnS2ke/+XWBp4+1svTx3qu+Gx6LsTvfPMY3mwPv3/X9jRZaG9++eY66svyeOTbJxgKzl7x2RvnR/iblzv44LXVeknKJJDhdvGn9+2ma2SaL3y35YrPlFJ84bstXBye4gv373HMcqzx/pWngA8CP1ppBxFxA18G7gF2AQ+KyK7ox18EvqSUagRGgU/EaY9mHXzqtkYObi3hD/7lBN95qxulFEPBWX7l60c53TvBFz+0L+5VnTTLk+Vx89cPHmBkco6PfeUwF4cnAfhJ2xCfePwIm0ty+ZN7d6fZSvtyY0MZv3prPU8cvsRfPHuGmfkQcwth/ux7Z/jGG1382q0NtlyAZiUknhrdiwcReRn4/egSlUs/exfwJ0qpu6LvPxP96FHAD1QqpRaW7rcazc3N6ujRd5xKswHGpub4la8f5ciFUXz5WUxMz6MU/MUH9zomLE4nP2r18+tPvMXU3AKVBdn0js9Q78vj6798kJri3HSbZ2tCYcXnnjnFP71+iYLsyKq9EzML/OK7tvAnP7vblmMDIvKmUuodvTdxrVm8RqqB2KT1buAQUAqMKaUWYravmCwtIg8DDwNs3qxTGRNFUW4m3/iVG3j6WG9kBabcTB44uJnGcl3cLBXcss3Hi793K0+8fpFLI1PsrSniPx3aTHaGO92m2R63S/iz+/fyvj1VPHO8FxF4/95N3NzknEjA4KpCICI/BJarPfzHSqmnE2/S8iilHgMeg0hEkKrzOgGP28WHrqvhQzoCSAsVBdl8+k49FpMubmws40aHr7p3VSFQSt0e5zl6gNqY9zXRbcNAkYh4olGBsV2j0Wg0KSQVQ+JHgKZohlAm8ADwjIoMTrwEfDi630NAyiIMjUaj0USIN33050SkG3gX8D0ReT66fZOIPAsQ9fY/BTwPnAG+pZQ6HT3EHwKfFpF2ImMGX43HHo1Go9Gsn4RkDaUanTWk0Wg062elrCFnzJbQaDQazYpoIdBoNBqHo4VAo9FoHI4WAo1Go3E4lhwsFhE/cHGDXy8DhhJojhXQf7Mz0H+z/Yn3792ilPIt3WhJIYgHETm63Ki5ndF/szPQf7P9Sdbfq7uGNBqNxuFoIdBoNBqH40QheCzdBqQB/Tc7A/0325+k/L2OGyPQaDQazZU4MSLQaDQaTQxaCDQajcbhOEoIRORuETknIu0i8ki67UkmIlIrIi+JSIuInBaR3063TalCRNwi8raIfDfdtqQCESkSkadE5KyInIku+2prROR3o/f1KRH5hojYbnFtEfmaiAyKyKmYbSUi8oKItEV/FyfiXI4RAhFxA18G7gF2AQ+KyK70WpVUFoDfU0rtAm4AfsPmf28sv02k5LlT+F/Ac0qpHcA12PxvF5Fq4LeAZqXUHsBNZJ0Tu/GPwN1Ltj0CvKiUagJejL6PG8cIAXAQaFdKdSql5oAngfvSbFPSUEr1KaXeir4OEGkcVlwT2i6ISA3wfuAr6bYlFYhIIXAL0bU8lFJzSqmxtBqVGjxAjoh4gFygN832JByl1I+AkSWb7wMej75+HLg/EedykhBUA10x77txQMMIICJ1wAHgcJpNSQV/BfxXIJxmO1LFVsAP/EO0O+wrIpKXbqOSiVKqB/gfwCWgDxhXSv0gvValjAqlVF/0dT9QkYiDOkkIHImIeIFvA7+jlJpItz3JREQ+AAwqpd5Mty0pxANcC/ytUuoAMEmCugvMSrRf/D4iIrgJyBORj6XXqtQTXe43Ifn/ThKCHqA25n1NdJttEZEMIiLwhFLqO+m2JwXcBNwrIheIdP3dJiL/lF6Tkk430K2UMqK9p4gIg525HTivlPIrpeaB7wA3ptmmVDEgIlUA0d+DiTiok4TgCNAkIltFJJPI4NIzabYpaYiIEOk3PqOU+p/pticVKKU+o5SqUUrVEfn//odSytaeolKqH+gSke3RTe8FWtJoUiq4BNwgIrnR+/y92HyAPIZngIeirx8Cnk7EQT2JOIgVUEotiMingOeJZBl8TSl1Os1mJZObgP8MnBSRY9Ftf6SUejZ9JmmSxG8CT0QdnE7gl9JsT1JRSh0WkaeAt4hkx72NDUtNiMg3gPcAZSLSDXwOeBT4loh8gkgp/o8k5Fy6xIRGo9E4Gyd1DWk0Go1mGbQQaDQajcPRQqDRaDQORwuBRqPROBwtBBqNRuNwtBBoNBqNw9FCoNFoNA7n/wN0YWwg8Keh0gAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8juQM8-tqZAo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "a079e1ea-f138-4c5d-ec08-c2f65c924c26"
      },
      "source": [
        "import jax.numpy as jnp\n",
        "\n",
        "x_jnp = jnp.linspace(0, 10, 1000)\n",
        "y_jnp = 2 * jnp.sin(x_jnp) * jnp.cos(x_jnp)\n",
        "plt.plot(x_jnp, y_jnp);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NytY9h09rewo",
        "outputId": "b0fd1e99-c667-4590-ec97-3fbd0e4b2a12"
      },
      "source": [
        "type(x_np)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-v1A7HUsOHM",
        "outputId": "ce5b7454-b68f-4a6d-e90c-6acb3bef17a2"
      },
      "source": [
        "type(x_jnp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "jaxlib.xla_extension.DeviceArray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CE_ZeH6sPH-",
        "outputId": "a4f5bdc1-9795-4963-c54c-a4445140067d"
      },
      "source": [
        "# NumPy: mutable arrays\n",
        "x = np.arange(10)\n",
        "x[0] = 10\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[10  1  2  3  4  5  6  7  8  9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUkuFibGsTcr",
        "outputId": "a1dccb2d-7f7b-4217-abb0-67ea88e1c4fb"
      },
      "source": [
        "# JAX: immutable arrays\n",
        "x = jnp.arange(10)\n",
        "#x[0] = 10 #error\n",
        "y = x.at[0].set(10)\n",
        "print(x)\n",
        "print(y)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4 5 6 7 8 9]\n",
            "[10  1  2  3  4  5  6  7  8  9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_ablyzdsdGx"
      },
      "source": [
        "### NumPy, lax & XLA: JAX API layering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PN61kARqsqZb"
      },
      "source": [
        "- `jax.numpy` is a high-level wrapper that provides a familiar interface.\n",
        "\n",
        "- `jax.lax` is a lower-level API that is stricter and often more powerful.\n",
        "\n",
        "- All JAX operations are implemented in terms of operations in XLA  the Accelerated Linear Algebra compiler."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iQnxzV8sXsE",
        "outputId": "4d3821ec-956c-4905-b62b-268fd56ad4ce"
      },
      "source": [
        "import jax.numpy as jnp\n",
        "jnp.add(1, 1.0)  # jax.numpy API implicitly promotes mixed types."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(2., dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7fBpNBt3swBU",
        "outputId": "62dd367c-f3f0-4903-bf9c-657454b865fa"
      },
      "source": [
        "from jax import lax\n",
        "lax.add(1, 1.0)  # error: jax.lax API requires explicit type promotion."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-2fdc08069114>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# error: jax.lax API requires explicit type promotion.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m   \u001b[0;34mr\"\"\"Elementwise addition: :math:`x + y`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0madd_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    262\u001b[0m         args, used_axis_names(self, params) if self._dispatch_on_params else None)\n\u001b[1;32m    263\u001b[0m     \u001b[0mtracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiple_results\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfull_lower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36mapply_primitive\u001b[0;34m(prim, *args, **params)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapply_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m   \u001b[0;34m\"\"\"Impl rule that compiles and runs a single primitive 'prim' using XLA.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m   \u001b[0mcompiled_fun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxla_primitive_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0munsafe_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mcompiled_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/util.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_clear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_clear\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/util.py\u001b[0m in \u001b[0;36mcached\u001b[0;34m(_, *args, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlru_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36mxla_primitive_callable\u001b[0;34m(prim, *arg_specs, **params)\u001b[0m\n\u001b[1;32m    270\u001b[0m     return _xla_callable(lu.wrap_init(prim_fun), device, None, \"prim\", donated_invars,\n\u001b[1;32m    271\u001b[0m                          *arg_specs)\n\u001b[0;32m--> 272\u001b[0;31m   \u001b[0maval_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstract_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mavals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mprim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiple_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0mhandle_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maval_to_result_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maval_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36mstandard_abstract_eval\u001b[0;34m(prim, shape_rule, dtype_rule, weak_type_rule, named_shape_rule, *avals, **kwargs)\u001b[0m\n\u001b[1;32m   2123\u001b[0m                          weak_type=weak_type)\n\u001b[1;32m   2124\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mleast_specialized\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mShapedArray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2125\u001b[0;31m     return ShapedArray(shape_rule(*avals, **kwargs), dtype_rule(*avals, **kwargs),\n\u001b[0m\u001b[1;32m   2126\u001b[0m                        \u001b[0mweak_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweak_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2127\u001b[0m                        named_shape=named_shape_rule(*avals, **kwargs))\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36mnaryop_dtype_rule\u001b[0;34m(result_dtype, accepted_dtypes, name, *avals, **kwargs)\u001b[0m\n\u001b[1;32m   2205\u001b[0m         \u001b[0mtypenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2206\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2207\u001b[0;31m   \u001b[0m_check_same_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0maval_dtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2208\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mavals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36m_check_same_dtypes\u001b[0;34m(name, ignore_fp_precision, *ttypes)\u001b[0m\n\u001b[1;32m   6591\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6592\u001b[0m       \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{} requires arguments to have the same dtypes, got {}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6593\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: add requires arguments to have the same dtypes, got int32, float32."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRL1pnYNsxBv",
        "outputId": "78b16892-3329-4578-dc25-e61283d6b53f"
      },
      "source": [
        "lax.add(jnp.float32(1), 1.0) # explicit type promotion"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(2., dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5Sfkpojs9Oe"
      },
      "source": [
        "For example, consider a 1D convolution, which can be expressed in NumPy this way:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAfUASC_s2Yk",
        "outputId": "ebf69424-9ae9-4830-81cc-b8143ad99435"
      },
      "source": [
        "x = jnp.array([1, 2, 1])\n",
        "y = jnp.ones(10)\n",
        "jnp.convolve(x, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([1., 3., 4., 4., 4., 4., 4., 4., 4., 4., 3., 1.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwaVN-Lss_go"
      },
      "source": [
        "Under the hood, this NumPy operation is translated to a much more general convolution implemented by `lax.conv_general_dilated`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FehK93h1s467",
        "outputId": "012fbf4a-2a74-448e-8f50-0376c1d2aade"
      },
      "source": [
        "from jax import lax\n",
        "result = lax.conv_general_dilated(\n",
        "    x.reshape(1, 1, 3).astype(float),  # note: explicit promotion\n",
        "    y.reshape(1, 1, 10),\n",
        "    window_strides=(1,),\n",
        "    padding=[(len(y) - 1, len(y) - 1)])  # equivalent of padding='full' in NumPy\n",
        "result[0, 0]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([1., 3., 4., 4., 4., 4., 4., 4., 4., 4., 3., 1.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Vdg0vRMtHVo"
      },
      "source": [
        "This is a batched convolution operation designed to be efficient for the types of convolutions often used in deep neural nets. It requires much more boilerplate, but is far more flexible and scalable than the convolution provided by NumPy (See JAX Sharp Bits: Convolutions for more detail on JAX convolutions).\n",
        "\n",
        "At their heart, all jax.lax operations are Python wrappers for operations in XLA; here, for example, the convolution implementation is provided by XLA:ConvWithGeneralPadding. Every JAX operation is eventually expressed in terms of these fundamental XLA operations, which is what enables just-in-time (JIT) compilation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dY3zhfsitMwg"
      },
      "source": [
        "### To JIT or not to JIT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrefFB6VtYbN"
      },
      "source": [
        "- By default JAX executes operations one at a time, in sequence.\n",
        "- Using a just-in-time (JIT) compilation decorator, sequences of operations can be optimized together and run at once.\n",
        "- Not all JAX code can be JIT compiled, as it requires array shapes to be static & known at compile time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6s6Zn52ntfCk"
      },
      "source": [
        "For example, consider this function that normalizes the rows of a 2D matrix, expressed in terms of jax.numpy operations:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaMwdrIutPU_"
      },
      "source": [
        "import jax.numpy as jnp\n",
        "\n",
        "def norm(X):\n",
        "  X = X - X.mean(0)\n",
        "  return X / X.std(0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Idcq_rBRtk8D"
      },
      "source": [
        "A just-in-time compiled version of the function can be created using the jax.jit transform:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFNNzM-YtlzK"
      },
      "source": [
        "from jax import jit\n",
        "norm_compiled = jit(norm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPDVKTlYtq6w"
      },
      "source": [
        "This function returns the same results as the original, up to standard floating-point accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsYyi4UAtorO",
        "outputId": "33e0b097-22eb-4234-a195-f7559a4631cc"
      },
      "source": [
        "np.random.seed(1701)\n",
        "X = jnp.array(np.random.rand(10000, 10))\n",
        "np.allclose(norm(X), norm_compiled(X), atol=1E-6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGNggAHRtvWQ"
      },
      "source": [
        "But due to the compilation (which includes fusing of operations, avoidance of allocating temporary arrays, and a host of other tricks), execution times can be orders of magnitude faster in the JIT-compiled case (note the use of block_until_ready() to account for JAXs [asynchronous dispatch](https://jax.readthedocs.io/en/latest/async_dispatch.html)):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7arYFoo9tsei",
        "outputId": "a2cdacd5-bca8-424a-e8d6-fdf575534a8a"
      },
      "source": [
        "%timeit norm(X).block_until_ready()\n",
        "%timeit norm_compiled(X).block_until_ready()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.82 ms  114 s per loop (mean  std. dev. of 7 runs, 100 loops each)\n",
            "372 s  3.66 s per loop (mean  std. dev. of 7 runs, 1000 loops each)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbVqMkcpt80-"
      },
      "source": [
        "That said, jax.jit does have limitations: in particular, it requires all arrays to have static shapes. That means that some JAX operations are incompatible with JIT compilation.\n",
        "\n",
        "For example, this operation can be executed in op-by-op mode:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Tmik82lt0qj",
        "outputId": "2f423031-e86f-46ba-b7f0-796ef2944411"
      },
      "source": [
        "def get_negatives(x):\n",
        "  return x[x < 0]\n",
        "\n",
        "x = jnp.array(np.random.randn(10))\n",
        "get_negatives(x)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([-0.10570311, -0.59403396, -0.8680282 , -0.23489487], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zdFR8L4uAHR"
      },
      "source": [
        "But it returns an error if you attempt to execute it in jit mode:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "id": "5UkOPaNdt-eN",
        "outputId": "5834146c-5f19-49ae-9021-ace95e85e86c"
      },
      "source": [
        "jit(get_negatives)(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NonConcreteBooleanIndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNonConcreteBooleanIndexError\u001b[0m              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-ec8799cf80d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_negatives\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-6b4ad7520a0c>\u001b[0m in \u001b[0;36mget_negatives\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_negatives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_negatives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_rewriting_take\u001b[0;34m(arr, idx)\u001b[0m\n\u001b[1;32m   4958\u001b[0m   \u001b[0;31m# followed by an optional reverse and broadcast_in_dim.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4959\u001b[0m   \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4960\u001b[0;31m   \u001b[0mtreedef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_split_index_for_jit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4961\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_gather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtreedef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_split_index_for_jit\u001b[0;34m(idx)\u001b[0m\n\u001b[1;32m   5026\u001b[0m   \u001b[0;31m# Expand any (concrete) boolean indices. We can then use advanced integer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5027\u001b[0m   \u001b[0;31m# indexing logic to handle them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5028\u001b[0;31m   \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_expand_bool_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5030\u001b[0m   \u001b[0mleaves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtreedef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_expand_bool_indices\u001b[0;34m(idx)\u001b[0m\n\u001b[1;32m   5295\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabstract_i\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mConcreteArray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5296\u001b[0m         \u001b[0;31m# TODO(mattjj): improve this error by tracking _why_ the indices are not concrete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5297\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNonConcreteBooleanIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabstract_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5298\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5299\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNonConcreteBooleanIndexError\u001b[0m: Array boolean indices must be concrete; got ShapedArray(bool[10])\n\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.NonConcreteBooleanIndexError"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Diu5LeIvuEtq"
      },
      "source": [
        "This is because the function generates an array whose shape is not known at compile time: the size of the output depends on the values of the input array, and so it is not compatible with JIT."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_4Iv1whuG4B"
      },
      "source": [
        "### JIT mechanics: tracing and static variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyDaeUMsuIyl"
      },
      "source": [
        "- JIT and other JAX transforms work by tracing a function to determine its effect on inputs of a specific shape and type.\n",
        "- Variables that you dont want to be traced can be marked as *static*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TMW1gktuRMW"
      },
      "source": [
        "To use jax.jit effectively, it is useful to understand how it works. Lets put a few print() statements within a JIT-compiled function and then call the function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0b1aCYtuBiU",
        "outputId": "f5c23271-cbae-4f3d-8931-1b61216843a2"
      },
      "source": [
        "@jit\n",
        "def f(x, y):\n",
        "  print(\"Running f():\")\n",
        "  print(f\"  x = {x}\")\n",
        "  print(f\"  y = {y}\")\n",
        "  result = jnp.dot(x + 1, y + 1)\n",
        "  print(f\"  result = {result}\")\n",
        "  return result\n",
        "\n",
        "x = np.random.randn(3, 4)\n",
        "y = np.random.randn(4)\n",
        "f(x, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running f():\n",
            "  x = Traced<ShapedArray(float32[3,4])>with<DynamicJaxprTrace(level=0/1)>\n",
            "  y = Traced<ShapedArray(float32[4])>with<DynamicJaxprTrace(level=0/1)>\n",
            "  result = Traced<ShapedArray(float32[3])>with<DynamicJaxprTrace(level=0/1)>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([0.25773212, 5.3623195 , 5.4032435 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAHH_nKOuaJ0"
      },
      "source": [
        "Notice that the print statements execute, but rather than printing the data we passed to the function, though, it prints tracer objects that stand-in for them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWND-H7ruw1x"
      },
      "source": [
        "These tracer objects are what `jax.jit` uses to extract the sequence of operations specified by the function. Basic tracers are stand-ins that encode the **shape** and **dtype** of the arrays, but are agnostic to the values. This recorded sequence of computations can then be efficiently applied within XLA to new inputs with the same shape and dtype, without having to re-execute the Python code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2d7ciwBu5lL"
      },
      "source": [
        "When we call the compiled fuction again on matching inputs, no re-compilation is required and nothing is printed because the result is computed in compiled XLA rather than in Python:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItNe_q1Uu7Am",
        "outputId": "5eaa82f8-eb90-44f3-8324-b004fdd8e5ca"
      },
      "source": [
        "x2 = np.random.randn(3, 4)\n",
        "y2 = np.random.randn(4)\n",
        "f(x2, y2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([1.4344587, 4.3004417, 7.989701 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jy9M5ND1u_PN"
      },
      "source": [
        "The extracted sequence of operations is encoded in a JAX expression, or *jaxpr* for short. You can view the jaxpr using the `jax.make_jaxpr` transformation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGwOAoUbu8HR",
        "outputId": "2ee8755d-78d6-4e76-cea8-6684440f061e"
      },
      "source": [
        "from jax import make_jaxpr\n",
        "\n",
        "def f(x, y):\n",
        "  return jnp.dot(x + 1, y + 1)\n",
        "\n",
        "make_jaxpr(f)(x, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{ lambda  ; a b.\n",
              "  let c = add a 1.0\n",
              "      d = add b 1.0\n",
              "      e = dot_general[ dimension_numbers=(((1,), (0,)), ((), ()))\n",
              "                       precision=None\n",
              "                       preferred_element_type=None ] c d\n",
              "  in (e,) }"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6m7PINpsvNzZ"
      },
      "source": [
        "Note one consequence of this: because JIT compilation is done without information on the content of the array, control flow statements in the function cannot depend on traced values. For example, this fails:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 631
        },
        "id": "-uxtZm9AvOuw",
        "outputId": "6dbe2236-3fe3-4815-ee70-5d1ed237288b"
      },
      "source": [
        "@jit\n",
        "def f(x, neg):\n",
        "  return -x if neg else x\n",
        "\n",
        "f(1, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ConcretizationTypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mConcretizationTypeError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-acbedba5ce66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mneg\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-acbedba5ce66>\u001b[0m in \u001b[0;36mf\u001b[0;34m(x, neg)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mneg\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/core.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, arg)\u001b[0m\n\u001b[1;32m    952\u001b[0m                       f\"or `jnp.array(x, {fun.__name__})` instead.\")\n\u001b[1;32m    953\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mConcretizationTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConcretizationTypeError\u001b[0m: Abstract tracer value encountered where concrete value is expected: Traced<ShapedArray(bool[], weak_type=True)>with<DynamicJaxprTrace(level=0/1)>\nThe problem arose with the `bool` function. \nWhile tracing the function f at <ipython-input-25-acbedba5ce66>:1 for jit, this concrete value was not available in Python because it depends on the value of the argument 'neg'.\n\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.ConcretizationTypeError"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nks6OtRxvRC1"
      },
      "source": [
        "If there are variables that you would not like to be traced, they can be marked as static for the purposes of JIT compilation:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpSkRdIbvPqU",
        "outputId": "f195b301-2a67-4abf-b354-46d2185aaa36"
      },
      "source": [
        "from functools import partial\n",
        "\n",
        "@partial(jit, static_argnums=(1,))\n",
        "def f(x, neg):\n",
        "  return -x if neg else x\n",
        "\n",
        "f(1, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(-1, dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMs4UhEivVO5"
      },
      "source": [
        "Note that calling a JIT-compiled function with a different static argument results in re-compilation, so the function still works as expected:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RpVAWwZvTAf",
        "outputId": "a5de570b-5641-4240-e8bb-8ff6146c5bfc"
      },
      "source": [
        "f(1, False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(1, dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMsm8k-1vYnj"
      },
      "source": [
        "Understanding which values and operations will be static and which will be traced is a key part of using `jax.jit` effectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2VZ8l9Rviwi"
      },
      "source": [
        "### Static vs Traced Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqo07uDmvkWH"
      },
      "source": [
        "- Just as values can be either static or traced, operations can be static or traced.\n",
        "- Static operations are evaluated at compile-time in Python; traced operations are compiled & evaluated at run-time in XLA.\n",
        "- Use `numpy` for operations that you want to be static; use `jax.numpy` for operations that you want to be traced."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kGq2-jzvsRc"
      },
      "source": [
        "This distinction between static and traced values makes it important to think about how to keep a static value static. Consider this function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "id": "d2cvgzmhvuCt",
        "outputId": "c302d8c9-7e75-4e46-c3fb-32c8d0ee9247"
      },
      "source": [
        "import jax.numpy as jnp\n",
        "from jax import jit\n",
        "\n",
        "@jit\n",
        "def f(x):\n",
        "  return x.reshape(jnp.array(x.shape).prod())\n",
        "\n",
        "x = jnp.ones((2, 3))\n",
        "f(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-5fa933a68063>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-5fa933a68063>\u001b[0m in \u001b[0;36mf\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_reshape\u001b[0;34m(a, order, *args)\u001b[0m\n\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_reshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1332\u001b[0;31m   \u001b[0mnewshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_compute_newshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1333\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0morder\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"C\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_compute_newshape\u001b[0;34m(a, newshape)\u001b[0m\n\u001b[1;32m   1323\u001b[0m   \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0miterable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0miterable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1325\u001b[0;31m   \u001b[0mnewshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanonicalize_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewshape\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0miterable\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnewshape\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m   return tuple(- core.divide_shape_sizes(np.shape(a), newshape)\n\u001b[1;32m   1327\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_equal_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/core.py\u001b[0m in \u001b[0;36mcanonicalize_shape\u001b[0;34m(shape)\u001b[0m\n\u001b[1;32m   1398\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1400\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0m_invalid_shape_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_invalid_shape_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mShape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Shapes must be 1D sequences of concrete values of integer type, got [Traced<ShapedArray(int32[])>with<DynamicJaxprTrace(level=0/1)>].\nIf using `jit`, try using `static_argnums` or applying `jit` to smaller subfunctions."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4fDJ7fUv5Aw"
      },
      "source": [
        "This fails with an error specifying that a tracer was found in jax.numpy.reshape. Lets add some print statements to the function to understand why this is happening:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahZ3AxWEvykm",
        "outputId": "eba09ba8-aa4e-4a91-830d-10d12e62fe1b"
      },
      "source": [
        "@jit\n",
        "def f(x):\n",
        "  print(f\"x = {x}\")\n",
        "  print(f\"x.shape = {x.shape}\")\n",
        "  print(f\"jnp.array(x.shape).prod() = {jnp.array(x.shape).prod()}\")\n",
        "  # comment this out to avoid the error:\n",
        "  # return x.reshape(jnp.array(x.shape).prod())\n",
        "\n",
        "f(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x = Traced<ShapedArray(float32[2,3])>with<DynamicJaxprTrace(level=0/1)>\n",
            "x.shape = (2, 3)\n",
            "jnp.array(x.shape).prod() = Traced<ShapedArray(int32[])>with<DynamicJaxprTrace(level=0/1)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AChm8chxv9Rm"
      },
      "source": [
        "Notice that although x is traced, x.shape is a static value. However, when we use jnp.array and jnp.prod on this static value, it becomes a traced value, at which point it cannot be used in a function like reshape() that requires a static input (recall: array shapes must be static)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lz61ojklv-r8"
      },
      "source": [
        "A useful pattern is to use numpy for operations that should be static (i.e. done at compile-time), and use jax.numpy for operations that should be traced (i.e. compiled and executed at run-time). For this function, it might look like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5ztyuVRv14n",
        "outputId": "14a1d032-d194-4949-9719-d1a821a6fca4"
      },
      "source": [
        "from jax import jit\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "\n",
        "@jit\n",
        "def f(x):\n",
        "  return x.reshape((np.prod(x.shape),))\n",
        "\n",
        "f(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([1., 1., 1., 1., 1., 1.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5Pso3o8wC99"
      },
      "source": [
        "For this reason, a standard convention in JAX programs is to import numpy as np and import jax.numpy as jnp so that both interfaces are available for finer control over whether operations are performed in a static matter (with numpy, once at compile-time) or a traced manner (with jax.numpy, optimized at run-time)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7VrxKYfwREs"
      },
      "source": [
        "## Tutorial 2: [JAX - The Sharp Bits](https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qz4vhfDEwXgP"
      },
      "source": [
        "JAX is a language for expressing and composing transformations of numerical programs. JAX is also able to compile numerical programs for CPU or accelerators (GPU/TPU). JAX works great for many numerical and scientific programs, but only if they are **written with certain constraints** that we describe below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUdmcbpAwa-8"
      },
      "source": [
        "import numpy as np\n",
        "from jax import grad, jit\n",
        "from jax import lax\n",
        "from jax import random\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import matplotlib as mpl\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import rcParams\n",
        "rcParams['image.interpolation'] = 'nearest'\n",
        "rcParams['image.cmap'] = 'viridis'\n",
        "rcParams['axes.grid'] = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63vDpSq1wkto"
      },
      "source": [
        "### Pure functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OF68O_gYwmH3"
      },
      "source": [
        "JAX transformation and compilation are designed to work only on Python functions that are functionally pure: all the input data is passed through the function parameters, all the results are output through the function results. A pure function will always return the same result if invoked with the same inputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1H1ZbUvMwolq"
      },
      "source": [
        "Here are some examples of functions that are not functionally pure for which JAX behaves differently than the Python interpreter. Note that these behaviors are not guaranteed by the JAX system; the proper way to use JAX is to use it only on functionally pure Python functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4W1Jdvd2wqXi"
      },
      "source": [
        "def impure_print_side_effect(x):\n",
        "  print(\"Executing function\")  # This is a side-effect \n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeWa0lPmwsun",
        "outputId": "61ad45f4-b616-4dc2-cfe5-46d2329a9994"
      },
      "source": [
        "# The side-effects appear during the first run  \n",
        "print (\"First call: \", jit(impure_print_side_effect)(4.))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing function\n",
            "First call:  4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtFfCR2Zwu14",
        "outputId": "82989560-6e2e-4d1c-96f9-e4efd2c61035"
      },
      "source": [
        "# Subsequent runs with parameters of same type and shape may not show the side-effect\n",
        "# This is because JAX now invokes a cached compilation of the function\n",
        "print (\"Second call: \", jit(impure_print_side_effect)(5.))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Second call:  5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRTY5zofwwE-",
        "outputId": "16ddf3c3-116b-4b66-cf26-c6b4b3348ca7"
      },
      "source": [
        "# JAX re-runs the Python function when the type or shape of the argument changes\n",
        "print (\"Third call, different type: \", jit(impure_print_side_effect)(jnp.array([5.])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing function\n",
            "Third call, different type:  [5.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywDRL-Ljw1WN"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zq0KbuEKwxPR"
      },
      "source": [
        "g = 0.\n",
        "def impure_uses_globals(x):\n",
        "  return x + g"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_s8C1bR0w4Ik",
        "outputId": "219046a9-7b39-45e7-98ad-1db73b0e32f8"
      },
      "source": [
        "# JAX captures the value of the global during the first run\n",
        "print (\"First call: \", jit(impure_uses_globals)(4.))\n",
        "g = 10.  # Update the global"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First call:  4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRlPamNEw5NG",
        "outputId": "8ef46766-c2bc-430d-c1f3-970cc49299a6"
      },
      "source": [
        "# Subsequent runs may silently use the cached value of the globals\n",
        "print (\"Second call: \", jit(impure_uses_globals)(5.))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Second call:  5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkXcIlpmw6EL",
        "outputId": "5a962133-b5e9-42f8-e961-7129abc67b22"
      },
      "source": [
        "# JAX re-runs the Python function when the type or shape of the argument changes\n",
        "# This will end up reading the latest value of the global\n",
        "print (\"Third call, different type: \", jit(impure_uses_globals)(jnp.array([4.])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Third call, different type:  [14.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvHkXFOIw8wa"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEaSBm8Yw69q"
      },
      "source": [
        "g = 0.\n",
        "def impure_saves_global(x):\n",
        "  global g\n",
        "  g = x\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_535y8xw_QP",
        "outputId": "7154c9f8-f7b9-4940-d513-cc40f8923cb8"
      },
      "source": [
        "# JAX runs once the transformed function with special Traced values for arguments\n",
        "print (\"First call: \", jit(impure_saves_global)(4.))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First call:  4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnkfgOwnxAXb",
        "outputId": "b9c186ec-b2e2-4743-9135-a2a9cb1e978c"
      },
      "source": [
        "print (\"Saved global: \", g)  # Saved global has an internal JAX value"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved global:  Traced<ShapedArray(float32[], weak_type=True)>with<DynamicJaxprTrace(level=0/1)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpjckSzPxE--"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Y7qVfCqxGB7"
      },
      "source": [
        "A Python function can be functionally pure even if it actually uses stateful objects internally, as long as it does not read or write external state:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOYaVi1zxBkZ",
        "outputId": "98476b62-67dd-4fc1-ccc1-2ba462147691"
      },
      "source": [
        "def pure_uses_internal_state(x):\n",
        "  state = dict(even=0, odd=0)\n",
        "  for i in range(10):\n",
        "    state['even' if i % 2 == 0 else 'odd'] += x\n",
        "  return state['even'] + state['odd']\n",
        "\n",
        "print(jit(pure_uses_internal_state)(5.))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMKoVwinxLtz"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArTvJ4_ExM4t"
      },
      "source": [
        "It is not recommended to use iterators in any JAX function you want to jit or in any control-flow primitive. The reason is that an iterator is a python object which introduces state to retrieve the next element. Therefore, it is incompatible with JAX functional programming model. In the code below, there are some examples of incorrect attempts to use iterators with JAX. Most of them return an error, but some give unexpected results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHpwZ-HIxH81",
        "outputId": "9ee404b8-2f60-41f0-ccb2-5c7a72617115"
      },
      "source": [
        "import jax.numpy as jnp\n",
        "import jax.lax as lax\n",
        "from jax import make_jaxpr\n",
        "\n",
        "\n",
        "# lax.fori_loop\n",
        "array = jnp.arange(10)\n",
        "print(lax.fori_loop(0, 10, lambda i,x: x+array[i], 0)) # expected result 45\n",
        "iterator = iter(range(10))\n",
        "print(lax.fori_loop(0, 10, lambda i,x: x+next(iterator), 0)) # unexpected result 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocdcQNODxTS7",
        "outputId": "39995dc7-e729-4361-e6fc-dc5eb19458cd"
      },
      "source": [
        "# lax.scan\n",
        "def func11(arr, extra):\n",
        "    ones = jnp.ones(arr.shape)  \n",
        "    def body(carry, aelems):\n",
        "        ae1, ae2 = aelems\n",
        "        return (carry + ae1 * ae2 + extra, carry)\n",
        "    return lax.scan(body, 0., (arr, ones))    \n",
        "make_jaxpr(func11)(jnp.arange(16), 5.)\n",
        "# make_jaxpr(func11)(iter(range(16)), 5.) # throws error"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{ lambda  ; a b.\n",
              "  let c = broadcast_in_dim[ broadcast_dimensions=(  )\n",
              "                            shape=(16,) ] 1.0\n",
              "      d e = scan[ jaxpr={ lambda  ; a b c d.\n",
              "                          let e = convert_element_type[ new_dtype=float32\n",
              "                                                        weak_type=False ] c\n",
              "                              f = mul e d\n",
              "                              g = convert_element_type[ new_dtype=float32\n",
              "                                                        weak_type=False ] b\n",
              "                              h = add g f\n",
              "                              i = convert_element_type[ new_dtype=float32\n",
              "                                                        weak_type=False ] a\n",
              "                              j = add h i\n",
              "                          in (j, b) }\n",
              "                  length=16\n",
              "                  linear=(False, False, False, False)\n",
              "                  num_carry=1\n",
              "                  num_consts=1\n",
              "                  reverse=False\n",
              "                  unroll=1 ] b 0.0 a c\n",
              "  in (d, e) }"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKUeSaJfxXin",
        "outputId": "45ac1d8e-47a7-4d32-d777-b5befaaa312b"
      },
      "source": [
        "# lax.cond\n",
        "array_operand = jnp.array([0.])\n",
        "lax.cond(True, lambda x: x+1, lambda x: x-1, array_operand)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([1.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "jhnPEACmxfzF",
        "outputId": "6c344160-39d3-4267-9a3d-f5ac0d23f802"
      },
      "source": [
        "iter_operand = iter(range(10))\n",
        "lax.cond(True, lambda x: next(x)+1, lambda x: next(x)-1, iter_operand) # throws error"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-5f8b2cb21dbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0miter_operand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_operand\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# throws error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "    \u001b[0;31m[... skipping hidden 6 frame]\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/core.py\u001b[0m in \u001b[0;36mconcrete_aval\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    914\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__jax_array__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcrete_aval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__jax_array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m   raise TypeError(f\"Value {repr(x)} with type {type(x)} is not a valid JAX \"\n\u001b[0m\u001b[1;32m    917\u001b[0m                    \"type\")\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Value <range_iterator object at 0x7f8a36083390> with type <class 'range_iterator'> is not a valid JAX type"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwam8KrRxoHJ"
      },
      "source": [
        "### In-Place Updates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45Weul4MxpFo"
      },
      "source": [
        "In Numpy youre used to doing this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_xOA46Oxqyt",
        "outputId": "02b91827-1175-4a7e-f99a-25854b85153d"
      },
      "source": [
        "numpy_array = np.zeros((3,3), dtype=np.float32)\n",
        "print(\"original array:\")\n",
        "print(numpy_array)\n",
        "\n",
        "# In place, mutating update\n",
        "numpy_array[1, :] = 1.0\n",
        "print(\"updated array:\")\n",
        "print(numpy_array)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original array:\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "updated array:\n",
            "[[0. 0. 0.]\n",
            " [1. 1. 1.]\n",
            " [0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhzmu46DxuIc"
      },
      "source": [
        "If we try to update a JAX device array in-place, however, we get an error!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oC1OALQ_xsCW",
        "outputId": "7ada945c-154e-4495-d191-ce61930f7d62"
      },
      "source": [
        "jax_array = jnp.zeros((3,3), dtype=jnp.float32)\n",
        "\n",
        "# In place update of JAX's array will yield an error!\n",
        "try:\n",
        "  jax_array[1, :] = 1.0\n",
        "except Exception as e:\n",
        "  print(\"Exception {}\".format(e))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exception '<class 'jaxlib.xla_extension.DeviceArray'>' object does not support item assignment. JAX arrays are immutable; perhaps you want jax.ops.index_update or jax.ops.index_add instead?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wswK8cgx0QR"
      },
      "source": [
        "Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qoWzqAOx1BF"
      },
      "source": [
        "Allowing mutation of variables in-place makes program analysis and transformation very difficult. JAX requires a pure functional expression of a numerical program."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJ4_gN9Ex4BE"
      },
      "source": [
        "Instead, JAX offers the functional update functions: [index_update](https://jax.readthedocs.io/en/latest/_autosummary/jax.ops.index_update.html#jax.ops.index_update), [index_add](https://jax.readthedocs.io/en/latest/_autosummary/jax.ops.index_add.html#jax.ops.index_add), [index_min](https://jax.readthedocs.io/en/latest/_autosummary/jax.ops.index_min.html#jax.ops.index_min), [index_max](https://jax.readthedocs.io/en/latest/_autosummary/jax.ops.index_max.html#jax.ops.index_max), and the [index](https://jax.readthedocs.io/en/latest/_autosummary/jax.ops.index.html#jax.ops.index) helper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mCHFi4MyTeR"
      },
      "source": [
        "Warning: inside jitd code and `lax.while_loop` or `lax.fori_loop` the **size** of slices cant be functions of argument *values* but only functions of argument *shapes*  the slice start indices have no such restriction. See the below **Control Flow** Section for more information on this limitation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzyN56X0y2Vl"
      },
      "source": [
        "from jax.ops import index, index_add, index_update"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJMw6Farylz9"
      },
      "source": [
        "#### `index_update`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpOV8zp3yrce"
      },
      "source": [
        "If the **input values** of `index_update` arent reused, **jit**-compiled code will perform these operations in-place.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNCOizLOxwOx",
        "outputId": "2ba10fca-0daf-4597-8fec-c25bea6f21fe"
      },
      "source": [
        "jax_array = jnp.zeros((3, 3))\n",
        "print(\"original array:\")\n",
        "print(jax_array)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original array:\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAKzcEcvyw86",
        "outputId": "bf8d186a-4d40-41f5-bcd2-0406b6457fdc"
      },
      "source": [
        "new_jax_array = index_update(jax_array, index[1, :], 1.)\n",
        "print(\"old array unchanged:\")\n",
        "print(jax_array)\n",
        "\n",
        "print(\"new array:\")\n",
        "print(new_jax_array)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "old array unchanged:\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "new array:\n",
            "[[0. 0. 0.]\n",
            " [1. 1. 1.]\n",
            " [0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9afCG293zKGI"
      },
      "source": [
        "#### `index_add`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qxq6JFsjzOvU"
      },
      "source": [
        "If the input values of index_update arent reused, jit-compiled code will perform these operations in-place."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdQWjlQLyypt",
        "outputId": "522c9825-8471-4b1d-8eb6-346c039e93d8"
      },
      "source": [
        "print(\"original array:\")\n",
        "jax_array = jnp.ones((5, 6))\n",
        "print(jax_array)\n",
        "\n",
        "new_jax_array = index_add(jax_array, index[::2, 3:], 7.)\n",
        "print(\"new array post-addition:\")\n",
        "print(new_jax_array)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original array:\n",
            "[[1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1.]]\n",
            "new array post-addition:\n",
            "[[1. 1. 1. 8. 8. 8.]\n",
            " [1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 8. 8. 8.]\n",
            " [1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 8. 8. 8.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gi7DAbDdzZu2"
      },
      "source": [
        "### Out-of-Bounds Indexing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylFFAA1PzbNk"
      },
      "source": [
        "In Numpy, you are used to errors being thrown when you index an array outside of its bounds, like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RH4tmHTLzQsD",
        "outputId": "9d8065bb-8b74-46cd-b981-b6af19e35a5e"
      },
      "source": [
        "try:\n",
        "  np.arange(10)[11]\n",
        "except Exception as e:\n",
        "  print(\"Exception {}\".format(e))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exception index 11 is out of bounds for axis 0 with size 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0I3Xh970zff_"
      },
      "source": [
        "However, raising an error from code running on an accelerator can be difficult or impossible. Therefore, JAX must choose some non-error behavior for out of bounds indexing (akin to how invalid floating point arithmetic results in `NaN`).\n",
        "\n",
        "1. When the indexing operation is an array index update (e.g. `index_add` or `scatter`-like primitives), **updates at out-of-bounds indices will be skipped**.\n",
        "\n",
        "2. When the operation is an array index retrieval (e.g. NumPy indexing or `gather`-like primitives) **the index is clamped to the bounds of the array**, since *something* must be returned."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZ6HJbkdzzWG"
      },
      "source": [
        "For example, the last value of the array will be returned from this indexing operation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtW39sMgzdtF",
        "outputId": "a8d92c4d-4bee-4912-9eb0-5f0ed1e59a8e"
      },
      "source": [
        "jnp.arange(10)[11]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(9, dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gQ3gIsVz31U"
      },
      "source": [
        "Note that due to this behavior for index retrieval, functions like `jnp.nanargmin` and `jnp.nanargmax` return -1 for slices consisting of NaNs whereas Numpy would throw an error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRy2_f9I0B9j"
      },
      "source": [
        " Note also that, as the two behaviors described above are not inverses of each other, reverse-mode automatic differentiation (which turns index updates into index retrievals and vice versa) [will not preserve the semantics of out of bounds indexing](https://github.com/google/jax/issues/5760). Thus it may be a good idea to think of out-of-bounds indexing in JAX as a case of [undefined behavior](https://en.wikipedia.org/wiki/Undefined_behavior)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgaK6Mu20VHz"
      },
      "source": [
        "### Non-array inputs: NumPy vs. JAX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afdQwkyt0WMz"
      },
      "source": [
        "NumPy is generally happy accepting Python lists or tuples as inputs to its API functions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AR6fuzA-0Yt6",
        "outputId": "f7a62458-7016-46a8-fcc1-9438f8123968"
      },
      "source": [
        "np.sum([1, 2, 3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8ipX6qJ0bWm"
      },
      "source": [
        "JAX departs from this, generally returning a helpful error:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wr4L3uir0ZqT",
        "outputId": "39d5355f-4e6a-452c-fd5a-c399e3614e7f"
      },
      "source": [
        "try:\n",
        "  jnp.sum([1, 2, 3])\n",
        "except TypeError as e:\n",
        "  print(f\"TypeError: {e}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TypeError: sum requires ndarray or scalar arguments, got <class 'list'> at position 0.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUEkWt4D0gf9"
      },
      "source": [
        "This is a deliberate design choice, because passing lists or tuples to traced functions can lead to silent performance degradation that might otherwise be difficult to detect."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE_FwAEi0hSj"
      },
      "source": [
        "For example, consider the following permissive version of `jnp.sum` that allows list inputs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RenR3vWD0kbS",
        "outputId": "db0ecbfc-6641-48f2-bb6a-cd7cbb5cfffa"
      },
      "source": [
        "def permissive_sum(x):\n",
        "  return jnp.sum(jnp.array(x))\n",
        "\n",
        "x = list(range(10))\n",
        "permissive_sum(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(45, dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulMnhRRS0qeP"
      },
      "source": [
        "The output is what we would expect, but this hides potential performance issues under the hood. In JAXs tracing and JIT compilation model, each element in a Python list or tuple is treated as a separate JAX variable, and individually processed and pushed to device. This can be seen in the jaxpr for the `permissive_sum` function above:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUYg0dOu0mjB",
        "outputId": "56ea786f-3b93-4ba7-aafb-fb504bcafd0d"
      },
      "source": [
        "make_jaxpr(permissive_sum)(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{ lambda  ; a b c d e f g h i j.\n",
              "  let k = broadcast_in_dim[ broadcast_dimensions=(  )\n",
              "                            shape=(1,) ] a\n",
              "      l = broadcast_in_dim[ broadcast_dimensions=(  )\n",
              "                            shape=(1,) ] b\n",
              "      m = broadcast_in_dim[ broadcast_dimensions=(  )\n",
              "                            shape=(1,) ] c\n",
              "      n = broadcast_in_dim[ broadcast_dimensions=(  )\n",
              "                            shape=(1,) ] d\n",
              "      o = broadcast_in_dim[ broadcast_dimensions=(  )\n",
              "                            shape=(1,) ] e\n",
              "      p = broadcast_in_dim[ broadcast_dimensions=(  )\n",
              "                            shape=(1,) ] f\n",
              "      q = broadcast_in_dim[ broadcast_dimensions=(  )\n",
              "                            shape=(1,) ] g\n",
              "      r = broadcast_in_dim[ broadcast_dimensions=(  )\n",
              "                            shape=(1,) ] h\n",
              "      s = broadcast_in_dim[ broadcast_dimensions=(  )\n",
              "                            shape=(1,) ] i\n",
              "      t = broadcast_in_dim[ broadcast_dimensions=(  )\n",
              "                            shape=(1,) ] j\n",
              "      u = concatenate[ dimension=0 ] k l m n o p q r s t\n",
              "      v = convert_element_type[ new_dtype=int32\n",
              "                                weak_type=False ] u\n",
              "      w = reduce_sum[ axes=(0,) ] v\n",
              "  in (w,) }"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJC0v4XL0vmh"
      },
      "source": [
        "Each entry of the list is handled as a separate input, resulting in a tracing & compilation overhead that grows linearly with the size of the list. **To prevent surprises like this, JAX avoids implicit conversions of lists and tuples to arrays**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjQYu9EL00p5"
      },
      "source": [
        "If you would like to pass a tuple or list to a JAX function, you can do so by first explicitly converting it to an array:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjB9OrIO0tDq",
        "outputId": "31096235-d5e4-4c28-a81d-034a7a0f71dd"
      },
      "source": [
        "jnp.sum(jnp.array(x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(45, dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yv9vL2G11FVq"
      },
      "source": [
        "### Random Numbers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIoPUgr_1Kjs"
      },
      "source": [
        "#### RNGs and State"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Va_2fwq91NY9"
      },
      "source": [
        "Youre used to stateful pseudorandom number generators (PRNGs) from numpy and other libraries, which helpfully hide a lot of details under the hood to give you a ready fountain of pseudorandomness:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYMNmM6w1OMo",
        "outputId": "e3309735-2fd7-439f-aecc-68fd46389092"
      },
      "source": [
        "print(np.random.random())\n",
        "print(np.random.random())\n",
        "print(np.random.random())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9041193705449755\n",
            "0.42302231551264424\n",
            "0.2951092425790558\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mN7m6iqw1TIS"
      },
      "source": [
        "Underneath the hood, numpy uses the Mersenne Twister PRNG to power its pseudorandom functions. The PRNG has a period of 2^199371 and at any point can be described by 624 32bit unsigned ints and a position indicating how much of this entropy has been used up."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Xhw0Nxz1PT9"
      },
      "source": [
        "np.random.seed(0)\n",
        "rng_state = np.random.get_state()\n",
        "#print(rng_state)\n",
        "# --> ('MT19937', array([0, 1, 1812433255, 1900727105, 1208447044,\n",
        "#       2481403966, 4042607538,  337614300, ... 614 more numbers..., \n",
        "#       3048484911, 1796872496], dtype=uint32), 624, 0, 0.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpeMek8U1lph"
      },
      "source": [
        "This pseudorandom state vector is automagically updated behind the scenes every time a random number is needed, consuming 2 of the uint32s in the Mersenne twister state vector:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cnu5DZy1cbW"
      },
      "source": [
        "_ = np.random.uniform()\n",
        "rng_state = np.random.get_state()\n",
        "#print(rng_state) \n",
        "# --> ('MT19937', array([2443250962, 1093594115, 1878467924,\n",
        "#       ..., 2648828502, 1678096082], dtype=uint32), 2, 0, 0.0)\n",
        "\n",
        "# Let's exhaust the entropy in this PRNG statevector\n",
        "for i in range(311):\n",
        "  _ = np.random.uniform()\n",
        "rng_state = np.random.get_state()\n",
        "#print(rng_state) \n",
        "# --> ('MT19937', array([2443250962, 1093594115, 1878467924,\n",
        "#       ..., 2648828502, 1678096082], dtype=uint32), 624, 0, 0.0)\n",
        "\n",
        "# Next call iterates the RNG state for a new batch of fake \"entropy\".\n",
        "_ = np.random.uniform()\n",
        "rng_state = np.random.get_state()\n",
        "# print(rng_state) \n",
        "# --> ('MT19937', array([1499117434, 2949980591, 2242547484, \n",
        "#      4162027047, 3277342478], dtype=uint32), 2, 0, 0.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x02kJdUU1tqw"
      },
      "source": [
        "The problem with magic PRNG state is that its hard to reason about how its being used and updated across different threads, processes, and devices, and its very easy to screw up when the details of entropy production and consumption are hidden from the end user.\n",
        "\n",
        "The Mersenne Twister PRNG is also known to have a [number](https://cs.stackexchange.com/a/53475) of problems, it has a large 2.5Kb state size, which leads to problematic [initialization issues](https://dl.acm.org/citation.cfm?id=1276928). It [fails](http://www.pcg-random.org/pdf/toms-oneill-pcg-family-v1.02.pdf) modern BigCrush tests, and is generally slow.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODL1FtuD14uY"
      },
      "source": [
        "#### JAX PRNG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BV3Xc2wM188i"
      },
      "source": [
        "JAX instead implements an explicit PRNG where entropy production and consumption are handled by explicitly passing and iterating PRNG state. JAX uses a modern [Threefry counter-based PRNG](https://github.com/google/jax/blob/master/design_notes/prng.md) thats splittable. That is, its design allows us to fork the PRNG state into new PRNGs for use with parallel stochastic generation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADMfyDFI2DCZ"
      },
      "source": [
        "The random state is described by two unsigned-int32s that we call a key:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9Pz2SCL1oT1",
        "outputId": "6a415ece-9f63-40cb-e79a-5ad232eb9c4b"
      },
      "source": [
        "from jax import random\n",
        "key = random.PRNGKey(0)\n",
        "key"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([0, 0], dtype=uint32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uD0MT7F2IVF"
      },
      "source": [
        "JAXs random functions produce pseudorandom numbers from the PRNG state, but they **don't change the state**!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsRTl2KK2RBF"
      },
      "source": [
        "Reusing the same state will cause sadness and monotony, depriving the enduser of lifegiving chaos. (I.e. don't reuse the same state):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zVykTpc2En9",
        "outputId": "c5be4326-c254-43b8-de16-39ed1e8ffe4c"
      },
      "source": [
        "print(random.normal(key, shape=(1,)))\n",
        "print(key)\n",
        "# No no no!\n",
        "print(random.normal(key, shape=(1,)))\n",
        "print(key)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.20584236]\n",
            "[0 0]\n",
            "[-0.20584236]\n",
            "[0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhuC3CJj2Xm6"
      },
      "source": [
        "Instead, we **split** the PRNG to get usable **subkeys** every time we need a new pseudorandom number:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASwodUb72Vh0",
        "outputId": "665ef8e4-2ed2-42c1-8cf9-4ddad3b3c73e"
      },
      "source": [
        "print(\"old key\", key)\n",
        "key, subkey = random.split(key)\n",
        "normal_pseudorandom = random.normal(subkey, shape=(1,))\n",
        "print(\"    \\---SPLIT --> new key   \", key)\n",
        "print(\"             \\--> new subkey\", subkey, \"--> normal\", normal_pseudorandom)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "old key [0 0]\n",
            "    \\---SPLIT --> new key    [4146024105  967050713]\n",
            "             \\--> new subkey [2718843009 1272950319] --> normal [-1.2515285]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgnJ2WdE2c9F"
      },
      "source": [
        "We propagate the key and make new subkeys whenever we need a new random number:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4Qhr9CF2azS",
        "outputId": "91a88328-851c-4d28-f68d-27bd0092054a"
      },
      "source": [
        "print(\"old key\", key)\n",
        "key, subkey = random.split(key)\n",
        "normal_pseudorandom = random.normal(subkey, shape=(1,))\n",
        "print(\"    \\---SPLIT --> new key   \", key)\n",
        "print(\"             \\--> new subkey\", subkey, \"--> normal\", normal_pseudorandom)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "old key [4146024105  967050713]\n",
            "    \\---SPLIT --> new key    [2384771982 3928867769]\n",
            "             \\--> new subkey [1278412471 2182328957] --> normal [-0.5866531]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv2e8nQJ2k7W"
      },
      "source": [
        "We can generate more than one subkey at a time:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fJKLhU92gNf",
        "outputId": "4382aa5f-bd8e-452f-f9ed-e52db3235a19"
      },
      "source": [
        "key, *subkeys = random.split(key, 4)\n",
        "for subkey in subkeys:\n",
        "  print(random.normal(subkey, shape=(1,)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.3753332]\n",
            "[0.9864523]\n",
            "[0.14553195]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWBbXv7A2xJn"
      },
      "source": [
        "### Control Flow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFWd_Fau2zzF"
      },
      "source": [
        "#### python control_flow + autodiff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qwltDMP203B"
      },
      "source": [
        "If you just want to apply `grad` to your python functions, you can use regular python control-flow constructs with no problems, as if you were using [Autograd](https://github.com/hips/autograd) (or Pytorch or TF Eager)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBNKrFz928yg",
        "outputId": "f2c379e8-5aa1-4a2a-e7ab-e5a81edc8844"
      },
      "source": [
        "def f(x):\n",
        "  if x < 3:\n",
        "    return 3. * x ** 2\n",
        "  else:\n",
        "    return -4 * x\n",
        "\n",
        "print(grad(f)(2.))  # ok!\n",
        "print(grad(f)(4.))  # ok!"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12.0\n",
            "-4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBIUIuHe3AOq"
      },
      "source": [
        "#### python control flow + JIT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lt68J8pj3BjD"
      },
      "source": [
        "Using control flow with `jit` is more complicated, and by default it has more constraints."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhXBqBMl3DcH"
      },
      "source": [
        "This works:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_w_0zENG3Eof",
        "outputId": "4c70a613-6396-4198-8700-63b8cd1a485d"
      },
      "source": [
        "@jit\n",
        "def f(x):\n",
        "  for i in range(3):\n",
        "    x = 2 * x\n",
        "  return x\n",
        "\n",
        "print(f(3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hopgTsU83H76"
      },
      "source": [
        "So does this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Za_eZfnt3Fnw",
        "outputId": "70dec359-b5e2-4697-990a-9808e317c75f"
      },
      "source": [
        "@jit\n",
        "def g(x):\n",
        "  y = 0.\n",
        "  for i in range(x.shape[0]):\n",
        "    y = y + x[i]\n",
        "  return y\n",
        "\n",
        "print(g(jnp.array([1., 2., 3.])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1a8iDXC3I01"
      },
      "source": [
        "But this doesnt, at least by default:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cs_VmAd3HJC",
        "outputId": "5f9beaae-58d5-428a-b522-b53e605b7308"
      },
      "source": [
        "@jit\n",
        "def f(x):\n",
        "  if x < 3:\n",
        "    return 3. * x ** 2\n",
        "  else:\n",
        "    return -4 * x\n",
        "\n",
        "# This will fail!\n",
        "try:\n",
        "  f(2)\n",
        "except Exception as e:\n",
        "  print(\"Exception {}\".format(e))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exception Abstract tracer value encountered where concrete value is expected: Traced<ShapedArray(bool[], weak_type=True)>with<DynamicJaxprTrace(level=0/1)>\n",
            "The problem arose with the `bool` function. \n",
            "While tracing the function f at <ipython-input-86-b42e45c0293f>:1 for jit, this concrete value was not available in Python because it depends on the value of the argument 'x'.\n",
            "\n",
            "See https://jax.readthedocs.io/en/latest/errors.html#jax.errors.ConcretizationTypeError\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OW7NJMSe3d9E"
      },
      "source": [
        "Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1VB2Wtm3eb1"
      },
      "source": [
        "When we `jit`-compile a function, we usually want to compile a version of the function that works for many different argument values, so that we can cache and reuse the compiled code. That way we dont have to re-compile on each function evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deQYtOWG3jhj"
      },
      "source": [
        "For example, if we evaluate an `@jit` function on the array `jnp.array([1., 2., 3.], jnp.float32)`, we might want to compile code that we can reuse to evaluate the function on `jnp.array([4., 5., 6.], jnp.float32)` to save on compile time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cw8PnQou3r63"
      },
      "source": [
        "To get a view of your Python code that is valid for many different argument values, JAX traces it on *abstract values* that represent sets of possible inputs. There are [multiple different levels of abstraction](https://github.com/google/jax/blob/master/jax/_src/abstract_arrays.py), and different transformations use different abstraction levels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWyfSmT64Dsw"
      },
      "source": [
        "By default, `jit` traces your code on the `ShapedArray` abstraction level, where each abstract value represents the set of all array values with a fixed shape and dtype. For example, if we trace using the abstract value `ShapedArray((3,), jnp.float32)`, we get a view of the function that can be reused for any concrete value in the corresponding set of arrays. That means we can save on compile time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_meFAnT4exN"
      },
      "source": [
        "But theres a tradeoff here: if we trace a Python function on a `ShapedArray((), jnp.float32)` that isnt committed to a specific concrete value, when we hit a line like `if x < 3`, the expression `x < 3` evaluates to an abstract `ShapedArray((), jnp.bool_)` that represents the set `{True, False}`. When Python attempts to coerce that to a concrete `True` or `False`, we get an error: we dont know which branch to take, and cant continue tracing! The tradeoff is that with higher levels of abstraction we gain a more general view of the Python code (and thus save on re-compilations), but we require more constraints on the Python code to complete the trace."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrLEBqc54nPX"
      },
      "source": [
        "The good news is that you can control this tradeoff yourself. By having `jit` trace on more refined abstract values, you can relax the traceability constraints. For example, using the `static_argnums` argument to `jit`, we can specify to trace on concrete values of some arguments. Heres that example function again:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RF0kc9Fl4q59",
        "outputId": "337ac596-4d6c-4328-8a5b-e715d28ffe43"
      },
      "source": [
        "def f(x):\n",
        "  if x < 3:\n",
        "    return 3. * x ** 2\n",
        "  else:\n",
        "    return -4 * x\n",
        "\n",
        "f = jit(f, static_argnums=(0,))\n",
        "\n",
        "print(f(2.))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnMnY_qv4vDH"
      },
      "source": [
        "Heres another example, this time involving a loop:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hm7DwFNK4r37",
        "outputId": "f50c1e4c-1042-4a05-d597-207719832cc6"
      },
      "source": [
        "def f(x, n):\n",
        "  y = 0.\n",
        "  for i in range(n):\n",
        "    y = y + x[i]\n",
        "  return y\n",
        "\n",
        "f = jit(f, static_argnums=(1,))\n",
        "\n",
        "f(jnp.array([2., 3., 4.]), 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(5., dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFKTF9q4415d"
      },
      "source": [
        "In effect, the loop gets statically unrolled. JAX can also trace at higher levels of abstraction, like `Unshaped`, but thats not currently the default for any transformation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_DgUvnl5Bee"
      },
      "source": [
        "#####  functions with argument-value dependent shapes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjkmIpRg5D9t"
      },
      "source": [
        "These control-flow issues also come up in a more subtle way: numerical functions we want to **jit** cant specialize the shapes of internal arrays on argument *values* (specializing on argument *shapes* is ok). As a trivial example, lets make a function whose output happens to depend on the input variable `length`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aSyUNAa5Xf-",
        "outputId": "7755920d-e072-4bd3-ec1c-1c2bab957dac"
      },
      "source": [
        "def example_fun(length, val):\n",
        "  return jnp.ones((length,)) * val\n",
        "# un-jit'd works fine\n",
        "print(example_fun(5, 4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4. 4. 4. 4. 4.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJkH0ES55Y5M",
        "outputId": "02b8e973-dc73-4523-8dbe-abe5b60ebfec"
      },
      "source": [
        "bad_example_jit = jit(example_fun)\n",
        "# this will fail:\n",
        "try:\n",
        "  print(bad_example_jit(10, 4))\n",
        "except Exception as e:\n",
        "  print(\"Exception {}\".format(e))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exception Shapes must be 1D sequences of concrete values of integer type, got (Traced<ShapedArray(int32[], weak_type=True)>with<DynamicJaxprTrace(level=0/1)>,).\n",
            "If using `jit`, try using `static_argnums` or applying `jit` to smaller subfunctions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAgoPWe65epM",
        "outputId": "e1ff4664-7ac9-4b3c-9b05-452f698122f7"
      },
      "source": [
        "# static_argnums tells JAX to recompile on changes at these argument positions:\n",
        "good_example_jit = jit(example_fun, static_argnums=(0,))\n",
        "# first compile\n",
        "print(good_example_jit(10, 4))\n",
        "# recompiles\n",
        "print(good_example_jit(5, 4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4. 4. 4. 4. 4. 4. 4. 4. 4. 4.]\n",
            "[4. 4. 4. 4. 4.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBvEG17M5lUk"
      },
      "source": [
        "`static_argnums` can be handy if `length` in our example rarely changes, but it would be disastrous if it changed a lot!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGHchu4_5qN2"
      },
      "source": [
        "Lastly, if your function has global side-effects, JAXs tracer can cause weird things to happen. A common gotcha is trying to print arrays inside `jit`d functions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpTILv0c5wMT",
        "outputId": "65bb3ad4-485f-40d6-debd-c7d4e5ceb241"
      },
      "source": [
        "@jit\n",
        "def f(x):\n",
        "  print(x)\n",
        "  y = 2 * x\n",
        "  print(y)\n",
        "  return y\n",
        "f(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traced<ShapedArray(int32[], weak_type=True)>with<DynamicJaxprTrace(level=0/1)>\n",
            "Traced<ShapedArray(int32[], weak_type=True)>with<DynamicJaxprTrace(level=0/1)>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(4, dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wpp9XHz06Aer"
      },
      "source": [
        "#### Structured control flow primitives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDgY_duL6B-t"
      },
      "source": [
        "There are more options for control flow in JAX. Say you want to avoid re-compilations but still want to use control flow thats traceable, and that avoids un-rolling large loops. Then you can use these 4 structured control flow primitives:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9Nag7nu6Ijp"
      },
      "source": [
        "1. `lax.cond` (differentiable)\n",
        "\n",
        "2. `lax.while_loop` (**fwd-mode**-differentiable)\n",
        "\n",
        "3. `lax.fori_loop` (**fwd-mode**-differentiable)\n",
        "\n",
        "4. `lax.scan` (differentiable)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuxMHj956ZZj"
      },
      "source": [
        "##### `lax.cond`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gxR6rPT6d60"
      },
      "source": [
        "python equivalent:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VO1nI-y6fLz"
      },
      "source": [
        "def cond(pred, true_fun, false_fun, operand):\n",
        "  if pred:\n",
        "    return true_fun(operand)\n",
        "  else:\n",
        "    return false_fun(operand)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muqECt0W6gF3",
        "outputId": "4778ad3c-cc0d-4c8a-fe3b-08dfbb4ac2e3"
      },
      "source": [
        "from jax import lax\n",
        "\n",
        "operand = jnp.array([0.])\n",
        "lax.cond(True, lambda x: x+1, lambda x: x-1, operand)\n",
        "# --> array([1.], dtype=float32)\n",
        "lax.cond(False, lambda x: x+1, lambda x: x-1, operand)\n",
        "# --> array([-1.], dtype=float32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([-1.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0m_b5QP8BeE"
      },
      "source": [
        "##### `lax.while_loop`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtvz20la8Ehs"
      },
      "source": [
        "python equivalent:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpNx-AYl8Fq5"
      },
      "source": [
        "def while_loop(cond_fun, body_fun, init_val):\n",
        "  val = init_val\n",
        "  while cond_fun(val):\n",
        "    val = body_fun(val)\n",
        "  return val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR8tvHK-8GmS",
        "outputId": "26b34332-2566-4b4d-9f0c-b9918884443b"
      },
      "source": [
        "init_val = 0\n",
        "cond_fun = lambda x: x<10\n",
        "body_fun = lambda x: x+1\n",
        "lax.while_loop(cond_fun, body_fun, init_val)\n",
        "# --> array(10, dtype=int32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(10, dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZYXgF2h8RYy"
      },
      "source": [
        "##### `lax.fori_loop`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVxn9Oyh8WHF"
      },
      "source": [
        "python equivalent:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaDnRY7Y8UT9"
      },
      "source": [
        "def fori_loop(start, stop, body_fun, init_val):\n",
        "  val = init_val\n",
        "  for i in range(start, stop):\n",
        "    val = body_fun(i, val)\n",
        "  return val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJabFIgL8XGm",
        "outputId": "7cae7d6b-93a9-4f7a-c866-cef478753f8c"
      },
      "source": [
        "init_val = 0\n",
        "start = 0\n",
        "stop = 10\n",
        "body_fun = lambda i,x: x+i\n",
        "lax.fori_loop(start, stop, body_fun, init_val)\n",
        "# --> array(45, dtype=int32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(45, dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iAPs7wG8xwh"
      },
      "source": [
        "##### Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rkwJ7d48zdq"
      },
      "source": [
        "| Python      | jit | grad |\n",
        "| ----------- | ----------- | --- |\n",
        "| `if` |  | \n",
        "| `for` | * | \n",
        "| `while` | * | \n",
        "| `lax.cond` |  | \n",
        "| `lax.while_loop` |  | fwd\n",
        "| `lax.fori_loop` |  | fwd\n",
        "| `lax.scan` |  | \n",
        "\n",
        "\\*  argument-__value__-independent loop condition - unrolls the loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_O__mrzm-eUe"
      },
      "source": [
        "### NaNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EeWgDYB-hgP"
      },
      "source": [
        "#### Debugging NaNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1y_aAhF-lSd"
      },
      "source": [
        "If you want to trace where NaNs are occurring in your functions or gradients, you can turn on the NaN-checker by:\n",
        "\n",
        "- setting the `JAX_DEBUG_NANS=True` environment variable\n",
        "\n",
        "- adding the following code near the top of your main file:\n",
        "```py\n",
        "from jax.config import config\n",
        "config.update(\"jax_debug_nans\", True)\n",
        "```\n",
        "\n",
        "- adding the following code to your main file, then set the option using a command-line flag like `--jax_debug_nans=True`:\n",
        "```py\n",
        "from jax.config import config\n",
        "config.parse_flags_with_absl()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1rVe_Pd-8by"
      },
      "source": [
        "This will cause computations to error-out immediately on production of a NaN. Switching this option on adds a nan check to every floating point type value produced by XLA. That means values are pulled back to the host and checked as ndarrays for every primitive operation not under an `@jit`. For code under an `@jit`, the output of every `@jit` function is checked and if a nan is present it will re-run the function in de-optimized op-by-op mode, effectively removing one level of `@jit` at a time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLo9xoR0_fbr"
      },
      "source": [
        "There could be tricky situations that arise, like nans that only occur under a `@jit` but dont get produced in de-optimized mode. In that case youll see a warning message print out but your code will continue to execute."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BjG53nn_h7z"
      },
      "source": [
        "If the nans are being produced in the backward pass of a gradient evaluation, when an exception is raised several frames up in the stack trace you will be in the backward_pass function, which is essentially a simple jaxpr interpreter that walks the sequence of primitive operations in reverse. In the example below, we started an ipython repl with the command line `env JAX_DEBUG_NANS=True ipython`, then ran this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "L3evg1Oq_qpY",
        "outputId": "7fc13976-6b65-473b-e667-7e35c3efb6b3"
      },
      "source": [
        "import jax.numpy as jnp\n",
        "from jax.config import config\n",
        "config.update(\"jax_debug_nans\", True)\n",
        "jnp.divide(0., 0.)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FloatingPointError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-103-48c0c4bb9ca9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"jax_debug_nans\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdivide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mtrue_divide\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrue_divide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m   \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_promote_args_inexact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"true_divide\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0mdivide\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_divide\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36mdiv\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m   \u001b[0;34mr\"\"\"Elementwise division: :math:`x \\over y`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mdiv_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    262\u001b[0m         args, used_axis_names(self, params) if self._dispatch_on_params else None)\n\u001b[1;32m    263\u001b[0m     \u001b[0mtracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiple_results\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfull_lower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36mapply_primitive\u001b[0;34m(prim, *args, **params)\u001b[0m\n\u001b[1;32m    247\u001b[0m   \u001b[0;34m\"\"\"Impl rule that compiles and runs a single primitive 'prim' using XLA.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m   \u001b[0mcompiled_fun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxla_primitive_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0munsafe_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mcompiled_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_execute_compiled_primitive\u001b[0;34m(prim, compiled, result_handler, *args)\u001b[0m\n\u001b[1;32m    364\u001b[0m   \u001b[0minput_bufs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_put\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m   \u001b[0mout_bufs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m   \u001b[0mcheck_special\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mout_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36mcheck_special\u001b[0;34m(name, bufs)\u001b[0m\n\u001b[1;32m    383\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mneeds_check_special\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbufs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m       \u001b[0m_check_special\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxla_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_special\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxla_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_check_special\u001b[0;34m(name, xla_shape, buf)\u001b[0m\n\u001b[1;32m    389\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxla_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melement_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minexact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjax_debug_nans\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mFloatingPointError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"invalid value (nan) encountered in {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjax_debug_infs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mFloatingPointError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"invalid value (inf) encountered in {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFloatingPointError\u001b[0m: invalid value (nan) encountered in div"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xz7TP7erAA4q"
      },
      "source": [
        "The nan generated was caught. By running `%debug`, we can get a post-mortem debugger."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xc0_UivC_tce",
        "outputId": "39dc1144-afdf-42ed-ae29-1090c7a296d0"
      },
      "source": [
        "%debug"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> \u001b[0;32m/home/shawn/.local/lib/python3.8/site-packages/jax/interpreters/xla.py\u001b[0m(391)\u001b[0;36m_check_special\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m    389 \u001b[0;31m  \u001b[0;32mif\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxla_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melement_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minexact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    390 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjax_debug_nans\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m--> 391 \u001b[0;31m      \u001b[0;32mraise\u001b[0m \u001b[0mFloatingPointError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"invalid value (nan) encountered in {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    392 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjax_debug_infs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    393 \u001b[0;31m      \u001b[0;32mraise\u001b[0m \u001b[0mFloatingPointError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"invalid value (inf) encountered in {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsuYcNozATEj"
      },
      "source": [
        "This also works with functions under `@jit`, as the example below shows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ky5127SP_-HA",
        "outputId": "675e76fe-23fa-4603-97ad-32e6aa23d035"
      },
      "source": [
        "from jax import jit\n",
        "\n",
        "@jit\n",
        "def f(x, y):\n",
        "     a = x * y\n",
        "     b = (x + y) / (x - y)\n",
        "     c = a + 2\n",
        "     return a + b * c\n",
        "\n",
        "x = jnp.array([2., 0.])\n",
        "y = jnp.array([3., 0.])\n",
        "f(x, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Invalid value encountered in the output of a jit function. Calling the de-optimized version.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FloatingPointError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_execute_compiled\u001b[0;34m(compiled, avals, handlers, kept_var_idx, *args)\u001b[0m\n\u001b[1;32m    893\u001b[0m   \u001b[0mout_bufs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m   \u001b[0mcheck_special\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxla_call_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandlers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_partition_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36mcheck_special\u001b[0;34m(name, bufs)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbufs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m       \u001b[0m_check_special\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxla_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_check_special\u001b[0;34m(name, xla_shape, buf)\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjax_debug_nans\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mFloatingPointError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"invalid value (nan) encountered in {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjax_debug_infs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFloatingPointError\u001b[0m: invalid value (nan) encountered in xla_call",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-115-2876ed9a8b85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "    \u001b[0;31m[... skipping hidden 8 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-115-2876ed9a8b85>\u001b[0m in \u001b[0;36mf\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m      \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m      \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m      \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m      \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mdeferring_binary_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   5817\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_scalar_types\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_arraylike_types\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTracer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5818\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5819\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5820\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdeferring_binary_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mtrue_divide\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrue_divide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m   \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_promote_args_inexact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"true_divide\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0mdivide\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_divide\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 6 frame]\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_check_special\u001b[0;34m(name, xla_shape, buf)\u001b[0m\n\u001b[1;32m    389\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxla_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melement_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minexact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjax_debug_nans\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mFloatingPointError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"invalid value (nan) encountered in {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjax_debug_infs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mFloatingPointError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"invalid value (inf) encountered in {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFloatingPointError\u001b[0m: invalid value (nan) encountered in div"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wr-UHgr_Agf4",
        "outputId": "a6cacad3-44af-4640-97f9-a03c44713063"
      },
      "source": [
        "%debug"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> \u001b[0;32m/home/shawn/.local/lib/python3.8/site-packages/jax/interpreters/xla.py\u001b[0m(391)\u001b[0;36m_check_special\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m    389 \u001b[0;31m  \u001b[0;32mif\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxla_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melement_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minexact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    390 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjax_debug_nans\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m--> 391 \u001b[0;31m      \u001b[0;32mraise\u001b[0m \u001b[0mFloatingPointError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"invalid value (nan) encountered in {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    392 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjax_debug_infs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    393 \u001b[0;31m      \u001b[0;32mraise\u001b[0m \u001b[0mFloatingPointError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"invalid value (inf) encountered in {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> bt\n",
            "  \u001b[0;32m<ipython-input-115-2876ed9a8b85>\u001b[0m(12)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[1;32m      8 \u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m      9 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     10 \u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     11 \u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m---> 12 \u001b[0;31m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[0;31m    [... skipping 8 hidden frame(s)]\u001b[0m\n",
            "\n",
            "  \u001b[0;32m<ipython-input-115-2876ed9a8b85>\u001b[0m(6)\u001b[0;36mf\u001b[0;34m()\u001b[0m\n",
            "\u001b[1;32m      4 \u001b[0m\u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m      5 \u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m----> 6 \u001b[0;31m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[1;32m      7 \u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m      8 \u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "  \u001b[0;32m/home/shawn/.local/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py\u001b[0m(5819)\u001b[0;36mdeferring_binary_op\u001b[0;34m()\u001b[0m\n",
            "\u001b[1;32m   5817 \u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_scalar_types\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_arraylike_types\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTracer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m   5818 \u001b[0m      \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m-> 5819 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[1;32m   5820 \u001b[0m  \u001b[0;32mreturn\u001b[0m \u001b[0mdeferring_binary_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m   5821 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "  \u001b[0;32m/home/shawn/.local/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py\u001b[0m(573)\u001b[0;36mtrue_divide\u001b[0;34m()\u001b[0m\n",
            "\u001b[1;32m    571 \u001b[0m\u001b[0;32mdef\u001b[0m \u001b[0mtrue_divide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    572 \u001b[0m  \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_promote_args_inexact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"true_divide\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 573 \u001b[0;31m  \u001b[0;32mreturn\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[1;32m    574 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    575 \u001b[0m\u001b[0mdivide\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_divide\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;31m    [... skipping 6 hidden frame(s)]\u001b[0m\n",
            "\n",
            "> \u001b[0;32m/home/shawn/.local/lib/python3.8/site-packages/jax/interpreters/xla.py\u001b[0m(391)\u001b[0;36m_check_special\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m    389 \u001b[0;31m  \u001b[0;32mif\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxla_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melement_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minexact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    390 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjax_debug_nans\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m--> 391 \u001b[0;31m      \u001b[0;32mraise\u001b[0m \u001b[0mFloatingPointError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"invalid value (nan) encountered in {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    392 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjax_debug_infs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    393 \u001b[0;31m      \u001b[0;32mraise\u001b[0m \u001b[0mFloatingPointError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"invalid value (inf) encountered in {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZG1lu3cAyIT"
      },
      "source": [
        "When this code sees a nan in the output of an `@jit` function, it calls into the de-optimized code, so we still get a clear stack trace. And we can run a post-mortem debugger with `%debug` to inspect all the values to figure out the error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-T7m3g8A20Q"
      },
      "source": [
        " You shouldnt have the NaN-checker on if youre not debugging, as it can introduce lots of device-host round-trips and performance regressions!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4QrTwx4CQzK"
      },
      "source": [
        "### Double (64bit) precision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "856tc3a5CUhV"
      },
      "source": [
        "At the moment, JAX by default enforces single-precision numbers to mitigate the Numpy APIs tendency to aggressively promote operands to `double`. This is the desired behavior for many machine-learning applications, but it may catch you by surprise!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGl17QAqCXfo",
        "outputId": "1e50d41c-fd4c-42ec-a0e8-56407ffae6c6"
      },
      "source": [
        "x = random.uniform(random.PRNGKey(0), (1000,), dtype=jnp.float64)\n",
        "x.dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float32')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9C9sCF12CbOD"
      },
      "source": [
        "To use double-precision numbers, you need to set the `jax_enable_x64` configuration variable at startup.\n",
        "\n",
        "There are a few ways to do this:\n",
        "\n",
        "1. You can enable 64bit mode by setting the environment variable `JAX_ENABLE_X64=True`.\n",
        "\n",
        "2. You can manually set the `jax_enable_x64` configuration flag at startup:\n",
        "```py\n",
        "# again, this only works on startup!\n",
        "from jax.config import config\n",
        "config.update(\"jax_enable_x64\", True)\n",
        "```\n",
        "\n",
        "3. You can parse command-line flags with `absl.app.run(main)`\n",
        "```py\n",
        "from jax.config import config\n",
        "config.config_with_absl()\n",
        "```\n",
        "\n",
        "4. If you want JAX to run absl parsing for you, i.e. you dont want to do `absl.app.run(main)`, you can instead use\n",
        "```py\n",
        "from jax.config import config\n",
        "if __name__ == '__main__':\n",
        "  # calls config.config_with_absl() *and* runs absl parsing\n",
        "  config.parse_flags_with_absl()\n",
        "```\n",
        "\n",
        "Note that #2-#4 work for any of JAXs configuration options.\n",
        "\n",
        "We can then confirm that `x64` mode is enabled:\n",
        "```py\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "x = random.uniform(random.PRNGKey(0), (1000,), dtype=jnp.float64)\n",
        "x.dtype # --> dtype('float64')\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKzyLJD2C7-7"
      },
      "source": [
        "#### Caveats\n",
        "\n",
        " XLA doesnt support 64-bit convolutions on all backends!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvhm9XyKDUKh"
      },
      "source": [
        "## Tutorial 3: [JAX 101](https://jax.readthedocs.io/en/latest/jax-101/index.html)\n",
        "\n",
        "This is a tutorial developed by engineers and researchers at DeepMind."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3xUnl4ODdEh"
      },
      "source": [
        "### JAX As Accelerated NumPy\n",
        "\n",
        "In this first section you will learn the very fundamentals of JAX."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFwYypMbD3jn"
      },
      "source": [
        "#### Getting started with JAX numpy\n",
        "\n",
        "Fundamentally, JAX is a library that enables transformations of array-manipulating programs written with a NumPy-like API.\n",
        "\n",
        "Over the course of this series of guides, we will unpack exactly what that means. For now, you can think of JAX as *differentiable NumPy* that runs on *accelerators*.\n",
        "\n",
        "The code below shows how to import JAX and create a vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJCxwN44D-D3",
        "outputId": "251fba7d-159b-4bbc-8a1d-b37b521e8e45"
      },
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "x = jnp.arange(10)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4 5 6 7 8 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u54q1DuEBNr"
      },
      "source": [
        "So far, everything is just like NumPy. A big appeal of JAX is that you dont need to learn a new API. Many common NumPy programs would run just as well in JAX if you substitute `np` for `jnp`. However, there are some important differences which we touch on at the end of this section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PEIB5QUEGg6"
      },
      "source": [
        "You can notice the first difference if you check the type of `x`. It is a variable of type `DeviceArray`, which is the way JAX represents arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dquhjnV0EIF-",
        "outputId": "1ba376f4-fcd0-4bcc-a831-4ef100ca5fda"
      },
      "source": [
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PenZ-u39ELOh"
      },
      "source": [
        "One useful feature of JAX is that the same code can be run on different backends  CPU, GPU and TPU.\n",
        "\n",
        "We will now perform a dot product to demonstrate that it can be done in different devices without changing the code. We use `%timeit` to check the performance.\n",
        "\n",
        "(Technical detail: when a JAX function is called, the corresponding operation is dispatched to an accelerator to be computed asynchronously when possible. The returned array is therefore not necessarily filled in as soon as the function returns. Thus, if we dont require the result immediately, the computation wont block Python execution. Therefore, unless we `block_until_ready`, we will only time the dispatch, not the actual computation. See [Asynchronous dispatch](https://jax.readthedocs.io/en/latest/async_dispatch.html) in the JAX docs.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTFbF9JZEZmP",
        "outputId": "f833e45b-1473-461d-f798-f34e4c5e9d51"
      },
      "source": [
        "long_vector = jnp.arange(int(1e7))\n",
        "\n",
        "%timeit jnp.dot(long_vector, long_vector).block_until_ready()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "818 s  194 s per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7M7UtvRFC-j"
      },
      "source": [
        "Tip: Try running the code above twice, once without an accelerator, and once with a GPU runtime (while in Colab, click Runtime  Change Runtime Type and choose GPU). Notice how much faster it runs on a GPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrgbXKTxFFC5"
      },
      "source": [
        "from jax import jit\n",
        "from functools import partial\n",
        "\n",
        "@partial(jax.jit, device=jax.devices(\"cpu\")[0])\n",
        "def on_cpu(x):\n",
        "  return jnp.dot(x, x)\n",
        "\n",
        "@jax.jit\n",
        "def on_mxu(x):\n",
        "  return jnp.dot(x, x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBdZ9BvPFZv0",
        "outputId": "3b91845e-c629-47b2-b670-41f5ba3b11c8"
      },
      "source": [
        "long_vector = jnp.arange(int(1e7))\n",
        "%timeit on_cpu(long_vector).block_until_ready()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10.3 ms  209 s per loop (mean  std. dev. of 7 runs, 100 loops each)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcFTwH7uFlGQ",
        "outputId": "b16c7c2f-00b8-4f2e-b971-1022d70b9cb7"
      },
      "source": [
        "long_vector = jnp.arange(int(1e7))\n",
        "%timeit on_mxu(long_vector).block_until_ready()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "476 s  9.58 s per loop (mean  std. dev. of 7 runs, 1000 loops each)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-wjUIYlGFHq"
      },
      "source": [
        "#### JAX first transformation: `grad`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpsOv7f4GJqT"
      },
      "source": [
        "A fundamental feature of JAX is that it allows you to transform functions.\n",
        "\n",
        "One of the most commonly used transformations is `jax.grad`, which takes a numerical function written in Python and returns you a new Python function that computes the gradient of the original function.\n",
        "\n",
        "To use it, lets first define a function that takes an array and returns the sum of squares."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkegC7L2GSxv"
      },
      "source": [
        "def sum_of_squares(x):\n",
        "  return jnp.sum(x**2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyqLo-N8GVhU"
      },
      "source": [
        "Applying `jax.grad` to `sum_of_squares` will return a different function, namely the gradient of `sum_of_squares` with respect to its first parameter `x`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pA4llasrGbcO"
      },
      "source": [
        "sum_of_squares_dx = jax.grad(sum_of_squares)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwJk88PJGcDT"
      },
      "source": [
        "Then, you can use that function on an array to return the derivatives with respect to each element of the array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JIphjyBGc0A"
      },
      "source": [
        "x = jnp.asarray([1.0, 2.0, 3.0, 4.0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y62CBeYLGisH",
        "outputId": "aa3448a9-155f-47d1-8b85-2d141b928f5b"
      },
      "source": [
        "sum_of_squares(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(30., dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0hNV5fQGk0c",
        "outputId": "902f1f04-e8fa-4412-c4f2-50a53643c6e2"
      },
      "source": [
        "sum_of_squares_dx(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([2., 4., 6., 8.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYMP8Xc2Gtka"
      },
      "source": [
        "You can think of jax.grad by analogy to the  operator from vector calculus. Given a function (),  represents the function that computes s gradient, i.e.\n",
        "\n",
        "()()_ = ( / _)().\n",
        "\n",
        "Analogously, `jax.grad(f)` is the function that computes the gradient, so `jax.grad(f)(x)` is the gradient of `f` at `x`.\n",
        "\n",
        "(Like , `jax.grad` will only work on functions with a scalar output  it will raise an error otherwise.)\n",
        "\n",
        " This makes the JAX API quite different to other autodiff libraries like Tensorflow and PyTorch, where to compute the gradient we use the loss tensor itself (e.g. by calling `loss.backward()`). The JAX API works directly with functions, staying closer to the underlying math. Once you become accustomed to this way of doing things, it feels natural: your loss function in code really is a function of parameters and data, and you find its gradient just like you would in the math.\n",
        "\n",
        "This way of doing things makes it straightforward to control things like which variables to differentiate with respect to. By default, `jax.grad` will find the gradient with respect to the first argument. In the example below, the result of `sum_squared_error_dx` will be the gradient of `sum_squared_error` with respect to `x`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xET43EFDHrPn",
        "outputId": "21d91de5-a4d9-4117-ba99-8ba488fe2ace"
      },
      "source": [
        "def sum_squared_error(x, y):\n",
        "  return jnp.sum((x-y)**2)\n",
        "\n",
        "sum_squared_error_dx = jax.grad(sum_squared_error)\n",
        "\n",
        "y = jnp.asarray([1.1, 2.1, 3.1, 4.1])\n",
        "\n",
        "print(sum_squared_error_dx(x, y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.20000005 -0.19999981 -0.19999981 -0.19999981]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmQnGDwSHwim"
      },
      "source": [
        "To find the gradient with respect to a different argument (or several), you can set argnums:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9jPNDFYHyNE",
        "outputId": "340bb5d1-b04f-43a4-fb50-918b21ba46ba"
      },
      "source": [
        "jax.grad(sum_squared_error, argnums=(0, 1))(x, y)  # Find gradient wrt both x & y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(DeviceArray([-0.20000005, -0.19999981, -0.19999981, -0.19999981], dtype=float32),\n",
              " DeviceArray([0.20000005, 0.19999981, 0.19999981, 0.19999981], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO2sTGh4IBVW"
      },
      "source": [
        "Does this mean that when doing machine learning, we need to write functions with gigantic argument lists, with an argument for each model parameter array? No. JAX comes equipped with machinery for bundling arrays together in data structures called pytrees, on which more in a [later guide](https://colab.research.google.com/github/google/jax/blob/master/docs/jax-101/05.1-pytrees.ipynb). So, most often, use of `jax.grad` looks like this:\n",
        "\n",
        "```py\n",
        "def loss_fn(params, data):\n",
        "  ...\n",
        "\n",
        "grads = jax.grad(loss_fn)(params, data_batch)\n",
        "```\n",
        "\n",
        "where `params` is, for example, a nested dict of arrays, and the returned `grads` is another nested dict of arrays with the same structure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUGSQa5fIZld"
      },
      "source": [
        "#### Value and Grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_p1LSQCIb6c"
      },
      "source": [
        "Often, you need to find both the value and the gradient of a function, e.g. if you want to log the training loss. JAX has a handy sister transformation for efficiently doing that:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "We7gSxAiIgAp",
        "outputId": "55d26341-b398-441d-d57c-6dffdf3970e3"
      },
      "source": [
        "jax.value_and_grad(sum_squared_error)(x, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(DeviceArray(0.03999995, dtype=float32),\n",
              " DeviceArray([-0.20000005, -0.19999981, -0.19999981, -0.19999981], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_EgS67RIkxX"
      },
      "source": [
        "which returns a tuple of, you guessed it, (value, grad). To be precise, for any `f`,\n",
        "\n",
        "```py\n",
        "jax.value_and_grad(f)(*xs) == (f(*xs), jax.grad(f)(*xs)) \n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qj3nz-WJIqzc"
      },
      "source": [
        "#### Auxiliary data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FVMFxmbIr7a"
      },
      "source": [
        "In addition to wanting to log the value, we often want to report some intermediate results obtained in computing the loss function. But if we try doing that with regular `jax.grad`, we run into trouble:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702
        },
        "id": "vSLU8e1HIwQ-",
        "outputId": "bde75f13-4024-4c6d-ef09-026e3858c4b6"
      },
      "source": [
        "def squared_error_with_aux(x, y):\n",
        "  return sum_squared_error(x, y), x-y\n",
        "\n",
        "jax.grad(squared_error_with_aux)(x, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/core.py\u001b[0m in \u001b[0;36mget_aval\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcrete_aval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/core.py\u001b[0m in \u001b[0;36mconcrete_aval\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    915\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcrete_aval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__jax_array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m   raise TypeError(f\"Value {repr(x)} with type {type(x)} is not a valid JAX \"\n\u001b[0m\u001b[1;32m    917\u001b[0m                    \"type\")\n",
            "\u001b[0;31mTypeError\u001b[0m: Value (DeviceArray(0.03999995, dtype=float32), DeviceArray([-0.10000002, -0.0999999 , -0.0999999 , -0.0999999 ], dtype=float32)) with type <class 'tuple'> is not a valid JAX type",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-138-7433a86e7375>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msum_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msquared_error_with_aux\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "    \u001b[0;31m[... skipping hidden 4 frame]\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/api.py\u001b[0m in \u001b[0;36m_check_scalar\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    900\u001b[0m     \u001b[0maval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_aval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"was {x}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mShapedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Gradient only defined for scalar-output functions. Output was (DeviceArray(0.03999995, dtype=float32), DeviceArray([-0.10000002, -0.0999999 , -0.0999999 , -0.0999999 ], dtype=float32))."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CAbws3TI6Hk"
      },
      "source": [
        "This is because `jax.grad` is only defined on scalar functions, and our new function returns a tuple. But we need to return a tuple to return our intermediate results! This is where `has_aux` comes in:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjSsGteWI9Mu",
        "outputId": "d4d52d41-9b79-4b63-86a4-4f633bbd9769"
      },
      "source": [
        "jax.grad(squared_error_with_aux, has_aux=True)(x, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(DeviceArray([-0.20000005, -0.19999981, -0.19999981, -0.19999981], dtype=float32),\n",
              " DeviceArray([-0.10000002, -0.0999999 , -0.0999999 , -0.0999999 ], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXaM5s37I_vs"
      },
      "source": [
        "`has_aux` signifies that the function returns a pair, `(out, aux)`. It makes `jax.grad` ignore `aux`, passing it through to the user, while differentiating the function as if only `out` was returned."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZC84HcQ2JmsN"
      },
      "source": [
        "#### Differences from NumPy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyIFdEerJoQc"
      },
      "source": [
        "The `jax.numpy` API closely follows that of NumPy. However, there are some important differences. We cover many of these in future guides, but its worth pointing some out now.\n",
        "\n",
        "The most important difference, and in some sense the root of all the rest, is that JAX is designed to be *functional*, as in *functional programming*. The reason behind this is that the kinds of program transformations that JAX enables are much more feasible in functional-style programs.\n",
        "\n",
        "An introduction to functional programming (FP) is out of scope of this guide. If you already are familiar with FP, you will find your FP intuition helpful while learning JAX. If not, dont worry! The important feature of functional programming to grok when working with JAX is very simple: dont write code with side-effects.\n",
        "\n",
        "A side-effect is any effect of a function that doesnt appear in its output. One example is modifying an array in place:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZ05M-9VJ2i6",
        "outputId": "638c0c4c-2147-4d9a-c9b6-a539d74264c1"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.array([1, 2, 3])\n",
        "\n",
        "def in_place_modify(x):\n",
        "  x[0] = 123\n",
        "  return None\n",
        "\n",
        "in_place_modify(x)\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([123,   2,   3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZD8d-LXJ60-"
      },
      "source": [
        "The side-effectful function modifies its argument, but returns a completely unrelated value. The modification is a side-effect.\n",
        "\n",
        "The code below will run in NumPy. However, JAX arrays wont allow themselves to be modified in-place:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "Isnx3ozYJ84-",
        "outputId": "ee00e380-f541-4bc0-a617-c615d2c5b5c5"
      },
      "source": [
        "in_place_modify(jnp.array(x))  # Raises error when we cast input to jnp.ndarray"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-141-709e2d7ddd3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0min_place_modify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Raises error when we cast input to jnp.ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-140-fce65eb843c7>\u001b[0m in \u001b[0;36min_place_modify\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0min_place_modify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m123\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_unimplemented_setitem\u001b[0;34m(self, i, x)\u001b[0m\n\u001b[1;32m   5827\u001b[0m          \u001b[0;34m\"immutable; perhaps you want jax.ops.index_update or \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5828\u001b[0m          \"jax.ops.index_add instead?\")\n\u001b[0;32m-> 5829\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5831\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_operator_round\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndigits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '<class 'jaxlib.xla_extension.DeviceArray'>' object does not support item assignment. JAX arrays are immutable; perhaps you want jax.ops.index_update or jax.ops.index_add instead?"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCAsGJ8IKBJP"
      },
      "source": [
        "Helpfully, the error points us to JAXs side-effect-free way of doing the same thing via the `jax.ops.index_*` ops. They are analogous to in-place modification by index, but create a new array with the corresponding modifications made:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTfwpLYVKDZx",
        "outputId": "5b42bdcc-5aac-4422-f07f-11305ed3cb41"
      },
      "source": [
        "def jax_in_place_modify(x):\n",
        "  return jax.ops.index_update(x, 0, 123)\n",
        "\n",
        "y = jnp.array([1, 2, 3])\n",
        "jax_in_place_modify(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([123,   2,   3], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6VssIh5KGHg"
      },
      "source": [
        "Note that the old array was untouched, so there is no side-effect:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5jrLnF6KHmf",
        "outputId": "0f634c81-d1a2-4d75-c688-3c6ac3b8ccbb"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([1, 2, 3], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzsYYbOYKJ1p"
      },
      "source": [
        "Side-effect-free code is sometimes called *functionally pure*, or just *pure*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fpBV39lKP-9"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mq23G4mUKRMQ"
      },
      "source": [
        "Isnt the pure version less efficient? Strictly, yes; we are creating a new array. However, as we will explain in the next guide, JAX computations are often compiled before being run using another program transformation, `jax.jit`. If we dont use the old array after modifying it in place using `jax.ops.index_update()`, the compiler can recognise that it can in fact compile to an in-place modify, resulting in efficient code in the end.\n",
        "\n",
        "Of course, its possible to mix side-effectful Python code and functionally pure JAX code, and we will touch on this more later. As you get more familiar with JAX, you will learn how and when this can work. As a rule of thumb, however, any functions intended to be transformed by JAX should avoid side-effects, and the JAX primitives themselves will try to help you do that.\n",
        "\n",
        "We will explain other places where the JAX idiosyncracies become relevant as they come up. There is even a section that focuses entirely on getting used to the functional programming style of handling state: [Part 7: Problem of State](https://colab.research.google.com/github/google/jax/blob/master/docs/jax-101/07-state.ipynb). However, if youre impatient, you can find a summary of [JAXs sharp edges](https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html) in the JAX docs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mGagFc2K8Xp"
      },
      "source": [
        "#### Your first JAX training loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZHTX5uzK-Ay"
      },
      "source": [
        "We still have much to learn about JAX, but you already know enough to understand how we can use JAX to build a simple training loop.\n",
        "\n",
        "To keep things simple, well start with a linear regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyZFTAgeLBsb"
      },
      "source": [
        "Our data is sampled according to  = _  + _ + ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "a9ddoCRPLL0a",
        "outputId": "f9c3bf1e-ab0a-4f64-8504-2e015e625cc9"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "xs = np.random.normal(size=(100,))\n",
        "noise = np.random.normal(scale=0.1, size=(100,))\n",
        "ys = xs * 3 - 1 + noise\n",
        "\n",
        "plt.scatter(xs, ys);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4ru4WHLLO1W"
      },
      "source": [
        "Therefore, our model is  (; ) =  + ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b4Bf7bwLUua"
      },
      "source": [
        "We will use a single array, theta = [w, b] to house both parameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rwo5_b3lLXi6"
      },
      "source": [
        "def model(theta, x):\n",
        "  \"\"\"Computes wx + b on a batch of input x.\"\"\"\n",
        "  w, b = theta\n",
        "  return w * x + b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "864XV_jVLZm7"
      },
      "source": [
        "The loss function is (,; ) = ( )^2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yA1ypG3LfJN"
      },
      "source": [
        "def loss_fn(theta, x, y):\n",
        "  prediction = model(theta, x)\n",
        "  return jnp.mean((prediction-y)**2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJSS_NqOLhkT"
      },
      "source": [
        "How do we optimize a loss function? Using gradient descent. At each update step, we will find the gradient of the loss w.r.t. the parameters, and take a small step in the direction of steepest descent:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zppzMfTmLs2j"
      },
      "source": [
        "_ =   0.1(_ )(,; )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3GMIXjCLr2I"
      },
      "source": [
        "def update(theta, x, y, lr=0.1):\n",
        "  return theta - lr * jax.grad(loss_fn)(theta, x, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MplC0mnL1l2"
      },
      "source": [
        "In JAX, its common to define an `update()` function that is called every step, taking the current parameters as input and returning the new parameters. This is a natural consequence of JAXs functional nature, and is explained in more detail in [The Problem of State](https://colab.research.google.com/github/google/jax/blob/master/docs/jax-101/07-state.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLzbPXFFL7Yq"
      },
      "source": [
        "This function can then be JIT-compiled in its entirety for maximum efficiency. The next guide will explain exactly how `jax.jit` works, but if you want to, you can try adding @jax.jit before the update() definition, and see how the training loop below runs much faster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "qRVqgNFzL_d7",
        "outputId": "9fa45047-bec4-438c-b292-9d3ec59a91dd"
      },
      "source": [
        "%%time\n",
        "theta = jnp.array([1., 1.])\n",
        "\n",
        "for _ in range(1000):\n",
        "  theta = update(theta, xs, ys)\n",
        "\n",
        "plt.scatter(xs, ys)\n",
        "plt.plot(xs, model(theta, xs))\n",
        "\n",
        "w, b = theta\n",
        "print(f\"w: {w:<.2f}, b: {b:<.2f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w: 3.00, b: -1.01\n",
            "CPU times: user 23.8 s, sys: 9.08 s, total: 32.9 s\n",
            "Wall time: 22.3 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "dTeZZKl_MIaq",
        "outputId": "a772a50c-174f-412c-b772-798641d088e7"
      },
      "source": [
        "%%time\n",
        "update_jit = jit(update)\n",
        "\n",
        "theta = jnp.array([1., 1.])\n",
        "\n",
        "for _ in range(1000):\n",
        "  theta = update_jit(theta, xs, ys)\n",
        "\n",
        "plt.scatter(xs, ys)\n",
        "plt.plot(xs, model(theta, xs))\n",
        "\n",
        "w, b = theta\n",
        "print(f\"w: {w:<.2f}, b: {b:<.2f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w: 3.00, b: -1.01\n",
            "CPU times: user 850 ms, sys: 429 ms, total: 1.28 s\n",
            "Wall time: 815 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qd8iqg9Mbr6"
      },
      "source": [
        "As you will see going through these guides, this basic recipe underlies almost all training loops youll see implemented in JAX. The main difference between this example and real training loops is the simplicity of our model: that allows us to use a single array to house all our parameters. We cover managing more parameters in the later [pytree guide](https://colab.research.google.com/github/google/jax/blob/master/docs/jax-101/05.1-pytrees.ipynb). Feel free to skip forward to that guide now to see how to manually define and train a simple MLP in JAX."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTbOLdyNPc6Q"
      },
      "source": [
        "### Working with Pytrees"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfV3IjHCPeSA"
      },
      "source": [
        "Often, we want to operate on objects that look like dicts of arrays, or lists of lists of dicts, or other nested structures. In JAX, we refer to these as *pytrees*, but you can sometimes see them called *nests*, or just *trees*.\n",
        "\n",
        "JAX has built-in support for such objects, both in its library functions as well as through the use of functions from `jax.tree_utils` (with the most common ones also available as `jax.tree_*`). This section will explain how to use them, give some useful snippets and point out common gotchas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnzYfZoBPrbb"
      },
      "source": [
        "#### What is a pytree?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJiHhEsLPswi"
      },
      "source": [
        "As defined in the JAX pytree docs:\n",
        "\n",
        "> a pytree is a container of leaf elements and/or more pytrees. Containers include lists, tuples, and dicts. A leaf element is anything thats not a pytree, e.g. an array. In other words, a pytree is just a possibly-nested standard or user-registered Python container. If nested, note that the container types do not need to match. A single leaf, i.e. a non-container object, is also considered a pytree."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHuVBCFsPxUj"
      },
      "source": [
        "Some example pytrees:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JisytiJFPzPP",
        "outputId": "a7cb454d-72da-4faf-cc8e-59b0e49113eb"
      },
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "example_trees = [\n",
        "    [1, 'a', object()],\n",
        "    (1, (2, 3), ()),\n",
        "    [1, {'k1': 2, 'k2': (3, 4)}, 5],\n",
        "    {'a': 2, 'b': (2, 3)},\n",
        "    jnp.array([1, 2, 3]),\n",
        "]\n",
        "\n",
        "# Let's see how many leaves they have:\n",
        "for pytree in example_trees:\n",
        "  leaves = jax.tree_leaves(pytree)\n",
        "  print(f\"{repr(pytree):<45} has {len(leaves)} leaves: {leaves}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 'a', <object object at 0x7f8a09c02df0>]   has 3 leaves: [1, 'a', <object object at 0x7f8a09c02df0>]\n",
            "(1, (2, 3), ())                               has 3 leaves: [1, 2, 3]\n",
            "[1, {'k1': 2, 'k2': (3, 4)}, 5]               has 5 leaves: [1, 2, 3, 4, 5]\n",
            "{'a': 2, 'b': (2, 3)}                         has 3 leaves: [2, 2, 3]\n",
            "DeviceArray([1, 2, 3], dtype=int32)           has 1 leaves: [DeviceArray([1, 2, 3], dtype=int32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTVNb1EvP82W"
      },
      "source": [
        "Weve also introduced our first `jax.tree_*` function, which allowed us to extract the flattened leaves from the trees."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5DHCRoSP_AS"
      },
      "source": [
        "#### Why pytrees?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iz7ms_WpP_6X"
      },
      "source": [
        "In machine learning, some places where you commonly find pytrees are:\n",
        "\n",
        "- Model parameters\n",
        "- Dataset entries\n",
        "- RL agent observations\n",
        "\n",
        "They also often arise naturally when working in bulk with datasets (e.g., lists of lists of dicts)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLrMV8UUQGJH"
      },
      "source": [
        "#### Common pytree functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYlra8laQHWP"
      },
      "source": [
        "The most commonly used pytree functions are `jax.tree_map` and `jax.tree_multimap`. They work analogously to Pythons native `map`, but on entire pytrees.\n",
        "\n",
        "For functions with one argument, use `jax.tree_map`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuTk477cQOhe",
        "outputId": "fd287ad2-c33c-4be5-96f9-c5257769804b"
      },
      "source": [
        "list_of_lists = [\n",
        "    [1, 2, 3],\n",
        "    [1, 2],\n",
        "    [1, 2, 3, 4]\n",
        "]\n",
        "\n",
        "jax.tree_map(lambda x: x*2, list_of_lists)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2, 4, 6], [2, 4], [2, 4, 6, 8]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsdYad-ZQQ8g"
      },
      "source": [
        "To use functions with more than one argument, use `jax.tree_multimap`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQrfER54QR-q",
        "outputId": "8fb7904d-a81c-42f2-d2c8-3fdab2d46271"
      },
      "source": [
        "another_list_of_lists = list_of_lists\n",
        "jax.tree_multimap(lambda x, y: x+y, list_of_lists, another_list_of_lists)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2, 4, 6], [2, 4], [2, 4, 6, 8]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kvf3vGBIQVlO"
      },
      "source": [
        "For `jax.tree_multimap`, the structure of the inputs must exactly match. That is, lists must have the same number of elements, dicts must have the same keys, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDW6wlILQY7r"
      },
      "source": [
        "#### Example: ML model parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITnJrHbGQanG"
      },
      "source": [
        "A simple example of training an MLP displays some ways in which pytree operations come in useful:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-ws_rjRQdWS"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def init_mlp_params(layer_widths):\n",
        "  params = []\n",
        "  for n_in, n_out in zip(layer_widths[:-1], layer_widths[1:]):\n",
        "    params.append(\n",
        "        dict(weights=np.random.normal(size=(n_in, n_out)) * np.sqrt(2/n_in),\n",
        "             biases=np.ones(shape=(n_out,))\n",
        "            )\n",
        "    )\n",
        "  return params\n",
        "\n",
        "params = init_mlp_params([1, 128, 128, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmDL7s70Qfs0"
      },
      "source": [
        "We can use `jax.tree_map` to check that the shapes of our parameters are what we expect:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOq2pxdUQhYS",
        "outputId": "211f7060-61f4-4026-8f78-a3fff44365f8"
      },
      "source": [
        "jax.tree_map(lambda x: x.shape, params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'biases': (128,), 'weights': (1, 128)},\n",
              " {'biases': (128,), 'weights': (128, 128)},\n",
              " {'biases': (1,), 'weights': (128, 1)}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6wnA_mlQjGM"
      },
      "source": [
        "Now, lets train our MLP:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61ml1PxXQlK_"
      },
      "source": [
        "def forward(params, x):\n",
        "  *hidden, last = params\n",
        "  for layer in hidden:\n",
        "    x = jax.nn.relu(x @ layer['weights'] + layer['biases'])\n",
        "  return x @ last['weights'] + last['biases']\n",
        "\n",
        "def loss_fn(params, x, y):\n",
        "  return jnp.mean((forward(params, x) - y) ** 2)\n",
        "\n",
        "LEARNING_RATE = 0.0001\n",
        "\n",
        "@jax.jit\n",
        "def update(params, x, y):\n",
        "\n",
        "  grads = jax.grad(loss_fn)(params, x, y)\n",
        "  # Note that `grads` is a pytree with the same structure as `params`.\n",
        "  # `jax.grad` is one of the many JAX functions that has\n",
        "  # built-in support for pytrees.\n",
        "\n",
        "  # This is handy, because we can apply the SGD update using tree utils:\n",
        "  return jax.tree_multimap(\n",
        "      lambda p, g: p - LEARNING_RATE * g, params, grads\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "2kcdQe7tQnYi",
        "outputId": "8e7219ea-d97f-4bca-e4fa-e7ffff030b4a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "xs = np.random.normal(size=(128, 1))\n",
        "ys = xs ** 2\n",
        "\n",
        "for _ in range(1000):\n",
        "  params = update(params, xs, ys)\n",
        "\n",
        "plt.scatter(xs, ys)\n",
        "plt.scatter(xs, forward(params, xs), label='Model prediction')\n",
        "plt.legend();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAAD7CAYAAACsV7WPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAl1ElEQVR4nO3de3zU9Z3v8dcnwwQGsEQlXgiyWOuhFQihRsSKl4UiXjFwunijdrUa9+hWrSsVVg8X64rC2Rbt2j2y9uKuqKQYKGpZiq7WxbaWRDCIlN3Wa4I9BjBYIJBJ8j1/TGZIwsxkQub2m3k/Hw8eYX6/X2Y+A8kn33x+3+/3Y845REQkuxVkOgAREemZkrWIiAcoWYuIeICStYiIByhZi4h4gJK1iIgHJJSszezbZrbNzN42s2fMbECqAxMRkcN6TNZmVgLcDpQ758YAPuDqVAcmIiKH9evFdQEzCwIDgZ3xLh46dKgbOXJkH0MTEckftbW1u5xzxbHO95isnXMNZvZ/gA+BZuCXzrlfdr/OzCqBSoARI0ZQU1Nz9FGLiOQZM/sg3vlEyiDHAlcCpwLDgEFmNrv7dc655c65cudceXFxzB8OIiJyFBK5wfhV4D3nXKNzLghUA19JbVgiItJZIsn6Q2CimQ00MwOmANtTG5aIiHSWSM36DTNbBbwJtAKbgeW9faFgMEh9fT0HDx7sfZSStQYMGMDw4cPx+/2ZDkUkpyU0G8Q5twBY0JcXqq+v55hjjmHkyJGEBujidc45du/eTX19PaeeemqmwxHJaYlO3euzgwcPKlHnGDPj+OOPp7GxMdOhiGTUms0NLF2/g51NzQwrCjBn2igqxpck9TXSlqwBJeocpP9TyXdrNjcwr3orzcE2ABqamplXvRUgqQlbe4OIiPTB0vU7Iok6rDnYxtL1O5L6OnmVrM2M2bMPTxFvbW2luLiYyy+/vFfPM3LkSHbt2tXna/rq/fffZ8yYMQDU1NRw++23x73+wQcf7PL4K1/RDEyRvtrZ1Nyr40crr5L1oEGDePvtt2luDv0jbtiwgZKS5NaVkqG1tbXXn1NeXs6jjz4a95ruyfrXv/51r19HRLoaVhTo1fGjlb3Juq4Kvj8GFhaFPtZVJeVpL730Ul588UUAnnnmGa655prIuT179lBRUUFpaSkTJ06krq4OgN27d3PRRRcxevRobrrpJjo3GX7qqaeYMGECZWVl3HLLLbS1df11qLvBgwfz7W9/m9GjRzNlypTIzbkLL7yQO++8k/Lych555BFqa2u54IILOPPMM5k2bRoff/wxALW1tYwbN45x48bx2GOPRZ731VdfjfyGsG/fPm644QbGjh1LaWkpzz33HHPnzqW5uZmysjKuu+66SCwQmtUxZ84cxowZw9ixY1m5cmXkOS+88EK+9rWv8cUvfpHrrrsONVgW6WrOtFEE/L4uxwJ+H3OmjUrq62Rnsq6rgudvh70fAS708fnbk5Kwr776ap599lkOHjxIXV0dZ599duTcggULGD9+PHV1dTz44INcf/31ACxatIhJkyaxbds2ZsyYwYcffgjA9u3bWblyJa+//jpbtmzB5/OxYsWKuK+/f/9+ysvL2bZtGxdccAGLFi2KnGtpaYmUM771rW+xatUqamtrufHGG7n33nsBuOGGG/jBD37AW2+9FfM1vvvd7zJkyBC2bt1KXV0dkydP5qGHHiIQCLBly5YjYqyurmbLli289dZbvPTSS8yZMyfyw2Hz5s0sW7aMd955h3fffZfXX3+9F//aIrmvYnwJi2eOpaQogAElRQEWzxzr7dkgCXv5fgh2q/cEm0PHS2f16alLS0t5//33eeaZZ7j00ku7nNu4cSPPPfccAJMnT2b37t189tlnvPbaa1RXVwNw2WWXceyxx4bCfPllamtrOeusswBobm7mhBNOiPv6BQUFXHXVVQDMnj2bmTNnRs6Fj+/YsYO3336bqVOnAtDW1sbJJ59MU1MTTU1NnH/++QB8/etfZ926dUe8xksvvcSzzz4beRyON5aNGzdyzTXX4PP5OPHEE7ngggvYtGkTn/vc55gwYQLDhw8HoKysjPfff59JkybFfT6RfFMxviTpybm77EzWe+t7d7yXpk+fzt13382rr77K7t27j/p5nHN84xvfYPHixUf9HJ2nvg0aNCjyvKNHj+Y3v/lNl2ubmpqO+nWOVv/+/SN/9/l8R1VPF5G+y84yyJDhvTveSzfeeCMLFixg7NixXY6fd955kRLBq6++ytChQ/nc5z7H+eefz9NPPw3AunXr+PTTTwGYMmUKq1at4pNPPgFCNe8PPoi7yyHt7e2sWrUKgKeffjrqKHXUqFE0NjZGknUwGGTbtm0UFRVRVFTExo0bAWKWXKZOndqlnh2O1+/3EwwGj7j+vPPOY+XKlbS1tdHY2Mhrr73GhAkT4r4PEUmv7EzWU+aDv9udVH8gdDwJhg8fHnWa28KFC6mtraW0tJS5c+fy5JNPAqFa9muvvcbo0aOprq5mxIgRAJxxxhk88MADXHTRRZSWljJ16tRIrTeWQYMG8bvf/Y4xY8bwH//xH8yff+R7KiwsZNWqVdxzzz2MGzeOsrKyyMyNn/zkJ9x2222UlZXFvNl333338emnnzJmzBjGjRvHK6+8AkBlZSWlpaWRG4xhM2bMoLS0lHHjxjF58mSWLFnCSSed1MO/ooikk6Xi7n55ebnr3nxg+/btfOlLX0r8SeqqQjXqvfWhEfWU+X2uV2eDwYMHs2/fvkyHkVS9/r8VkSOYWa1zrjzW+eysWUMoMedAchYRSYbsLIPksFwbVYtIeqQ1WWtBRe7R/6lIeqQtWQ8YMIDdu3frmzuHhPezHjBgQKZDEcl5PdaszWwUsLLToc8D851zy3rzQsOHD6e+vl57H+eYcKcYEUmtRNp67QDKAMzMBzQAq3v7Qn6/X91ERESOUm/LIFOAPzrn4q/8EBGRpOptsr4aeCYVgYiISGwJJ2szKwSmAz+Lcb7SzGrMrEZ1aRGR5OrNyPoS4E3n3P+LdtI5t9w5V+6cKy8uLk5OdCIiAvQuWV+DSiAiIhmRULI2s0HAVKA6teGIiEg0Ce0N4pzbDxyf4lhERCQG7Q0iIuIBStYiIh6gZC0i4gFK1iIiHqBkLSLiAUrWIiIeoGQtIuIBWdODcc3mBpau38HOpmaGFQWYM20UFeNLMh2WiEhWyIpkvWZzA/Oqt9IcbAOgoamZedVbAZSwRUTIkjLI0vU7Iok6rDnYxtL1OzIUkYhIdsmKZL2zqblXx0VE8k1WJOthRYFeHRcRyTdZkaznTBtFwO/rcizg9zFn2qgMRSQikl2y4gZj+CaiZoOIiESXFckaQglbyVlEJLqsKIOIiEh8StYiIh6QaFuvIjNbZWa/N7PtZnZOqgMTEZHDEq1ZPwL8u3Pua2ZWCAxMYUwiIinntS0uekzWZjYEOB/4awDnXAvQktqwRERSx4tbXCRSBjkVaAR+YmabzeyJjm7nXZhZpZnVmFlNY2Nj0gMVEUkWL25xkUiy7gd8Gfhn59x4YD8wt/tFzrnlzrly51x5cXFxksMUEUkeL25xkUiyrgfqnXNvdDxeRSh5i4h4khe3uOgxWTvn/gR8ZGbhtd9TgHdSGpWISAp5cYuLRGeDfAtY0TET5F3ghtSFJCKSWl7c4iKhZO2c2wKUpzYUEZH08doWF1rBKCLiAUrWIiIeoGQtIuIBStYiIh6gZC0i4gFK1iIifVVXBd8fAwuLQh/rqpL+ElnTKUZExJPqquD52yHYsVR970ehxwCls5L2MhpZi4j0xcv3H07UYcHm0PEkUrIWEemLvfW9O36UlKxFRPpiyPDeHT9KStYiIn0xZT74u+3W5w+EjieRkrWISF+UzoIrHoUhpwAW+njFo0m9uQiaDSIi0nels5KenLvTyFpExAOUrEVEPEDJWkTEAxKqWZvZ+8CfgTag1TmnRgQiImnUmxuMf+mc25WySEREJCaVQUREPCDRZO2AX5pZrZlVRrvAzCrNrMbMahobG5MXoYiIJJysJznnvgxcAtxmZud3v8A5t9w5V+6cKy8uLk5qkCIi+S6hZO2ca+j4+AmwGpiQyqBERKSrHpO1mQ0ys2PCfwcuAt5OdWAiInJYIrNBTgRWm1n4+qedc/+e9EjqqkL7v+6tD+1WNWV+ypdvioh4RY/J2jn3LjAupVGkqdOCiEiExwaI2bGRU7xOC1n8jycimbNmcwNL1+9gZ1Mzw4oCzJk2iorxJYl9sgcHiNkxzzpNnRZEJDes2dzAvOqtNDQ144CGpmbmVW9lzeaGxJ4gTa24kik7knWaOi2ISG5Yun4HzcG2Lseag20sXb8jsSfw4AAxO5J1mjotiEhu2NnU3KvjR/DgADE7knWaOi2ISG4YVhTo1fEjeHCAmB03GCEtnRZEJDfMmTaKedVbu5RCAn4fc6aNSuwJwrlGs0FERFInPOvjqGeDgOcGiErWIuIJ0abqvT53cqbDShslaxHJeuGpeuGyR3iqHtC70bSHZccNRhGROPo8VS8HKFmLSNbr81S9HKBkLSJZr89T9XKAkrWIZL0500YR8Pu6HOvVVL0coBuMIpL1kjJVz+OUrEXEEyrGl+RVcu5OZRAR8aa6Kvj+GFhYFPpYV5XpiFIq4ZG1mfmAGqDBOXd56kISEemBB/ej7qvejKzvALanKhARkYR5cD/qvkpoZG1mw4HLgH8A7kppRBnQp44TIpJ+HtyPuq8SLYMsA74DHBPrAjOrBCoBRowY0efA0kXLWEU8onPPRCsA13bkNVm8H3Vf9VgGMbPLgU+cc7XxrnPOLXfOlTvnyouLi5MWYKppGauIB4Rr1Hs/Alz0RJ3l+1H3VSI163OB6Wb2PvAsMNnMnkppVGmkZawiHhCtRg1gPvKlYUmPZRDn3DxgHoCZXQjc7Zybndqw0mdYUYCGKIk5n5aximS9WLVo1w4Lm9IaSqbk/TxrLWMV8QAP9kxMtl4la+fcq7k2x7pifAmLZ46lpCiAASVFARbPHKubiyLZxIM9E5NNy83RMlaRrOfBnonJpmQtIt7gsZ6JyZb3NWsg7/YYEBHv0cg6D/cYEBHv0cg6D/cYEBHvUbLOwz0GRMR7lKw1f1NEPEDJWvM3RcQDlKxLZ4X2FBhyCvmyx4CIeI9mg0Dez98UkeynkbWIiAdoZN1L6ioj0nv6vuk7JeteUFcZkd5bs7mBjat/yEqeZVj/Xew8MJRlq68GbtX3TS+oDNILS9fvYGrbr9hYeDvv9r+WjYW3M7XtV+oqIxLHlheXc78tZ3jBLgoMhhfs4n5bzpYXl2c6NE9Rsu6F8s828JD/iS5fdA/5n6D8sw2ZDk0kK21a+zj3BR9loLV0OT7QWripJWcaTqWFknUvzCv8WdQvuu/4q1izuSFDUYlkp01rH2dM7X30s/ao54cV7E5zRN6mZN0LJ7Ir6vFh7GLj6h8qYYt0cvqb3yXQbXDT2cHASWmMxvsS6W4+wMx+Z2Zvmdk2M1uUjsCykcVYgm6GanAindVVMcT9OebpVt8ABl6izdJ6I5GR9SFgsnNuHFAGXGxmE1MaVbaKtjS9w0BrYUFwGX9a+AU2rX08zYGJZJcD6+ZjFv1cKwX0u/IHWojWSz0maxeyr+Ohv+OPS2lU2apjaXqsN28GJ9HImNr7lLAlrw1o/lPU487B5i8/pER9FBKqWZuZz8y2AJ8AG5xzb0S5ptLMasysprGxMclhZpHSWTQHTo57ScBaOOXNpWkKSCT77Gw/PurxPW4wZ02/Jc3R5IaEkrVzrs05VwYMByaY2Zgo1yx3zpU758qLi4uTHGZ2GXjJ/bT6BsS95gQX/WakSE7q1hrvDV85B1xhl0sOuEJ+UHhTZuLLAb2aDeKcawJeAS5OSTReUTorVHMbckrMksgnNjStIYlkTLg13t6PAAd7P+LKgldZ7S6gvn0o7c6obx/KfFdJ2WWVmY7WsxKZDVJsZkUdfw8AU4Hfpziu7Fc6C779NjVfXkJztxFEi/NxrD+oBrySH6K0xuvXdpAZg97mqoH/wmmHVnDVwH9h0gwtL+8Lcy7+vUIzKwWeBHyEknuVcy7unJvy8nJXU1OTtCCz3aa1j3PKm0s5we3iMxvMYDtIPxeMnHeABY6DSx7WjRXJPQuLiD7nwGBhU3pj8TAzq3XOlcc63+NGTs65OmB8UqPKMWdNvwU6bpoUPvxF+jV3nV9qAM171DVdckddVWhEvbeedjMKogz6DgROYmAGQstVWsGYZLGmLAGhXxXX3ZO+YERSoVuNusC10z1XH3CFLAlelZHwcpWSdZLFmrIU0bxHNWzxtig1ajNodQWRm4lzgzfx5L4JGQowNylZJ9kThbOPmLJ0hJe1zFY8KDw9b+9HUU8X4Pj8oRVManmUte2TGFYUfbWvHB0l6yQru6yS+a6SPW7wEb8aRuytT2tMIn3WpfQR3U53+LfKgN/HnGmj0hFZ3lCyTrKK8SVMmnErXz60nE8ZHPWadjNN6xNviVL66KzF+vNE4WwMKCkKsHjmWE3TSzIl6xSoGF9CSVGAhcHrjyiJOAcFrp3w4gGev10JW7JXD6UP56C+fSh/33YzZZdV8t5Dl/H63MlK1CmgZJ0ic6aNYm37JOYGb4qs4mp1BUfuRBZsVg1bslMCpY8GN5RJLY+yquUram+XYkrWKVIxvoRjB/pZ2z6JSS2P8vlDKyggescM9n6kkohknx5KHwdcIUtaD68Z2NkU+1rpOyXrFFpwxWgCfl/k8U4XZ78QlUQk28S4ER4ufcwN3sTa9kmR45r9kVpK1ilUMb6ExTPHUlIUwIDHCq6NP61Pi2Ykm8TojBQufXRO1Jr9kXpK1ilWMb6E1+dO5r2HLuO1AX8ZqWHHnNanRTOSLaJ0Rupe+gDN/kgXJes02tnUHKlhN8QrieiGo2SD0llsGruIP1HcZWVi5xG1gWZ/pEmPGzlJ8gwrCtDQcRNmSessHvH/MHqfuvANxynztemTZMyazQ3M2/QXNAcfiXmN6tTpo5F1Gs2ZNipyw3Ft+6SYi2aAUMKuvhn+6ew0RSfS1dL1O2gOtsU8rzp1eilZp1HnG45A1EUzR9j1e3hyehqiE+kq3lQ81anTT8k6zcI3HA26LJqJ2wPivV/ppqOkXawSR0lRQHXqDEikrdcpZvaKmb1jZtvM7I50BJbrwt8ICd1wBFhzqxK2pFXnsl2YSh+Zk8jIuhX4O+fcGcBE4DYzOyO1YeW+7l/wS1pnxR9dtwc1B1vSqvs6AZU+MiuRtl4fAx93/P3PZrYdKAHeSXFsOa1ifAmLnt/GpwdCvRrXtk/if7mf80Uaos8QgdAcbJG+eHJ6qKwW5iuEKx+LOeuoYnyJknOW6FXN2sxGEurH+EaUc5VmVmNmNY2NjUkKL7d1X45+SctS/rN9dPwRtsjR6p6oAdpaoLpSJTYPSDhZm9lg4DngTufcZ93PO+eWO+fKnXPlxcXFyYwxZ3WfHQJwffDe2FP6AselKTLJSd0TdYTTQiwPSChZm5mfUKJe4ZyrTm1I+SU8O6Rzwl4YvJ4W17VC1Wp+uOThdIcnXhfej3phUfzr1L0o6yUyG8SAHwHbnXPfS31I+anzDce17ZO4O1gZ2Qe7vn0odx26mfve/VLXbz5tqyrxdOtCHleMTZske5jroUBqZpOA/wS2QmRD5r93zv0i1ueUl5e7mpqapAWZL/7Hvb+gpS32/0eF73WWDfzxkXsM+wfBFcu0NF26evjUBG9KG8xcrq+fDDOzWudceazzPY6snXMbnXPmnCt1zpV1/ImZqOXoLfnaOApizQQB7vatjL4ZfHC/5mFLVy/clVii9hUqUXuEVjBmkYrxJXxvVlnM88NsV+xP1jxsCaurgpofxTx9IHAy5w5YzakHn+Zc/0rWtJ2bxuDkaClZZ5mK8SXMnjgi6rm9hSfG/2TthS0Q94e2A+bunUFDUzMOaGhqZl71VtZsbkhbeHJ0lKyz0AMVY5k9cQS+jtUxPjNmTxzBsVc8QGgH4Tg0us5vdVVxyx+fusFd9qMGaA62qdmtB2g/6yz1QMVYHqgY2+3oWP5Y+zKf/+DZ2Cm7eY/2ws5X4dkfMTgXmhYajZrdZj+NrD1kzeYGLn93Bne03Bp/laOa7+anHrqR73P9jxhVh6mJQPZTsvaQ8GbwPTYugNA37fN3piUuyRJxFrYccj7ubf1mzPPaSS/7KVl7SOdfVaOtcjxCcL8aF+SqaIujYixsaXUFzAneEnNUffoJg7RZkwcoWXtI519VO69yVOOCPFNXBT+/7fDKxL0fhR6fflHUbuR3Bf8mZqI+97Tj2HDXhamPWfpMydpD5kwb1eXGYrhxwR3BHmrY2qQnd9RVwepbQrvlddbWAttWwxWPciBwcsxu5BCaT/T+Q5fx/kOXseLmc9IXu/SJkrWHVIwv4booc7DXtk+iPd6UvnC3dI2wvS0828O1Rz/fvAdKZ3HuoUf5/KEVTGp5NOqIWjcTvUnJ2mPCc7C7e6ptimaI5LK6qlC3+zizPSA0Yyjc0CIaQzcTvUrJ2oMeqBjLuad13dt6QeuNPTcuCDarJOJFdVWw+m96vOyQfwjzqrfGvea6iSN0M9GjlKw9asXN53RZ5QihxgV3BG+Nf9NR+xZ7z7p7wLXFv6bAz2J3A83B2NcF/AVRFlqJVyhZe9gDFWP54+JLuzQu6LFbuvYt9pYelo8DoQ5CFT/kyX0TYl7iLzAWzyxNcnCSTkrWOSBaDXJJ6ywOuMIux9qsX+gbf+GQ0J+HT1UNO1u9cBcsOi5Up47HCuCe96B0Vswbhz4zlv7VOJU/PE7JOgdUjC85ooa9tn0Sc4M3RbrN7G4fjGtvh5b9hy9q3qN9sLPRC3eFtjjtofThHDwZnMxp837BfWu2MmfaqC4NmAECfh//OEuJOhck0tbrx2b2iZm9nY6A5OisuPmcqAl7UktoGlczA+hnUaZ8tQd10zHb1P60x0ucg39t+yoLWm+kzTme+u2H1HywJ9KA2YCSogCLZ45Vos4RibT1Oh/YB/yrc25MIk+qtl6Zs2ZzA0vX76Ch2y5q7/a/Nm4XGmb+i3bpyxYLh8Q9fcAVRl3s4jPjj4svTWVkkkLJaOv1GpBIIzfJAtG6pQPsjHXDMay6MvTrt2Se+aIedo6YqxIB2noYeIm3Ja1mbWaVZlZjZjWNjY3Jelo5St3rl0taZ/Ww8ZML1UmVsDPvzL8+4lC47BFrVSLQZRqn5J6kJWvn3HLnXLlzrry4uDhZTytHqWJ8SZf65YvuPO4OVrLHDY6/cKbmR9qpL9Mu/x6UfzMywm6lIFKfjueas09JR3SSIT3WrAHMbCTwgmrW3nXq3BcJ/09vLLyd4QVxmu8CnHoBfGNtyuPKW3VVoRu7e+tDc99jdPZZs7mBO1du6fHpZk8coQUvHtdTzVptvfLEsKJA5KbjktZZLPP/MP4Nx/DWqrrpmHwv3AU1P4bwj8/wvi0Q+fe+b81Wnnnjo4Tq0MuuKtOMjzyQyNS9Z4DfAKPMrN7MYrebkKw1Z9oo/L5Qdl7bPol/a/tq/HIIhLbi1Bzs5ArPoabbP36nfVvuW7OVp377YUKJ+tzTjlOizhM9jqydc9ekIxBJrfA39KLnt/HpgWCk/nm97yVi3pdy7aEVdB/+NlRHlb6JJOoYOvZteeaNjxJ6OpU+8otWMOaRivElbJ5/EcuuKsNIcKc+wNX8SCPsvqqrip+oIbJvS08j6oDfx7KrypSo84ySdR7q3MTg+uC9PSZsAw6sm5+e4HLVunt6uMBCNxmJPwVPqxLzl5J1nnqgYizLriqjf78Crg/eyx4Xv1v6gOY/pSmyHBNubNvTznnlN0ZuLsaagjd74ghenztZiTpPKVnnsYrxJex44BLOPe04FrVezyEXfeUcwKftg47spi3xhdtw7Y1fg95Hf9aU/F3kcbgbUHiE7TNTfVoSm2fdW5pn7T33rdnKZ797mn/o9yMG26EuNx0POR9mRiGtkWOtvgH0u/IHmtoXTV0VvHBn1x0OY2h3cGfwVtZxnrYxzXN93htE8sMDFWP53IRrGdvyk0i3mXCH7P0EuiRqgH5tB3HP3cyfFn6BTWsfz1DUWaiuCtb8TcKJ+t/avsra9kkE2x1L1+9IQ4DiVVoUIxEPVIyl/C+OY9HzftYeCO0/URTw86aLPno2g5NoZEjtfWwCzpp+SxqjzVIv3w/tPe9D3eCGsqR1Vpd9PnY2xW+GK/lNyVq6qBhfcsSv4vXzj4+7PD1gLZxcs4SRvx7OsQP9LLhidP79Ol9XBc/fCcH4I+pY25sCMTu9iIDKIJKAJwpnH9EirLsS28V7/a+lpm0Wn1XfwZrNDWmKLgu8cFdo8VAPido5YiZqf4FFbc8mEqZkLT0qu6yS+a4ybtd0s9Afnzm+XrCBgz//dnqDzJSeViV2CG9xGj1Ro5uL0iOVQaRHoSRyK1etn8KZn23gIf8TDLSWmNebwdfcBkbOfTFyLOAvYPHM0txJSB1lDxfcT7z9sJyDduCpGFucnnvacay4+ZyUhSm5Q8laEnK4lj2ZTWtHcsqbSznRNcbcV8RH136PzcF27ly5hZoP9nh/vnBdFW2rb8XngnETNUAbBXzh0FORx0ZoC6eSogBzpo3KnR9eknJK1tJrZ02/BabfwoGHv8jA5o9jXvdu/2vZ2W3Ww1O//ZDyv/DeTnGb1j7OKW8u5QTXSLsV0I8ozYe7cQ5WtE2OPB5U6OMfZmipuBwdLYqRo1dXRVv1LUeMop2jy4g7PJ84XAY4dqCf/YdaaWk7/LWXreWATWsf5wtv3k+R2xd7d8JunAuNnju/52x9f5I91HxAUqd0Fj4guOZ2+rU3R7Zo7p7UCiy0FSuEdvr79EDwiKd6/Y97IjVunxnXnH1Kxsol4Q7xlfse4+u+l0JNGnqRqDu34NJoWpJFI2tJKrewCOu+sX74XLdE1pP+/QoI+H3sbQ4yLAU13jWbG5jzsy0E22F6wUa+06+KYbaLJgbjd8Ejlt33pPv7034e0hs9jawT7cF4MfAI4AOecM49FO96Jes89v0xcTcucg7uCN4as0N3Twb6C2gOtuP3WZcyCnQdka/Z3MC86jqag4dLNAF/Af/zzOG8WPdxZHQ/vWAjC/r9K8dZ4mWOsDZnFHT8YNrjBrOo9Xpe8p3Pg7k060XSps/J2sx8wH8BU4F6YBNwjXPunVifo2Sdx+qqQgtE4qhvH8qklkdTFsLpJwzij5/sj3sLcHrBRpb4H6c/bb1O0hBaibjAVfKzlq8AoWX5C6fn4cpNSZpk1KwnAH9wzr3b8YTPAlcCMZO15LHSWT0uux5mu1Mawn9/Evu1pxds5EH/jxnEwaNK0s5Bkx3DH8783yydfgtL+xCnSG8kkqxLgM6/19YDZ6cmHMkJVyyLO7oOFg7hTSo5ln3A4RLC0ZZGoplesDGy3WvYQefDb45+1vO0u2jaHbxx/AzOuf2nnJWsQEUSlLTZIGZWCVQCjBgxIllPK15UOivUZDfaMuwCH/1b/0x/O7wz3fG2j2WFP+T77p8jNWCATzvd6APYzwAOuX4ca/uOmL/d2fSCjfyj/5/xW9cSX8Di74YXi3Ow147hv8/835yjnQUlQxKpWZ8DLHTOTet4PA/AObc41ueoZi1AqH697p7DLa0Cx4U+9tTiKkHRvnT3059Dzs/xBfuO/nmBFv8Q+gc/CzWxnTJfTRYk5ZJRs94EnG5mpwINwNXAtUmKT3JZ6awjk9zCoqQ9fbSa82AOMYhDR57ozfOWf5P+l3+vT88hkmw97rrnnGsF/hZYD2wHqpxz21IdmOSoIcNT/hJHc+Ow4zOh/JugRC1ZKKGatXPuF8AvUhyL5IMp83uc2pdyhYMOt90KHAeXPKwyh2Q9LTeX9CqdBZufgvd+ldrXCRwHrYe6TiH0DwrNVFFiFg9Sspb0+8ba0Kb9tT8F1wbmg+NPh93/HXoc1j3hFg4CX/+eb1CaT6NlyTlK1pIZl3+vb7XhJ6dHH51r9Cw5SslavOkbazMdgUhaqQejiIgHKFmLiHiAkrWIiAcoWYuIeICStYiIB6SkrZeZNQIfJP2JU2sosCvTQaRBPrzPfHiPkB/vMx/eI4Te5yDnXHGsC1KSrL3IzGri7XiVK/LhfebDe4T8eJ/58B4hsfepMoiIiAcoWYuIeICS9WHLMx1AmuTD+8yH9wj58T7z4T1CAu9TNWsREQ/QyFpExAOUrEVEPEDJuhMzW2pmvzezOjNbbWZFmY4pFczsr8xsm5m1m1lOTYsys4vNbIeZ/cHM5mY6nlQwsx+b2Sdm9namY0kVMzvFzF4xs3c6vlbvyHRMyWZmA8zsd2b2Vsd7XBTveiXrrjYAY5xzpcB/AfMyHE+qvA3MBF7LdCDJZGY+4DHgEuAM4BozOyOzUaXET4GLMx1EirUCf+ecOwOYCNyWg/+Xh4DJzrlxQBlwsZlNjHWxknUnzrlfdjQIBvgtkPrurhngnNvunNuR6ThSYALwB+fcu865FuBZ4MoMx5R0zrnXgB7a5Xibc+5j59ybHX//M6Fm3SWZjSq5XMi+jof+jj8xZ3woWcd2I7Au00FIr5QAH3V6XE+OfYPnIzMbCYwH3shwKElnZj4z2wJ8AmxwzsV8j3nXKcbMXgJOinLqXufczzuuuZfQr2Er0hlbMiXyPkWynZkNBp4D7nTOfZbpeJLNOdcGlHXcH1ttZmOcc1HvReRdsnbOfTXeeTP7a+ByYIrz8CT0nt5njmoATun0eHjHMfEgM/MTStQrnHPVmY4nlZxzTWb2CqF7EVGTtcognZjZxcB3gOnOuQOZjkd6bRNwupmdamaFwNWAmjV6kJkZ8CNgu3OuD52Vs5eZFYdnnJlZAJgK/D7W9UrWXf0TcAywwcy2mNn/zXRAqWBmM8ysHjgHeNHM1mc6pmTouDn8t8B6Qjekqpxz2zIbVfKZ2TPAb4BRZlZvZt/MdEwpcC7wdWByx/fiFjO7NNNBJdnJwCtmVkdooLHBOfdCrIu13FxExAM0shYR8QAlaxERD1CyFhHxACVrEREPULIWEfEAJWsREQ9QshYR8YD/D9B0QwyO1gNeAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DS-W421TQuiH"
      },
      "source": [
        "#### Custom pytree nodes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RtvJWu9Qwmh"
      },
      "source": [
        "So far, weve only been considering pytrees of lists, tuples, and dicts; everything else is considered a leaf. Therefore, if you define my own container class, it will be considered a leaf, even if it has trees inside it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8l5x77LnQyZG"
      },
      "source": [
        "class MyContainer:\n",
        "  \"\"\"A named container.\"\"\"\n",
        "\n",
        "  def __init__(self, name: str, a: int, b: int, c: int):\n",
        "    self.name = name\n",
        "    self.a = a\n",
        "    self.b = b\n",
        "    self.c = c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtfFlwVDQzUg",
        "outputId": "f7d68558-e2f0-433c-c4ba-6709e11e0927"
      },
      "source": [
        "jax.tree_leaves([\n",
        "    MyContainer('Alice', 1, 2, 3),\n",
        "    MyContainer('Bob', 4, 5, 6)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<__main__.MyContainer at 0x7f8a09e02610>,\n",
              " <__main__.MyContainer at 0x7f8a09e021c0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUN-ngliQ1Sl"
      },
      "source": [
        "Accordingly, if we try to use a tree map expecting our leaves to be the elements inside the container, we will get an error:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "id": "reHeh7VrQ2l0",
        "outputId": "bc0bd0fc-dd25-4c64-8788-4a599ea0fa03"
      },
      "source": [
        "jax.tree_map(lambda x: x + 1, [\n",
        "    MyContainer('Alice', 1, 2, 3),\n",
        "    MyContainer('Bob', 4, 5, 6)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-162-d6b45a2ec2b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m jax.tree_map(lambda x: x + 1, [\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mMyContainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Alice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mMyContainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Bob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m ])\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/tree_util.py\u001b[0m in \u001b[0;36mtree_map\u001b[0;34m(f, tree, is_leaf, *rest)\u001b[0m\n\u001b[1;32m    166\u001b[0m   \u001b[0mleaves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtreedef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_leaf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m   \u001b[0mall_leaves\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mleaves\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtreedef\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_up_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtreedef\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mxs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mall_leaves\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0mtree_multimap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/tree_util.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    166\u001b[0m   \u001b[0mleaves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtreedef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_leaf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m   \u001b[0mall_leaves\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mleaves\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtreedef\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_up_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtreedef\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mxs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mall_leaves\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0mtree_multimap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-162-d6b45a2ec2b9>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m jax.tree_map(lambda x: x + 1, [\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mMyContainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Alice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mMyContainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Bob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m ])\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'MyContainer' and 'int'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2PVKi6CQ6EZ"
      },
      "source": [
        "To solve this, we need to register our container with JAX by telling it how to flatten and unflatten it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzR8xrzoQ7uU"
      },
      "source": [
        "from typing import Tuple, Iterable\n",
        "\n",
        "def flatten_MyContainer(container) -> Tuple[Iterable[int], str]:\n",
        "  \"\"\"Returns an iterable over container contents, and aux data.\"\"\"\n",
        "  flat_contents = [container.a, container.b, container.c]\n",
        "\n",
        "  # we don't want the name to appear as a child, so it is auxiliary data.\n",
        "  # auxiliary data is usually a description of the structure of a node,\n",
        "  # e.g., the keys of a dict -- anything that isn't a node's children.\n",
        "  aux_data = container.name\n",
        "  return flat_contents, aux_data\n",
        "\n",
        "def unflatten_MyContainer(\n",
        "    aux_data: str, flat_contents: Iterable[int]) -> MyContainer:\n",
        "  \"\"\"Converts aux data and the flat contents into a MyContainer.\"\"\"\n",
        "  return MyContainer(aux_data, *flat_contents)\n",
        "\n",
        "jax.tree_util.register_pytree_node(\n",
        "    MyContainer, flatten_MyContainer, unflatten_MyContainer)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GqX6pM4RIZ5",
        "outputId": "47c095ad-2089-4b7c-c214-aa52784e05ae"
      },
      "source": [
        "jax.tree_leaves([\n",
        "    MyContainer('Alice', 1, 2, 3),\n",
        "    MyContainer('Bob', 4, 5, 6)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5, 6]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wKGu8gARBOm",
        "outputId": "ac5a869b-be7f-424e-d4be-d90a63fe468d"
      },
      "source": [
        "jax.tree_leaves(\n",
        "    jax.tree_map(\n",
        "    lambda x: x + 1, [\n",
        "    MyContainer('Alice', 1, 2, 3),\n",
        "    MyContainer('Bob', 4, 5, 6)\n",
        "]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 3, 4, 5, 6, 7]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NvubowvRd7M"
      },
      "source": [
        "---\n",
        "Modern Python comes equipped with helpful tools to make defining containers easier. Some of these will work with JAX out-of-the-box, but others require more care. For instance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HEPyJTcRgLa",
        "outputId": "710a948b-dbf7-4f4a-a487-c35c0b7b2928"
      },
      "source": [
        "from typing import NamedTuple, Any\n",
        "\n",
        "class MyOtherContainer(NamedTuple):\n",
        "  name: str\n",
        "  a: Any\n",
        "  b: Any\n",
        "  c: Any\n",
        "\n",
        "# Since `tuple` is already registered with JAX, and NamedTuple is a subclass,\n",
        "# this will work out-of-the-box:\n",
        "jax.tree_leaves([\n",
        "    MyOtherContainer('Alice', 1, 2, 3),\n",
        "    MyOtherContainer('Bob', 4, 5, 6)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Alice', 1, 2, 3, 'Bob', 4, 5, 6]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N98yoXkBRiC1"
      },
      "source": [
        "Notice that the `name` field now appears as a leaf, as all tuple elements are children. Thats the price we pay for not having to register the class the hard way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_4LW1ojRre_"
      },
      "source": [
        "#### Common pytree gotchas and patterns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ1Y2B9-RssR"
      },
      "source": [
        "##### Gotchas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuH59NVGRv6A"
      },
      "source": [
        "###### Gotcha #1: Mistaking nodes for leaves\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHgdhfGOR31E"
      },
      "source": [
        "\n",
        "A common problem to look out for is accidentally introducing tree nodes instead of leaves:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezdPp1GZR8Ku",
        "outputId": "66a562af-ab24-4954-b985-ce8d2b41c6d4"
      },
      "source": [
        "a_tree = [jnp.zeros((2, 3)), jnp.zeros((3, 4))]\n",
        "\n",
        "# Try to make another tree with ones instead of zeros\n",
        "shapes = jax.tree_map(lambda x: x.shape, a_tree)\n",
        "jax.tree_map(jnp.ones, shapes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(DeviceArray([1., 1.], dtype=float32),\n",
              "  DeviceArray([1., 1., 1.], dtype=float32)),\n",
              " (DeviceArray([1., 1., 1.], dtype=float32),\n",
              "  DeviceArray([1., 1., 1., 1.], dtype=float32))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqGvmWtCR-_h"
      },
      "source": [
        "What happened is that the `shape` of an array is a tuple, which is a pytree node, with its elements as leaves. Thus, in the map, instead of calling `jnp.ones` on e.g. `(2, 3)`, its called on `2` and `3`.\n",
        "\n",
        "The solution will depend on the specifics, but there are two broadly applicable options:\n",
        "\n",
        "- rewrite the code to avoid the intermediate `tree_map`.\n",
        "- convert the tuple into an `np.array` or `jnp.array`, which makes the entire sequence a leaf."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWoY6LhKSTXV"
      },
      "source": [
        "###### Gotcha #2: Handling of None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TaRsqvASYnV"
      },
      "source": [
        "`jax.tree_utils` treats None as a node without children, not as a leaf:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSKIqPozSa1E",
        "outputId": "4e78047a-1113-449f-aee4-ad604a706059"
      },
      "source": [
        "jax.tree_leaves([None, None, None])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onuIL50WRuTK"
      },
      "source": [
        "##### Patterns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otlgU6w0Sl5t"
      },
      "source": [
        "###### Pattern #1: Transposing trees\n",
        "\n",
        "If you would like to transpose a pytree, i.e. turn a list of trees into a tree of lists, you can do so using `jax.tree_multimap`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOIR383ISrS4",
        "outputId": "590ac855-dd98-460e-89e9-694c79404a37"
      },
      "source": [
        "def tree_transpose(list_of_trees):\n",
        "  \"\"\"Convert a list of trees of identical structure into a single tree of lists.\"\"\"\n",
        "  return jax.tree_multimap(lambda *xs: list(xs), *list_of_trees)\n",
        "\n",
        "\n",
        "# Convert a dataset from row-major to column-major:\n",
        "episode_steps = [dict(t=1, obs=3), dict(t=2, obs=4)]\n",
        "tree_transpose(episode_steps)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'obs': [3, 4], 't': [1, 2]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZV-7JqeHSuhs"
      },
      "source": [
        "For more complicated transposes, JAX provides `jax.tree_transpose`, which is more verbose, but allows you specify the structure of the inner and outer Pytree for more flexibility:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elTNWEJ1SxEZ",
        "outputId": "a8e039ee-d9c7-4cd6-9f71-221245abe9d4"
      },
      "source": [
        "jax.tree_transpose(\n",
        "  outer_treedef = jax.tree_structure([0 for e in episode_steps]),\n",
        "  inner_treedef = jax.tree_structure(episode_steps[0]),\n",
        "  pytree_to_transpose = episode_steps\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'obs': [3, 4], 't': [1, 2]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kq7ABk9cSzXa"
      },
      "source": [
        "##### More Information\n",
        "\n",
        "For more information on pytrees in JAX and the operations that are available, see the [Pytrees](https://jax.readthedocs.io/en/latest/pytrees.html) section in the JAX documentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59tBqZi3W9fG"
      },
      "source": [
        "### [Automatic Vectorization in JAX](https://jax.readthedocs.io/en/latest/jax-101/03-vectorization.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDYsTUtEW-lW"
      },
      "source": [
        "In another section we'll discuss JIT compilation via the `jax.jit` function. This notebook discusses another of JAXs transforms: vectorization via `jax.vmap`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2pPVyn2XMzR"
      },
      "source": [
        "#### Manual Vectorization\n",
        "\n",
        "Consider the following simple code that computes the convolution of two one-dimensional vectors:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEQXOtmmXRA7",
        "outputId": "2ff3fdcd-8d61-47d7-f817-9786d606173b"
      },
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "x = jnp.arange(5)\n",
        "w = jnp.array([2., 3., 4.])\n",
        "\n",
        "def convolve(x, w):\n",
        "  output = []\n",
        "  for i in range(1, len(x)-1):\n",
        "    output.append(jnp.dot(x[i-1:i+2], w))\n",
        "  return jnp.array(output)\n",
        "\n",
        "convolve(x, w)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([11., 20., 29.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiNBQLLkXTWy"
      },
      "source": [
        "Suppose we would like to apply this function to a batch of weights `w` to a batch of vectors `x`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDuA4obVXVcS"
      },
      "source": [
        "xs = jnp.stack([x, x])\n",
        "ws = jnp.stack([w, w])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a866-kRDXW9I"
      },
      "source": [
        "The most naive option would be to simply loop over the batch in Python:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_SIwcR3XYLq",
        "outputId": "8310f318-7355-407a-bd6b-f28094c6681f"
      },
      "source": [
        "def manually_batched_convolve(xs, ws):\n",
        "  output = []\n",
        "  for i in range(xs.shape[0]):\n",
        "    output.append(convolve(xs[i], ws[i]))\n",
        "  return jnp.stack(output)\n",
        "\n",
        "manually_batched_convolve(xs, ws)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([[11., 20., 29.],\n",
              "             [11., 20., 29.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYNT82fSXax7"
      },
      "source": [
        "This produces the correct result, however it is not very efficient.\n",
        "\n",
        "In order to batch the computation efficiently, you would normally have to rewrite the function manually to ensure it is done in vectorized form. This is not particularly difficult to implement, but does involve changing how the function treats indices, axes, and other parts of the input.\n",
        "\n",
        "For example, we could manually rewrite `convolve()` to support vectorized computation across the batch dimension as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEmEVPmjXe3r",
        "outputId": "1036e296-017c-4af1-8eeb-94bc24af774b"
      },
      "source": [
        "def manually_vectorized_convolve(xs, ws):\n",
        "  output = []\n",
        "  for i in range(1, xs.shape[-1] -1):\n",
        "    output.append(jnp.sum(xs[:, i-1:i+2] * ws, axis=1))\n",
        "  return jnp.stack(output, axis=1)\n",
        "\n",
        "manually_vectorized_convolve(xs, ws)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([[11., 20., 29.],\n",
              "             [11., 20., 29.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJXDQeFaXh2k"
      },
      "source": [
        "Such re-implementation is messy and error-prone; fortunately JAX provides another way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRpO2OxeXihV"
      },
      "source": [
        "#### Automatic Vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7C0w_sH6Xkzh"
      },
      "source": [
        "In JAX, the `jax.vmap` transformation is designed to generate such a vectorized implementation of a function automatically:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCujG4I3XnNe",
        "outputId": "2d9278d2-77c9-4321-e007-1b72128bdd08"
      },
      "source": [
        "auto_batch_convolve = jax.vmap(convolve)\n",
        "\n",
        "auto_batch_convolve(xs, ws)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([[11., 20., 29.],\n",
              "             [11., 20., 29.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BTeNmMSXpc4"
      },
      "source": [
        "It does this by tracing the function similarly to `jax.jit`, and automatically adding batch axes at the beginning of each input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ5Vg8V1XrmX"
      },
      "source": [
        "If the batch dimension is not the first, you may use the `in_axes` and out_axes arguments to specify the location of the batch dimension in inputs and outputs. These may be an integer if the batch axis is the same for all inputs and outputs, or lists, otherwise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7blvwOCFXvAw",
        "outputId": "5ae3c919-256b-4b57-d416-a2e28054a65a"
      },
      "source": [
        "auto_batch_convolve_v2 = jax.vmap(convolve, in_axes=1, out_axes=1)\n",
        "\n",
        "xst = jnp.transpose(xs)\n",
        "wst = jnp.transpose(ws)\n",
        "\n",
        "auto_batch_convolve_v2(xst, wst)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([[11., 11.],\n",
              "             [20., 20.],\n",
              "             [29., 29.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6ay_M_3XyFg"
      },
      "source": [
        "`jax.vmap` also supports the case where only one of the arguments is batched: for example, if you would like to convolve to a single set of weights `w` with a batch of vectors `x`; in this case the `in_axes` argument can be set to None:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zRoYg7GX3t6",
        "outputId": "a54a12f3-efcc-410b-a406-0ab20f630786"
      },
      "source": [
        "batch_convolve_v3 = jax.vmap(convolve, in_axes=[0, None])\n",
        "\n",
        "batch_convolve_v3(xs, w)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([[11., 20., 29.],\n",
              "             [11., 20., 29.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62iq8YQyX7T7"
      },
      "source": [
        "#### Combining Transformations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHnM7CUFX8z8"
      },
      "source": [
        "As with all JAX transformations, `jax.jit` and `jax.vmap` are designed to be composable, which means you can wrap a vmapped function with `jit`, or a JITted function with `vmap`, and everything will work correctly:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGQ2alLzYBZn",
        "outputId": "53a39fd0-77a6-4e3d-f534-fb2756f381b8"
      },
      "source": [
        "jitted_batch_convolve = jax.jit(auto_batch_convolve)\n",
        "\n",
        "jitted_batch_convolve(xs, ws)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([[11., 20., 29.],\n",
              "             [11., 20., 29.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    }
  ]
}